{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_15 (InputLayer)       [(None, 256, 3072)]          0         []                            \n",
      "                                                                                                  \n",
      " dense_700 (Dense)           (None, 256, 256)             786688    ['input_15[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_19 (T  (None, 256, 256)             0         ['dense_700[0][0]']           \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " class_token_40 (ClassToken  (None, 1, 256)               256       ['tf.__operators__.add_19[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " concatenate_14 (Concatenat  (None, 257, 256)             0         ['class_token_40[0][0]',      \n",
      " e)                                                                  'tf.__operators__.add_19[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " layer_normalization_686 (L  (None, 257, 256)             512       ['concatenate_14[0][0]']      \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_336 (  (None, 257, 256)             3155200   ['layer_normalization_686[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_686[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_672 (Add)               (None, 257, 256)             0         ['multi_head_attention_336[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'concatenate_14[0][0]']      \n",
      "                                                                                                  \n",
      " layer_normalization_687 (L  (None, 257, 256)             512       ['add_672[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_701 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_687[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_1296 (Dropout)      (None, 257, 1024)            0         ['dense_701[0][0]']           \n",
      "                                                                                                  \n",
      " dense_702 (Dense)           (None, 257, 256)             262400    ['dropout_1296[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_1297 (Dropout)      (None, 257, 256)             0         ['dense_702[0][0]']           \n",
      "                                                                                                  \n",
      " add_673 (Add)               (None, 257, 256)             0         ['dropout_1297[0][0]',        \n",
      "                                                                     'add_672[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_688 (L  (None, 257, 256)             512       ['add_673[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_337 (  (None, 257, 256)             3155200   ['layer_normalization_688[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_688[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_674 (Add)               (None, 257, 256)             0         ['multi_head_attention_337[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_673[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_689 (L  (None, 257, 256)             512       ['add_674[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_703 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_689[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_1298 (Dropout)      (None, 257, 1024)            0         ['dense_703[0][0]']           \n",
      "                                                                                                  \n",
      " dense_704 (Dense)           (None, 257, 256)             262400    ['dropout_1298[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_1299 (Dropout)      (None, 257, 256)             0         ['dense_704[0][0]']           \n",
      "                                                                                                  \n",
      " add_675 (Add)               (None, 257, 256)             0         ['dropout_1299[0][0]',        \n",
      "                                                                     'add_674[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_690 (L  (None, 257, 256)             512       ['add_675[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_338 (  (None, 257, 256)             3155200   ['layer_normalization_690[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_690[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_676 (Add)               (None, 257, 256)             0         ['multi_head_attention_338[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_675[0][0]']             \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " layer_normalization_691 (L  (None, 257, 256)             512       ['add_676[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_705 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_691[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_1300 (Dropout)      (None, 257, 1024)            0         ['dense_705[0][0]']           \n",
      "                                                                                                  \n",
      " dense_706 (Dense)           (None, 257, 256)             262400    ['dropout_1300[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_1301 (Dropout)      (None, 257, 256)             0         ['dense_706[0][0]']           \n",
      "                                                                                                  \n",
      " add_677 (Add)               (None, 257, 256)             0         ['dropout_1301[0][0]',        \n",
      "                                                                     'add_676[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_692 (L  (None, 257, 256)             512       ['add_677[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_339 (  (None, 257, 256)             3155200   ['layer_normalization_692[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_692[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_678 (Add)               (None, 257, 256)             0         ['multi_head_attention_339[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_677[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_693 (L  (None, 257, 256)             512       ['add_678[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_707 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_693[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_1302 (Dropout)      (None, 257, 1024)            0         ['dense_707[0][0]']           \n",
      "                                                                                                  \n",
      " dense_708 (Dense)           (None, 257, 256)             262400    ['dropout_1302[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_1303 (Dropout)      (None, 257, 256)             0         ['dense_708[0][0]']           \n",
      "                                                                                                  \n",
      " add_679 (Add)               (None, 257, 256)             0         ['dropout_1303[0][0]',        \n",
      "                                                                     'add_678[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_694 (L  (None, 257, 256)             512       ['add_679[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_340 (  (None, 257, 256)             3155200   ['layer_normalization_694[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_694[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_680 (Add)               (None, 257, 256)             0         ['multi_head_attention_340[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_679[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_695 (L  (None, 257, 256)             512       ['add_680[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_709 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_695[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_1304 (Dropout)      (None, 257, 1024)            0         ['dense_709[0][0]']           \n",
      "                                                                                                  \n",
      " dense_710 (Dense)           (None, 257, 256)             262400    ['dropout_1304[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_1305 (Dropout)      (None, 257, 256)             0         ['dense_710[0][0]']           \n",
      "                                                                                                  \n",
      " add_681 (Add)               (None, 257, 256)             0         ['dropout_1305[0][0]',        \n",
      "                                                                     'add_680[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_696 (L  (None, 257, 256)             512       ['add_681[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_341 (  (None, 257, 256)             3155200   ['layer_normalization_696[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_696[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_682 (Add)               (None, 257, 256)             0         ['multi_head_attention_341[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_681[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_697 (L  (None, 257, 256)             512       ['add_682[0][0]']             \n",
      " ayerNormalization)                                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " dense_711 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_697[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_1306 (Dropout)      (None, 257, 1024)            0         ['dense_711[0][0]']           \n",
      "                                                                                                  \n",
      " dense_712 (Dense)           (None, 257, 256)             262400    ['dropout_1306[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_1307 (Dropout)      (None, 257, 256)             0         ['dense_712[0][0]']           \n",
      "                                                                                                  \n",
      " add_683 (Add)               (None, 257, 256)             0         ['dropout_1307[0][0]',        \n",
      "                                                                     'add_682[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_698 (L  (None, 257, 256)             512       ['add_683[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_342 (  (None, 257, 256)             3155200   ['layer_normalization_698[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_698[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_684 (Add)               (None, 257, 256)             0         ['multi_head_attention_342[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_683[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_699 (L  (None, 257, 256)             512       ['add_684[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_713 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_699[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_1308 (Dropout)      (None, 257, 1024)            0         ['dense_713[0][0]']           \n",
      "                                                                                                  \n",
      " dense_714 (Dense)           (None, 257, 256)             262400    ['dropout_1308[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_1309 (Dropout)      (None, 257, 256)             0         ['dense_714[0][0]']           \n",
      "                                                                                                  \n",
      " add_685 (Add)               (None, 257, 256)             0         ['dropout_1309[0][0]',        \n",
      "                                                                     'add_684[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_700 (L  (None, 257, 256)             512       ['add_685[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_343 (  (None, 257, 256)             3155200   ['layer_normalization_700[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_700[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_686 (Add)               (None, 257, 256)             0         ['multi_head_attention_343[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_685[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_701 (L  (None, 257, 256)             512       ['add_686[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_715 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_701[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_1310 (Dropout)      (None, 257, 1024)            0         ['dense_715[0][0]']           \n",
      "                                                                                                  \n",
      " dense_716 (Dense)           (None, 257, 256)             262400    ['dropout_1310[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_1311 (Dropout)      (None, 257, 256)             0         ['dense_716[0][0]']           \n",
      "                                                                                                  \n",
      " add_687 (Add)               (None, 257, 256)             0         ['dropout_1311[0][0]',        \n",
      "                                                                     'add_686[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_702 (L  (None, 257, 256)             512       ['add_687[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_344 (  (None, 257, 256)             3155200   ['layer_normalization_702[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_702[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_688 (Add)               (None, 257, 256)             0         ['multi_head_attention_344[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_687[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_703 (L  (None, 257, 256)             512       ['add_688[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_717 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_703[0][0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_1312 (Dropout)      (None, 257, 1024)            0         ['dense_717[0][0]']           \n",
      "                                                                                                  \n",
      " dense_718 (Dense)           (None, 257, 256)             262400    ['dropout_1312[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_1313 (Dropout)      (None, 257, 256)             0         ['dense_718[0][0]']           \n",
      "                                                                                                  \n",
      " add_689 (Add)               (None, 257, 256)             0         ['dropout_1313[0][0]',        \n",
      "                                                                     'add_688[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_704 (L  (None, 257, 256)             512       ['add_689[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_345 (  (None, 257, 256)             3155200   ['layer_normalization_704[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_704[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_690 (Add)               (None, 257, 256)             0         ['multi_head_attention_345[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_689[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_705 (L  (None, 257, 256)             512       ['add_690[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_719 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_705[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_1314 (Dropout)      (None, 257, 1024)            0         ['dense_719[0][0]']           \n",
      "                                                                                                  \n",
      " dense_720 (Dense)           (None, 257, 256)             262400    ['dropout_1314[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_1315 (Dropout)      (None, 257, 256)             0         ['dense_720[0][0]']           \n",
      "                                                                                                  \n",
      " add_691 (Add)               (None, 257, 256)             0         ['dropout_1315[0][0]',        \n",
      "                                                                     'add_690[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_706 (L  (None, 257, 256)             512       ['add_691[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_346 (  (None, 257, 256)             3155200   ['layer_normalization_706[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_706[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_692 (Add)               (None, 257, 256)             0         ['multi_head_attention_346[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_691[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_707 (L  (None, 257, 256)             512       ['add_692[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_721 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_707[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_1316 (Dropout)      (None, 257, 1024)            0         ['dense_721[0][0]']           \n",
      "                                                                                                  \n",
      " dense_722 (Dense)           (None, 257, 256)             262400    ['dropout_1316[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_1317 (Dropout)      (None, 257, 256)             0         ['dense_722[0][0]']           \n",
      "                                                                                                  \n",
      " add_693 (Add)               (None, 257, 256)             0         ['dropout_1317[0][0]',        \n",
      "                                                                     'add_692[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_708 (L  (None, 257, 256)             512       ['add_693[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_347 (  (None, 257, 256)             3155200   ['layer_normalization_708[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_708[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_694 (Add)               (None, 257, 256)             0         ['multi_head_attention_347[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_693[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_709 (L  (None, 257, 256)             512       ['add_694[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_723 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_709[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dropout_1318 (Dropout)      (None, 257, 1024)            0         ['dense_723[0][0]']           \n",
      "                                                                                                  \n",
      " dense_724 (Dense)           (None, 257, 256)             262400    ['dropout_1318[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_1319 (Dropout)      (None, 257, 256)             0         ['dense_724[0][0]']           \n",
      "                                                                                                  \n",
      " add_695 (Add)               (None, 257, 256)             0         ['dropout_1319[0][0]',        \n",
      "                                                                     'add_694[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_710 (L  (None, 257, 256)             512       ['add_695[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_348 (  (None, 257, 256)             3155200   ['layer_normalization_710[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_710[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_696 (Add)               (None, 257, 256)             0         ['multi_head_attention_348[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_695[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_711 (L  (None, 257, 256)             512       ['add_696[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_725 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_711[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_1320 (Dropout)      (None, 257, 1024)            0         ['dense_725[0][0]']           \n",
      "                                                                                                  \n",
      " dense_726 (Dense)           (None, 257, 256)             262400    ['dropout_1320[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_1321 (Dropout)      (None, 257, 256)             0         ['dense_726[0][0]']           \n",
      "                                                                                                  \n",
      " add_697 (Add)               (None, 257, 256)             0         ['dropout_1321[0][0]',        \n",
      "                                                                     'add_696[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_712 (L  (None, 257, 256)             512       ['add_697[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_349 (  (None, 257, 256)             3155200   ['layer_normalization_712[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_712[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_698 (Add)               (None, 257, 256)             0         ['multi_head_attention_349[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_697[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_713 (L  (None, 257, 256)             512       ['add_698[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_727 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_713[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_1322 (Dropout)      (None, 257, 1024)            0         ['dense_727[0][0]']           \n",
      "                                                                                                  \n",
      " dense_728 (Dense)           (None, 257, 256)             262400    ['dropout_1322[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_1323 (Dropout)      (None, 257, 256)             0         ['dense_728[0][0]']           \n",
      "                                                                                                  \n",
      " add_699 (Add)               (None, 257, 256)             0         ['dropout_1323[0][0]',        \n",
      "                                                                     'add_698[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_714 (L  (None, 257, 256)             512       ['add_699[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_350 (  (None, 257, 256)             3155200   ['layer_normalization_714[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_714[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_700 (Add)               (None, 257, 256)             0         ['multi_head_attention_350[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_699[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_715 (L  (None, 257, 256)             512       ['add_700[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_729 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_715[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_1324 (Dropout)      (None, 257, 1024)            0         ['dense_729[0][0]']           \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_730 (Dense)           (None, 257, 256)             262400    ['dropout_1324[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_1325 (Dropout)      (None, 257, 256)             0         ['dense_730[0][0]']           \n",
      "                                                                                                  \n",
      " add_701 (Add)               (None, 257, 256)             0         ['dropout_1325[0][0]',        \n",
      "                                                                     'add_700[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_716 (L  (None, 257, 256)             512       ['add_701[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_351 (  (None, 257, 256)             3155200   ['layer_normalization_716[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_716[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_702 (Add)               (None, 257, 256)             0         ['multi_head_attention_351[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_701[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_717 (L  (None, 257, 256)             512       ['add_702[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_731 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_717[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_1326 (Dropout)      (None, 257, 1024)            0         ['dense_731[0][0]']           \n",
      "                                                                                                  \n",
      " dense_732 (Dense)           (None, 257, 256)             262400    ['dropout_1326[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_1327 (Dropout)      (None, 257, 256)             0         ['dense_732[0][0]']           \n",
      "                                                                                                  \n",
      " add_703 (Add)               (None, 257, 256)             0         ['dropout_1327[0][0]',        \n",
      "                                                                     'add_702[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_718 (L  (None, 257, 256)             512       ['add_703[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_352 (  (None, 257, 256)             3155200   ['layer_normalization_718[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_718[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_704 (Add)               (None, 257, 256)             0         ['multi_head_attention_352[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_703[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_719 (L  (None, 257, 256)             512       ['add_704[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_733 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_719[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_1328 (Dropout)      (None, 257, 1024)            0         ['dense_733[0][0]']           \n",
      "                                                                                                  \n",
      " dense_734 (Dense)           (None, 257, 256)             262400    ['dropout_1328[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_1329 (Dropout)      (None, 257, 256)             0         ['dense_734[0][0]']           \n",
      "                                                                                                  \n",
      " add_705 (Add)               (None, 257, 256)             0         ['dropout_1329[0][0]',        \n",
      "                                                                     'add_704[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_720 (L  (None, 257, 256)             512       ['add_705[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_353 (  (None, 257, 256)             3155200   ['layer_normalization_720[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_720[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_706 (Add)               (None, 257, 256)             0         ['multi_head_attention_353[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_705[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_721 (L  (None, 257, 256)             512       ['add_706[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_735 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_721[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_1330 (Dropout)      (None, 257, 1024)            0         ['dense_735[0][0]']           \n",
      "                                                                                                  \n",
      " dense_736 (Dense)           (None, 257, 256)             262400    ['dropout_1330[0][0]']        \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dropout_1331 (Dropout)      (None, 257, 256)             0         ['dense_736[0][0]']           \n",
      "                                                                                                  \n",
      " add_707 (Add)               (None, 257, 256)             0         ['dropout_1331[0][0]',        \n",
      "                                                                     'add_706[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_722 (L  (None, 257, 256)             512       ['add_707[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_354 (  (None, 257, 256)             3155200   ['layer_normalization_722[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_722[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_708 (Add)               (None, 257, 256)             0         ['multi_head_attention_354[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_707[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_723 (L  (None, 257, 256)             512       ['add_708[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_737 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_723[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_1332 (Dropout)      (None, 257, 1024)            0         ['dense_737[0][0]']           \n",
      "                                                                                                  \n",
      " dense_738 (Dense)           (None, 257, 256)             262400    ['dropout_1332[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_1333 (Dropout)      (None, 257, 256)             0         ['dense_738[0][0]']           \n",
      "                                                                                                  \n",
      " add_709 (Add)               (None, 257, 256)             0         ['dropout_1333[0][0]',        \n",
      "                                                                     'add_708[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_724 (L  (None, 257, 256)             512       ['add_709[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_355 (  (None, 257, 256)             3155200   ['layer_normalization_724[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_724[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_710 (Add)               (None, 257, 256)             0         ['multi_head_attention_355[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_709[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_725 (L  (None, 257, 256)             512       ['add_710[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_739 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_725[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_1334 (Dropout)      (None, 257, 1024)            0         ['dense_739[0][0]']           \n",
      "                                                                                                  \n",
      " dense_740 (Dense)           (None, 257, 256)             262400    ['dropout_1334[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_1335 (Dropout)      (None, 257, 256)             0         ['dense_740[0][0]']           \n",
      "                                                                                                  \n",
      " add_711 (Add)               (None, 257, 256)             0         ['dropout_1335[0][0]',        \n",
      "                                                                     'add_710[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_726 (L  (None, 257, 256)             512       ['add_711[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_356 (  (None, 257, 256)             3155200   ['layer_normalization_726[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_726[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_712 (Add)               (None, 257, 256)             0         ['multi_head_attention_356[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_711[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_727 (L  (None, 257, 256)             512       ['add_712[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_741 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_727[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_1336 (Dropout)      (None, 257, 1024)            0         ['dense_741[0][0]']           \n",
      "                                                                                                  \n",
      " dense_742 (Dense)           (None, 257, 256)             262400    ['dropout_1336[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_1337 (Dropout)      (None, 257, 256)             0         ['dense_742[0][0]']           \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " add_713 (Add)               (None, 257, 256)             0         ['dropout_1337[0][0]',        \n",
      "                                                                     'add_712[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_728 (L  (None, 257, 256)             512       ['add_713[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_357 (  (None, 257, 256)             3155200   ['layer_normalization_728[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_728[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_714 (Add)               (None, 257, 256)             0         ['multi_head_attention_357[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_713[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_729 (L  (None, 257, 256)             512       ['add_714[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_743 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_729[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_1338 (Dropout)      (None, 257, 1024)            0         ['dense_743[0][0]']           \n",
      "                                                                                                  \n",
      " dense_744 (Dense)           (None, 257, 256)             262400    ['dropout_1338[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_1339 (Dropout)      (None, 257, 256)             0         ['dense_744[0][0]']           \n",
      "                                                                                                  \n",
      " add_715 (Add)               (None, 257, 256)             0         ['dropout_1339[0][0]',        \n",
      "                                                                     'add_714[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_730 (L  (None, 257, 256)             512       ['add_715[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_358 (  (None, 257, 256)             3155200   ['layer_normalization_730[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_730[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_716 (Add)               (None, 257, 256)             0         ['multi_head_attention_358[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_715[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_731 (L  (None, 257, 256)             512       ['add_716[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_745 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_731[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_1340 (Dropout)      (None, 257, 1024)            0         ['dense_745[0][0]']           \n",
      "                                                                                                  \n",
      " dense_746 (Dense)           (None, 257, 256)             262400    ['dropout_1340[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_1341 (Dropout)      (None, 257, 256)             0         ['dense_746[0][0]']           \n",
      "                                                                                                  \n",
      " add_717 (Add)               (None, 257, 256)             0         ['dropout_1341[0][0]',        \n",
      "                                                                     'add_716[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_732 (L  (None, 257, 256)             512       ['add_717[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_359 (  (None, 257, 256)             3155200   ['layer_normalization_732[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_732[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_718 (Add)               (None, 257, 256)             0         ['multi_head_attention_359[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_717[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_733 (L  (None, 257, 256)             512       ['add_718[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_747 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_733[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_1342 (Dropout)      (None, 257, 1024)            0         ['dense_747[0][0]']           \n",
      "                                                                                                  \n",
      " dense_748 (Dense)           (None, 257, 256)             262400    ['dropout_1342[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_1343 (Dropout)      (None, 257, 256)             0         ['dense_748[0][0]']           \n",
      "                                                                                                  \n",
      " add_719 (Add)               (None, 257, 256)             0         ['dropout_1343[0][0]',        \n",
      "                                                                     'add_718[0][0]']             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " layer_normalization_734 (L  (None, 257, 256)             512       ['add_719[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  (None, 256)                  0         ['layer_normalization_734[0][0\n",
      " 9 (SlicingOpLambda)                                                ]']                           \n",
      "                                                                                                  \n",
      " dense_749 (Dense)           (None, 3)                    771       ['tf.__operators__.getitem_19[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 89151235 (340.08 MB)\n",
      "Trainable params: 89151235 (340.08 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "\n",
    "class ClassToken(Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        w_init = tf.random_normal_initializer()\n",
    "        self.w = tf.Variable(\n",
    "            initial_value = w_init(shape=(1, 1, input_shape[-1]), dtype=tf.float32),\n",
    "            trainable = True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        hidden_dim = self.w.shape[-1]\n",
    "\n",
    "        cls = tf.broadcast_to(self.w, [batch_size, 1, hidden_dim])\n",
    "        cls = tf.cast(cls, dtype=inputs.dtype)\n",
    "        return cls\n",
    "\n",
    "def mlp(x, cf):\n",
    "    x = Dense(cf[\"mlp_dim\"], activation=\"gelu\")(x)\n",
    "    x = Dropout(cf[\"dropout_rate\"])(x)\n",
    "    x = Dense(cf[\"hidden_dim\"])(x)\n",
    "    x = Dropout(cf[\"dropout_rate\"])(x)\n",
    "    return x\n",
    "\n",
    "def transformer_encoder(x, cf):\n",
    "    skip_1 = x\n",
    "    x = LayerNormalization()(x)\n",
    "    x = MultiHeadAttention(\n",
    "        num_heads=cf[\"num_heads\"], key_dim=cf[\"hidden_dim\"]\n",
    "    )(x, x)\n",
    "    x = Add()([x, skip_1])\n",
    "\n",
    "    skip_2 = x\n",
    "    x = LayerNormalization()(x)\n",
    "    x = mlp(x, cf)\n",
    "    x = Add()([x, skip_2])\n",
    "\n",
    "    return x\n",
    "\n",
    "def ViT(cf):\n",
    "    \"\"\" Inputs \"\"\"\n",
    "    input_shape = (cf[\"num_patches\"], cf[\"patch_size\"]*cf[\"patch_size\"]*cf[\"num_channels\"])\n",
    "    inputs = Input(input_shape)     ## (None, 256, 3072)\n",
    "\n",
    "    \"\"\" Patch + Position Embeddings \"\"\"\n",
    "    patch_embed = Dense(cf[\"hidden_dim\"])(inputs)   ## (None, 256, 768)\n",
    "\n",
    "    positions = tf.range(start=0, limit=cf[\"num_patches\"], delta=1)\n",
    "    pos_embed = Embedding(input_dim=cf[\"num_patches\"], output_dim=cf[\"hidden_dim\"])(positions) ## (256, 768)\n",
    "    embed = patch_embed + pos_embed ## (None, 256, 768)\n",
    "\n",
    "    \"\"\" Adding Class Token \"\"\"\n",
    "    token = ClassToken()(embed)\n",
    "    x = Concatenate(axis=1)([token, embed]) ## (None, 257, 768)\n",
    "\n",
    "    for _ in range(cf[\"num_layers\"]):\n",
    "        x = transformer_encoder(x, cf)\n",
    "\n",
    "    \"\"\" Classification Head \"\"\"\n",
    "    x = LayerNormalization()(x)     ## (None, 257, 768)\n",
    "    x = x[:, 0, :]\n",
    "    x = Dense(cf[\"num_classes\"], activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs, x)\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config = {}\n",
    "    config[\"num_layers\"] = 24\n",
    "#     config[\"hidden_dim\"] = 768\n",
    "#     config[\"mlp_dim\"] =3072\n",
    "    config[\"num_heads\"] = 12\n",
    "    config[\"dropout_rate\"] = 0.1\n",
    "    config[\"num_patches\"] = 256\n",
    "    config[\"patch_size\"] = 32\n",
    "    config[\"num_channels\"] = 3\n",
    "    config[\"num_classes\"] = 3\n",
    "\n",
    "    config[\"hidden_dim\"] = 256\n",
    "    config[\"mlp_dim\"] = 1024  \n",
    "\n",
    "    model = ViT(config)\n",
    "    model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 63 - Valid: 21 - Test: 21\n",
      "Train: 63 - Valid: 21 - Test: 21\n",
      "Training for fold 1 ...\n",
      "2\n",
      "5/5 [==============================] - ETA: 0s - loss: 3.7172 - acc: 0.2985 - auc: 0.4858\n",
      "Epoch 1: val_loss improved from inf to 1.73207, saving model to files/modelN_fold1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 97s 8s/step - loss: 3.7172 - acc: 0.2985 - auc: 0.4858 - val_loss: 1.7321 - val_acc: 0.1765 - val_auc: 0.7984 - lr: 1.0000e-04\n",
      "3\n",
      "Training for fold 2 ...\n",
      "2\n",
      "5/5 [==============================] - ETA: 0s - loss: 3.1043 - acc: 0.4627 - auc: 0.6007\n",
      "Epoch 1: val_loss improved from inf to 2.17573, saving model to files/modelN_fold2.h5\n",
      "5/5 [==============================] - 96s 7s/step - loss: 3.1043 - acc: 0.4627 - auc: 0.6007 - val_loss: 2.1757 - val_acc: 0.3529 - val_auc: 0.6939 - lr: 1.0000e-04\n",
      "3\n",
      "Training for fold 3 ...\n",
      "2\n",
      "5/5 [==============================] - ETA: 0s - loss: 3.2526 - acc: 0.3881 - auc: 0.5455\n",
      "Epoch 1: val_loss improved from inf to 2.94492, saving model to files/modelN_fold3.h5\n",
      "5/5 [==============================] - 91s 7s/step - loss: 3.2526 - acc: 0.3881 - auc: 0.5455 - val_loss: 2.9449 - val_acc: 0.2941 - val_auc: 0.8074 - lr: 1.0000e-04\n",
      "3\n",
      "Training for fold 4 ...\n",
      "2\n",
      "5/5 [==============================] - ETA: 0s - loss: 3.7242 - acc: 0.2836 - auc: 0.4456\n",
      "Epoch 1: val_loss improved from inf to 3.98770, saving model to files/modelN_fold4.h5\n",
      "5/5 [==============================] - 97s 8s/step - loss: 3.7242 - acc: 0.2836 - auc: 0.4456 - val_loss: 3.9877 - val_acc: 0.2941 - val_auc: 0.6280 - lr: 1.0000e-04\n",
      "3\n",
      "Training for fold 5 ...\n",
      "2\n",
      "5/5 [==============================] - ETA: 0s - loss: 4.5292 - acc: 0.3235 - auc: 0.4822WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x7f99ca005040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 4.11598, saving model to files/modelN_fold5.h5\n",
      "5/5 [==============================] - 95s 7s/step - loss: 4.5292 - acc: 0.3235 - auc: 0.4822 - val_loss: 4.1160 - val_acc: 0.2500 - val_auc: 0.5139 - lr: 1.0000e-04\n",
      "3\n",
      "Evaluating the test set...\n",
      "2/2 [==============================] - 8s 598ms/step\n",
      "2/2 [==============================] - 11s 1s/step\n",
      "2/2 [==============================] - 9s 700ms/step\n",
      "2/2 [==============================] - 8s 643ms/step\n",
      "2/2 [==============================] - 10s 725ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Yellow_rust       0.00      0.00      0.00         7\n",
      "  Brown_rust       0.38      1.00      0.55         8\n",
      "     Healthy       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.38        21\n",
      "   macro avg       0.13      0.33      0.18        21\n",
      "weighted avg       0.15      0.38      0.21        21\n",
      "\n",
      "AUC-ROC (Yellow_rust): 0.7347\n",
      "AUC-ROC (Brown_rust): 1.0000\n",
      "AUC-ROC (Healthy): 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive/')\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from keras.metrics import AUC\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
    "from patchify import patchify\n",
    "# import tensorflow_hub as hub\n",
    "# Assuming you have already imported or defined the ViT model\n",
    "# ...\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "#from project import ViT\n",
    "hp = {\n",
    "    \"image_size\": 512,\n",
    "    \"num_channels\": 3,\n",
    "    \"patch_size\": 64,\n",
    "    \"num_classes\": 3,\n",
    "    \"class_names\": [\"Yellow_rust\",\"Brown_rust\", \"Healthy\"],\n",
    "    \"num_layers\": 24,\n",
    "    \"hidden_dim\": 256,\n",
    "    \"mlp_dim\": 1024,\n",
    "    \"num_heads\": 4,\n",
    "    \"dropout_rate\": 0.1,\n",
    "    \"batch_size\": 16,\n",
    "    \"lr\": 1e-4,\n",
    "    \"num_epochs\": 1\n",
    "}\n",
    "hp[\"num_patches\"] = (hp[\"image_size\"] ** 2) // (hp[\"patch_size\"] ** 2)\n",
    "hp[\"flat_patches_shape\"] = (hp[\"num_patches\"], hp[\"patch_size\"] * hp[\"patch_size\"] * hp[\"num_channels\"])\n",
    "\n",
    "\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "\n",
    "def load_data(path, split=0.20):\n",
    "    images = glob(os.path.join(path, \"*\", \"*.jpg\"))\n",
    "\n",
    "    # Separate images by class\n",
    "    images_class_BKL = [image for image in images if \"Yellow_rust\" in image]\n",
    "    images_class_NV = [image for image in images if \"Brown_rust\" in image]\n",
    "    images_class_MEL2 = [image for image in images if \"Healthy\" in image]\n",
    "\n",
    "    # Oversample to 33,000 to match the largest class (BKL)\n",
    "    target_size = len(images_class_BKL)\n",
    "    #print(images_class_BKL)\n",
    "    images_class_NV = np.random.choice(images_class_NV, size=target_size, replace=True).tolist()\n",
    "    images_class_MEL2 = np.random.choice(images_class_MEL2, size=target_size, replace=True).tolist()\n",
    "\n",
    "    # Concatenate lists again and shuffle\n",
    "    images = shuffle(images_class_BKL + images_class_NV + images_class_MEL2)\n",
    "\n",
    "    split_size = int(len(images) * split)\n",
    "    train_x, valid_x = train_test_split(images, test_size=split_size, random_state=42)\n",
    "    train_x, test_x = train_test_split(train_x, test_size=split_size, random_state=42)\n",
    "    print(f\"Train: {len(train_x)} - Valid: {len(valid_x)} - Test: {len(test_x)}\")\n",
    "\n",
    "    return train_x, valid_x, test_x\n",
    "\n",
    "\n",
    "def process_image_label(path):\n",
    "    path = path.decode()\n",
    "    image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (hp[\"image_size\"], hp[\"image_size\"]))\n",
    "    image = image / 255.0\n",
    "\n",
    "    patch_shape = (hp[\"patch_size\"], hp[\"patch_size\"], hp[\"num_channels\"])\n",
    "    patches = patchify(image, patch_shape, hp[\"patch_size\"])\n",
    "    patches = np.reshape(patches, hp[\"flat_patches_shape\"])\n",
    "    patches = patches.astype(np.float32)\n",
    "\n",
    "    class_name = path.split(\"/\")[-2]\n",
    "    class_idx = hp[\"class_names\"].index(class_name)\n",
    "    class_idx = np.array(class_idx, dtype=np.int32)\n",
    "    return patches, class_idx\n",
    "\n",
    "\n",
    "def parse(path):\n",
    "    patches, labels = tf.numpy_function(process_image_label, [path], [tf.float32, tf.int32])\n",
    "    labels = tf.one_hot(labels, hp[\"num_classes\"])\n",
    "\n",
    "    patches.set_shape(hp[\"flat_patches_shape\"])\n",
    "    labels.set_shape(hp[\"num_classes\"])\n",
    "\n",
    "    return patches, labels\n",
    "\n",
    "\n",
    "def tf_dataset(images, batch=32):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((images))\n",
    "    ds = ds.map(parse).batch(batch).prefetch(8)\n",
    "    return ds\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    model = ViT(hp)\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        optimizer=tf.keras.optimizers.Adam(hp[\"lr\"], clipvalue=1.0),\n",
    "        metrics=[\"acc\", AUC(name='auc', multi_label=True)]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_dir(\"files\")\n",
    "    dataset_path = '/home/ali/Music/PYTHON/DS'\n",
    "    model_path = os.path.join(\"files\", \"model3.h5\")\n",
    "    csv_path = os.path.join(\"files\", \"log2.csv\")\n",
    "    train_x, valid_x, test_x = load_data(dataset_path)\n",
    "    images = train_x + valid_x\n",
    "    print(f\"Train: {len(train_x)} - Valid: {len(valid_x)} - Test: {len(test_x)}\")\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    fold_no = 1\n",
    "\n",
    "    for train, val in kfold.split(images):\n",
    "        print(f'Training for fold {fold_no} ...')\n",
    "        train_ds = tf_dataset(np.array(images)[train], batch=hp[\"batch_size\"])\n",
    "        valid_ds = tf_dataset(np.array(images)[val], batch=hp[\"batch_size\"])\n",
    "        model = get_model()\n",
    "        callbacks = [\n",
    "            ModelCheckpoint(f\"files/modelN_fold{fold_no}.h5\", monitor='val_loss', verbose=1, save_best_only=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, min_lr=1e-10, verbose=1),\n",
    "            CSVLogger(f\"files/log2_fold{fold_no}.csv\"),\n",
    "            EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=False),\n",
    "        ]\n",
    "        print(2)\n",
    "        model.fit(train_ds, epochs=hp[\"num_epochs\"], validation_data=valid_ds, callbacks=callbacks)\n",
    "        fold_no += 1\n",
    "        print(3)\n",
    "\n",
    "    # Evaluating on the test set\n",
    "    print(\"Evaluating the test set...\")\n",
    "    test_ds = tf_dataset(test_x, batch=hp[\"batch_size\"])\n",
    "    all_preds = []\n",
    "    custom_objects = {\"ClassToken\": ClassToken}\n",
    "    for fold_no in range(1, 6):\n",
    "        with tf.keras.utils.custom_object_scope(custom_objects):\n",
    "            fold_model = tf.keras.models.load_model(f\"files/modelN_fold{fold_no}.h5\")\n",
    "        y_pred_probs = fold_model.predict(test_ds)\n",
    "        all_preds.append(y_pred_probs)\n",
    "\n",
    "    avg_preds = np.mean(all_preds, axis=0)\n",
    "    final_preds = np.argmax(avg_preds, axis=1)\n",
    "    y_true = [hp[\"class_names\"].index(img.split(\"/\")[-2]) for img in test_x]\n",
    "    print(classification_report(y_true, final_preds, target_names=hp[\"class_names\"]))\n",
    "    roc_aucs = []\n",
    "\n",
    "    for i, class_name in enumerate(hp[\"class_names\"]):\n",
    "        auc_val = roc_auc_score((np.array(y_true) == i).astype(int), avg_preds[:, i])\n",
    "        roc_aucs.append(auc_val)\n",
    "        print(f\"AUC-ROC ({class_name}): {auc_val:.4f}\")\n",
    "\n",
    "    for i, class_name in enumerate(hp[\"class_names\"]):\n",
    "        fpr, tpr, _ = roc_curve((np.array(y_true) == i).astype(int), avg_preds[:, i])\n",
    "        plt.plot(fpr, tpr, label=f\"{class_name} (AUC = {roc_aucs[i]:.2f})\")\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], color='grey', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 2083 - Valid: 694 - Test: 694\n",
      "Train: 2083 - Valid: 694 - Test: 694\n",
      "Training for fold 1 ...\n",
      "2\n",
      "139/139 [==============================] - ETA: 0s - loss: 1.2528 - acc: 0.3679 - auc: 0.5354\n",
      "Epoch 1: val_loss improved from inf to 1.17410, saving model to files/modelN_fold1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/139 [==============================] - 1017s 7s/step - loss: 1.2528 - acc: 0.3679 - auc: 0.5354 - val_loss: 1.1741 - val_acc: 0.3129 - val_auc: 0.7422 - lr: 1.0000e-04\n",
      "3\n",
      "Training for fold 2 ...\n",
      "2\n",
      "139/139 [==============================] - ETA: 0s - loss: 1.2627 - acc: 0.3543 - auc: 0.5284\n",
      "Epoch 1: val_loss improved from inf to 1.02183, saving model to files/modelN_fold2.h5\n",
      "139/139 [==============================] - 1017s 7s/step - loss: 1.2627 - acc: 0.3543 - auc: 0.5284 - val_loss: 1.0218 - val_acc: 0.4227 - val_auc: 0.7840 - lr: 1.0000e-04\n",
      "3\n",
      "Training for fold 3 ...\n",
      "2\n",
      "139/139 [==============================] - ETA: 0s - loss: 1.1983 - acc: 0.3947 - auc: 0.5605\n",
      "Epoch 1: val_loss improved from inf to 0.81027, saving model to files/modelN_fold3.h5\n",
      "139/139 [==============================] - 1013s 7s/step - loss: 1.1983 - acc: 0.3947 - auc: 0.5605 - val_loss: 0.8103 - val_acc: 0.6450 - val_auc: 0.8551 - lr: 1.0000e-04\n",
      "3\n",
      "Training for fold 4 ...\n",
      "2\n",
      "139/139 [==============================] - ETA: 0s - loss: 1.3360 - acc: 0.3564 - auc: 0.5151\n",
      "Epoch 1: val_loss improved from inf to 1.11063, saving model to files/modelN_fold4.h5\n",
      "139/139 [==============================] - 1011s 7s/step - loss: 1.3360 - acc: 0.3564 - auc: 0.5151 - val_loss: 1.1106 - val_acc: 0.3351 - val_auc: 0.7006 - lr: 1.0000e-04\n",
      "3\n",
      "Training for fold 5 ...\n",
      "2\n",
      "139/139 [==============================] - ETA: 0s - loss: 1.3605 - acc: 0.3425 - auc: 0.5064\n",
      "Epoch 1: val_loss improved from inf to 1.07331, saving model to files/modelN_fold5.h5\n",
      "139/139 [==============================] - 1015s 7s/step - loss: 1.3605 - acc: 0.3425 - auc: 0.5064 - val_loss: 1.0733 - val_acc: 0.4577 - val_auc: 0.6791 - lr: 1.0000e-04\n",
      "3\n",
      "Evaluating the test set...\n",
      "44/44 [==============================] - 94s 2s/step\n",
      "44/44 [==============================] - 94s 2s/step\n",
      "44/44 [==============================] - 105s 2s/step\n",
      "44/44 [==============================] - 100s 2s/step\n",
      "44/44 [==============================] - 94s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " Yellow_rust       0.00      0.00      0.00       218\n",
      "  Brown_rust       0.95      0.41      0.57       218\n",
      "     Healthy       0.43      1.00      0.60       258\n",
      "\n",
      "    accuracy                           0.50       694\n",
      "   macro avg       0.46      0.47      0.39       694\n",
      "weighted avg       0.46      0.50      0.40       694\n",
      "\n",
      "AUC-ROC (Yellow_rust): 0.8322\n",
      "AUC-ROC (Brown_rust): 0.8680\n",
      "AUC-ROC (Healthy): 0.8785\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive/')\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from keras.metrics import AUC\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
    "from patchify import patchify\n",
    "# import tensorflow_hub as hub\n",
    "# Assuming you have already imported or defined the ViT model\n",
    "# ...\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "#from project import ViT\n",
    "hp = {\n",
    "    \"image_size\": 512,\n",
    "    \"num_channels\": 3,\n",
    "    \"patch_size\": 64,\n",
    "    \"num_classes\": 3,\n",
    "    \"class_names\": [\"Yellow_rust\",\"Brown_rust\", \"Healthy\"],\n",
    "    \"num_layers\": 24,\n",
    "    \"hidden_dim\": 256,\n",
    "    \"mlp_dim\": 1024,\n",
    "    \"num_heads\": 4,\n",
    "    \"dropout_rate\": 0.1,\n",
    "    \"batch_size\": 16,\n",
    "    \"lr\": 1e-4,\n",
    "    \"num_epochs\": 1\n",
    "}\n",
    "hp[\"num_patches\"] = (hp[\"image_size\"] ** 2) // (hp[\"patch_size\"] ** 2)\n",
    "hp[\"flat_patches_shape\"] = (hp[\"num_patches\"], hp[\"patch_size\"] * hp[\"patch_size\"] * hp[\"num_channels\"])\n",
    "\n",
    "\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "\n",
    "def load_data(path, split=0.20):\n",
    "    images = glob(os.path.join(path, \"*\", \"*.jpg\"))\n",
    "\n",
    "    # Separate images by class\n",
    "    images_class_BKL = [image for image in images if \"Yellow_rust\" in image]\n",
    "    images_class_NV = [image for image in images if \"Brown_rust\" in image]\n",
    "    images_class_MEL2 = [image for image in images if \"Healthy\" in image]\n",
    "\n",
    "    # Oversample to 33,000 to match the largest class (BKL)\n",
    "    target_size = len(images_class_BKL)\n",
    "    #print(images_class_BKL)\n",
    "    images_class_NV = np.random.choice(images_class_NV, size=target_size, replace=True).tolist()\n",
    "    images_class_MEL2 = np.random.choice(images_class_MEL2, size=target_size, replace=True).tolist()\n",
    "\n",
    "    # Concatenate lists again and shuffle\n",
    "    images = shuffle(images_class_BKL + images_class_NV + images_class_MEL2)\n",
    "\n",
    "    split_size = int(len(images) * split)\n",
    "    train_x, valid_x = train_test_split(images, test_size=split_size, random_state=42)\n",
    "    train_x, test_x = train_test_split(train_x, test_size=split_size, random_state=42)\n",
    "    print(f\"Train: {len(train_x)} - Valid: {len(valid_x)} - Test: {len(test_x)}\")\n",
    "\n",
    "    return train_x, valid_x, test_x\n",
    "\n",
    "\n",
    "def process_image_label(path):\n",
    "    path = path.decode()\n",
    "    image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (hp[\"image_size\"], hp[\"image_size\"]))\n",
    "    image = image / 255.0\n",
    "\n",
    "    patch_shape = (hp[\"patch_size\"], hp[\"patch_size\"], hp[\"num_channels\"])\n",
    "    patches = patchify(image, patch_shape, hp[\"patch_size\"])\n",
    "    patches = np.reshape(patches, hp[\"flat_patches_shape\"])\n",
    "    patches = patches.astype(np.float32)\n",
    "\n",
    "    class_name = path.split(\"/\")[-2]\n",
    "    class_idx = hp[\"class_names\"].index(class_name)\n",
    "    class_idx = np.array(class_idx, dtype=np.int32)\n",
    "    return patches, class_idx\n",
    "\n",
    "\n",
    "def parse(path):\n",
    "    patches, labels = tf.numpy_function(process_image_label, [path], [tf.float32, tf.int32])\n",
    "    labels = tf.one_hot(labels, hp[\"num_classes\"])\n",
    "\n",
    "    patches.set_shape(hp[\"flat_patches_shape\"])\n",
    "    labels.set_shape(hp[\"num_classes\"])\n",
    "\n",
    "    return patches, labels\n",
    "\n",
    "\n",
    "def tf_dataset(images, batch=32):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((images))\n",
    "    ds = ds.map(parse).batch(batch).prefetch(8)\n",
    "    return ds\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    model = ViT(hp)\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        optimizer=tf.keras.optimizers.Adam(hp[\"lr\"], clipvalue=1.0),\n",
    "        metrics=[\"acc\", AUC(name='auc', multi_label=True)]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_dir(\"files\")\n",
    "    dataset_path = '/home/ali/Music/PYTHON/WholeDataset'\n",
    "    model_path = os.path.join(\"files\", \"model3.h5\")\n",
    "    csv_path = os.path.join(\"files\", \"log2.csv\")\n",
    "    train_x, valid_x, test_x = load_data(dataset_path)\n",
    "    images = train_x + valid_x\n",
    "    print(f\"Train: {len(train_x)} - Valid: {len(valid_x)} - Test: {len(test_x)}\")\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    fold_no = 1\n",
    "\n",
    "    for train, val in kfold.split(images):\n",
    "        print(f'Training for fold {fold_no} ...')\n",
    "        train_ds = tf_dataset(np.array(images)[train], batch=hp[\"batch_size\"])\n",
    "        valid_ds = tf_dataset(np.array(images)[val], batch=hp[\"batch_size\"])\n",
    "        model = get_model()\n",
    "        callbacks = [\n",
    "            ModelCheckpoint(f\"files/modelN_fold{fold_no}.h5\", monitor='val_loss', verbose=1, save_best_only=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, min_lr=1e-10, verbose=1),\n",
    "            CSVLogger(f\"files/log2_fold{fold_no}.csv\"),\n",
    "            EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=False),\n",
    "        ]\n",
    "        print(2)\n",
    "        model.fit(train_ds, epochs=hp[\"num_epochs\"], validation_data=valid_ds, callbacks=callbacks)\n",
    "        fold_no += 1\n",
    "        print(3)\n",
    "\n",
    "    # Evaluating on the test set\n",
    "    print(\"Evaluating the test set...\")\n",
    "    test_ds = tf_dataset(test_x, batch=hp[\"batch_size\"])\n",
    "    all_preds = []\n",
    "    custom_objects = {\"ClassToken\": ClassToken}\n",
    "    for fold_no in range(1, 6):\n",
    "        with tf.keras.utils.custom_object_scope(custom_objects):\n",
    "            fold_model = tf.keras.models.load_model(f\"files/modelN_fold{fold_no}.h5\")\n",
    "        y_pred_probs = fold_model.predict(test_ds)\n",
    "        all_preds.append(y_pred_probs)\n",
    "\n",
    "    avg_preds = np.mean(all_preds, axis=0)\n",
    "    final_preds = np.argmax(avg_preds, axis=1)\n",
    "    y_true = [hp[\"class_names\"].index(img.split(\"/\")[-2]) for img in test_x]\n",
    "    print(classification_report(y_true, final_preds, target_names=hp[\"class_names\"]))\n",
    "    roc_aucs = []\n",
    "\n",
    "    for i, class_name in enumerate(hp[\"class_names\"]):\n",
    "        auc_val = roc_auc_score((np.array(y_true) == i).astype(int), avg_preds[:, i])\n",
    "        roc_aucs.append(auc_val)\n",
    "        print(f\"AUC-ROC ({class_name}): {auc_val:.4f}\")\n",
    "\n",
    "    for i, class_name in enumerate(hp[\"class_names\"]):\n",
    "        fpr, tpr, _ = roc_curve((np.array(y_true) == i).astype(int), avg_preds[:, i])\n",
    "        plt.plot(fpr, tpr, label=f\"{class_name} (AUC = {roc_aucs[i]:.2f})\")\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], color='grey', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 2083 - Valid: 694 - Test: 694\n",
      "Train: 2083 - Valid: 694 - Test: 694\n",
      "Training for fold 1 ...\n",
      "2\n",
      "Epoch 1/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 1.2986 - acc: 0.3516 - auc: 0.5258\n",
      "Epoch 1: val_loss improved from inf to 1.06386, saving model to files/modelN_fold1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/139 [==============================] - 1005s 7s/step - loss: 1.2986 - acc: 0.3516 - auc: 0.5258 - val_loss: 1.0639 - val_acc: 0.4065 - val_auc: 0.6795 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.9857 - acc: 0.4840 - auc: 0.6872\n",
      "Epoch 2: val_loss improved from 1.06386 to 0.82759, saving model to files/modelN_fold1.h5\n",
      "139/139 [==============================] - 979s 7s/step - loss: 0.9857 - acc: 0.4840 - auc: 0.6872 - val_loss: 0.8276 - val_acc: 0.5252 - val_auc: 0.8448 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.7221 - acc: 0.6749 - auc: 0.8477\n",
      "Epoch 3: val_loss improved from 0.82759 to 0.51293, saving model to files/modelN_fold1.h5\n",
      "139/139 [==============================] - 977s 7s/step - loss: 0.7221 - acc: 0.6749 - auc: 0.8477 - val_loss: 0.5129 - val_acc: 0.8129 - val_auc: 0.9376 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.5523 - acc: 0.7789 - auc: 0.9163\n",
      "Epoch 4: val_loss improved from 0.51293 to 0.33273, saving model to files/modelN_fold1.h5\n",
      "139/139 [==============================] - 976s 7s/step - loss: 0.5523 - acc: 0.7789 - auc: 0.9163 - val_loss: 0.3327 - val_acc: 0.8795 - val_auc: 0.9737 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.3745 - acc: 0.8523 - auc: 0.9610\n",
      "Epoch 5: val_loss did not improve from 0.33273\n",
      "139/139 [==============================] - 946s 7s/step - loss: 0.3745 - acc: 0.8523 - auc: 0.9610 - val_loss: 0.4386 - val_acc: 0.8201 - val_auc: 0.9793 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.2772 - acc: 0.8946 - auc: 0.9780\n",
      "Epoch 6: val_loss did not improve from 0.33273\n",
      "139/139 [==============================] - 957s 7s/step - loss: 0.2772 - acc: 0.8946 - auc: 0.9780 - val_loss: 0.3434 - val_acc: 0.8723 - val_auc: 0.9739 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.2361 - acc: 0.9154 - auc: 0.9842\n",
      "Epoch 7: val_loss improved from 0.33273 to 0.23691, saving model to files/modelN_fold1.h5\n",
      "139/139 [==============================] - 966s 7s/step - loss: 0.2361 - acc: 0.9154 - auc: 0.9842 - val_loss: 0.2369 - val_acc: 0.8975 - val_auc: 0.9876 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.1966 - acc: 0.9266 - auc: 0.9888\n",
      "Epoch 8: val_loss did not improve from 0.23691\n",
      "139/139 [==============================] - 950s 7s/step - loss: 0.1966 - acc: 0.9266 - auc: 0.9888 - val_loss: 0.2394 - val_acc: 0.9011 - val_auc: 0.9895 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.1603 - acc: 0.9415 - auc: 0.9925\n",
      "Epoch 9: val_loss improved from 0.23691 to 0.12343, saving model to files/modelN_fold1.h5\n",
      "139/139 [==============================] - 960s 7s/step - loss: 0.1603 - acc: 0.9415 - auc: 0.9925 - val_loss: 0.1234 - val_acc: 0.9550 - val_auc: 0.9952 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.1234 - acc: 0.9563 - auc: 0.9955\n",
      "Epoch 10: val_loss did not improve from 0.12343\n",
      "139/139 [==============================] - 949s 7s/step - loss: 0.1234 - acc: 0.9563 - auc: 0.9955 - val_loss: 0.1684 - val_acc: 0.9371 - val_auc: 0.9952 - lr: 1.0000e-04\n",
      "3\n",
      "Training for fold 2 ...\n",
      "2\n",
      "Epoch 1/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 1.1498 - acc: 0.4277 - auc: 0.6076\n",
      "Epoch 1: val_loss improved from inf to 0.85749, saving model to files/modelN_fold2.h5\n",
      "139/139 [==============================] - 1061s 7s/step - loss: 1.1498 - acc: 0.4277 - auc: 0.6076 - val_loss: 0.8575 - val_acc: 0.5522 - val_auc: 0.8489 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.7403 - acc: 0.6677 - auc: 0.8397\n",
      "Epoch 2: val_loss improved from 0.85749 to 0.55397, saving model to files/modelN_fold2.h5\n",
      "139/139 [==============================] - 1008s 7s/step - loss: 0.7403 - acc: 0.6677 - auc: 0.8397 - val_loss: 0.5540 - val_acc: 0.7770 - val_auc: 0.9260 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.5457 - acc: 0.7771 - auc: 0.9170\n",
      "Epoch 3: val_loss improved from 0.55397 to 0.31216, saving model to files/modelN_fold2.h5\n",
      "139/139 [==============================] - 963s 7s/step - loss: 0.5457 - acc: 0.7771 - auc: 0.9170 - val_loss: 0.3122 - val_acc: 0.8831 - val_auc: 0.9709 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.3561 - acc: 0.8640 - auc: 0.9635\n",
      "Epoch 4: val_loss did not improve from 0.31216\n",
      "139/139 [==============================] - 947s 7s/step - loss: 0.3561 - acc: 0.8640 - auc: 0.9635 - val_loss: 0.3640 - val_acc: 0.8489 - val_auc: 0.9755 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.2818 - acc: 0.8946 - auc: 0.9759\n",
      "Epoch 5: val_loss improved from 0.31216 to 0.21773, saving model to files/modelN_fold2.h5\n",
      "139/139 [==============================] - 959s 7s/step - loss: 0.2818 - acc: 0.8946 - auc: 0.9759 - val_loss: 0.2177 - val_acc: 0.9083 - val_auc: 0.9877 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.2171 - acc: 0.9176 - auc: 0.9856\n",
      "Epoch 6: val_loss did not improve from 0.21773\n",
      "139/139 [==============================] - 941s 7s/step - loss: 0.2171 - acc: 0.9176 - auc: 0.9856 - val_loss: 0.2199 - val_acc: 0.9173 - val_auc: 0.9897 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.2010 - acc: 0.9253 - auc: 0.9885\n",
      "Epoch 7: val_loss did not improve from 0.21773\n",
      "139/139 [==============================] - 945s 7s/step - loss: 0.2010 - acc: 0.9253 - auc: 0.9885 - val_loss: 0.2280 - val_acc: 0.9083 - val_auc: 0.9872 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.1765 - acc: 0.9329 - auc: 0.9911\n",
      "Epoch 8: val_loss did not improve from 0.21773\n",
      "139/139 [==============================] - 944s 7s/step - loss: 0.1765 - acc: 0.9329 - auc: 0.9911 - val_loss: 0.5310 - val_acc: 0.8165 - val_auc: 0.9784 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.1573 - acc: 0.9433 - auc: 0.9921\n",
      "Epoch 9: val_loss improved from 0.21773 to 0.21407, saving model to files/modelN_fold2.h5\n",
      "139/139 [==============================] - 976s 7s/step - loss: 0.1573 - acc: 0.9433 - auc: 0.9921 - val_loss: 0.2141 - val_acc: 0.9263 - val_auc: 0.9921 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.1142 - acc: 0.9608 - auc: 0.9956\n",
      "Epoch 10: val_loss did not improve from 0.21407\n",
      "139/139 [==============================] - 951s 7s/step - loss: 0.1142 - acc: 0.9608 - auc: 0.9956 - val_loss: 0.3000 - val_acc: 0.9083 - val_auc: 0.9868 - lr: 1.0000e-04\n",
      "3\n",
      "Training for fold 3 ...\n",
      "2\n",
      "Epoch 1/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 1.2348 - acc: 0.3713 - auc: 0.5523\n",
      "Epoch 1: val_loss improved from inf to 1.05158, saving model to files/modelN_fold3.h5\n",
      "139/139 [==============================] - 1021s 7s/step - loss: 1.2348 - acc: 0.3713 - auc: 0.5523 - val_loss: 1.0516 - val_acc: 0.3658 - val_auc: 0.8349 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.8709 - acc: 0.5909 - auc: 0.7711\n",
      "Epoch 2: val_loss improved from 1.05158 to 0.79980, saving model to files/modelN_fold3.h5\n",
      "139/139 [==============================] - 962s 7s/step - loss: 0.8709 - acc: 0.5909 - auc: 0.7711 - val_loss: 0.7998 - val_acc: 0.5514 - val_auc: 0.8946 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.6814 - acc: 0.7012 - auc: 0.8662\n",
      "Epoch 3: val_loss improved from 0.79980 to 0.57312, saving model to files/modelN_fold3.h5\n",
      "139/139 [==============================] - 964s 7s/step - loss: 0.6814 - acc: 0.7012 - auc: 0.8662 - val_loss: 0.5731 - val_acc: 0.7658 - val_auc: 0.9269 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.5691 - acc: 0.7651 - auc: 0.9105\n",
      "Epoch 4: val_loss improved from 0.57312 to 0.35833, saving model to files/modelN_fold3.h5\n",
      "139/139 [==============================] - 978s 7s/step - loss: 0.5691 - acc: 0.7651 - auc: 0.9105 - val_loss: 0.3583 - val_acc: 0.8721 - val_auc: 0.9756 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.3131 - acc: 0.8870 - auc: 0.9717\n",
      "Epoch 5: val_loss improved from 0.35833 to 0.33927, saving model to files/modelN_fold3.h5\n",
      "139/139 [==============================] - 949s 7s/step - loss: 0.3131 - acc: 0.8870 - auc: 0.9717 - val_loss: 0.3393 - val_acc: 0.8559 - val_auc: 0.9818 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.2698 - acc: 0.9001 - auc: 0.9793\n",
      "Epoch 6: val_loss improved from 0.33927 to 0.20299, saving model to files/modelN_fold3.h5\n",
      "139/139 [==============================] - 957s 7s/step - loss: 0.2698 - acc: 0.9001 - auc: 0.9793 - val_loss: 0.2030 - val_acc: 0.9153 - val_auc: 0.9904 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.1952 - acc: 0.9329 - auc: 0.9885\n",
      "Epoch 7: val_loss improved from 0.20299 to 0.19675, saving model to files/modelN_fold3.h5\n",
      "139/139 [==============================] - 976s 7s/step - loss: 0.1952 - acc: 0.9329 - auc: 0.9885 - val_loss: 0.1967 - val_acc: 0.9261 - val_auc: 0.9914 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.1721 - acc: 0.9419 - auc: 0.9911\n",
      "Epoch 8: val_loss improved from 0.19675 to 0.12779, saving model to files/modelN_fold3.h5\n",
      "139/139 [==============================] - 958s 7s/step - loss: 0.1721 - acc: 0.9419 - auc: 0.9911 - val_loss: 0.1278 - val_acc: 0.9604 - val_auc: 0.9947 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.1535 - acc: 0.9478 - auc: 0.9920\n",
      "Epoch 9: val_loss did not improve from 0.12779\n",
      "139/139 [==============================] - 944s 7s/step - loss: 0.1535 - acc: 0.9478 - auc: 0.9920 - val_loss: 0.2854 - val_acc: 0.9081 - val_auc: 0.9878 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.1360 - acc: 0.9487 - auc: 0.9943\n",
      "Epoch 10: val_loss did not improve from 0.12779\n",
      "139/139 [==============================] - 954s 7s/step - loss: 0.1360 - acc: 0.9487 - auc: 0.9943 - val_loss: 0.1992 - val_acc: 0.9279 - val_auc: 0.9914 - lr: 1.0000e-04\n",
      "3\n",
      "Training for fold 4 ...\n",
      "2\n",
      "Epoch 1/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 1.2190 - acc: 0.3812 - auc: 0.5528\n",
      "Epoch 1: val_loss improved from inf to 0.93046, saving model to files/modelN_fold4.h5\n",
      "139/139 [==============================] - 1022s 7s/step - loss: 1.2190 - acc: 0.3812 - auc: 0.5528 - val_loss: 0.9305 - val_acc: 0.6198 - val_auc: 0.8170 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.8227 - acc: 0.6278 - auc: 0.7987\n",
      "Epoch 2: val_loss improved from 0.93046 to 0.67027, saving model to files/modelN_fold4.h5\n",
      "139/139 [==============================] - 955s 7s/step - loss: 0.8227 - acc: 0.6278 - auc: 0.7987 - val_loss: 0.6703 - val_acc: 0.7369 - val_auc: 0.8970 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.5917 - acc: 0.7511 - auc: 0.9051\n",
      "Epoch 3: val_loss did not improve from 0.67027\n",
      "139/139 [==============================] - 952s 7s/step - loss: 0.5917 - acc: 0.7511 - auc: 0.9051 - val_loss: 0.7837 - val_acc: 0.6793 - val_auc: 0.9415 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.3752 - acc: 0.8519 - auc: 0.9600\n",
      "Epoch 4: val_loss improved from 0.67027 to 0.63658, saving model to files/modelN_fold4.h5\n",
      "139/139 [==============================] - 978s 7s/step - loss: 0.3752 - acc: 0.8519 - auc: 0.9600 - val_loss: 0.6366 - val_acc: 0.7279 - val_auc: 0.9622 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.2635 - acc: 0.9032 - auc: 0.9798\n",
      "Epoch 5: val_loss improved from 0.63658 to 0.44283, saving model to files/modelN_fold4.h5\n",
      "139/139 [==============================] - 963s 7s/step - loss: 0.2635 - acc: 0.9032 - auc: 0.9798 - val_loss: 0.4428 - val_acc: 0.8306 - val_auc: 0.9789 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.2221 - acc: 0.9221 - auc: 0.9850\n",
      "Epoch 6: val_loss improved from 0.44283 to 0.19343, saving model to files/modelN_fold4.h5\n",
      "139/139 [==============================] - 989s 7s/step - loss: 0.2221 - acc: 0.9221 - auc: 0.9850 - val_loss: 0.1934 - val_acc: 0.9279 - val_auc: 0.9909 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.1944 - acc: 0.9262 - auc: 0.9880\n",
      "Epoch 7: val_loss improved from 0.19343 to 0.15984, saving model to files/modelN_fold4.h5\n",
      "139/139 [==============================] - 958s 7s/step - loss: 0.1944 - acc: 0.9262 - auc: 0.9880 - val_loss: 0.1598 - val_acc: 0.9423 - val_auc: 0.9946 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.1626 - acc: 0.9383 - auc: 0.9914\n",
      "Epoch 8: val_loss did not improve from 0.15984\n",
      "139/139 [==============================] - 942s 7s/step - loss: 0.1626 - acc: 0.9383 - auc: 0.9914 - val_loss: 0.1636 - val_acc: 0.9387 - val_auc: 0.9936 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.1461 - acc: 0.9505 - auc: 0.9931\n",
      "Epoch 9: val_loss improved from 0.15984 to 0.12403, saving model to files/modelN_fold4.h5\n",
      "139/139 [==============================] - 953s 7s/step - loss: 0.1461 - acc: 0.9505 - auc: 0.9931 - val_loss: 0.1240 - val_acc: 0.9459 - val_auc: 0.9964 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.1629 - acc: 0.9415 - auc: 0.9918\n",
      "Epoch 10: val_loss did not improve from 0.12403\n",
      "139/139 [==============================] - 943s 7s/step - loss: 0.1629 - acc: 0.9415 - auc: 0.9918 - val_loss: 0.1700 - val_acc: 0.9405 - val_auc: 0.9934 - lr: 1.0000e-04\n",
      "3\n",
      "Training for fold 5 ...\n",
      "2\n",
      "Epoch 1/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 1.0855 - acc: 0.4766 - auc: 0.6652\n",
      "Epoch 1: val_loss improved from inf to 0.78267, saving model to files/modelN_fold5.h5\n",
      "139/139 [==============================] - 1011s 7s/step - loss: 1.0855 - acc: 0.4766 - auc: 0.6652 - val_loss: 0.7827 - val_acc: 0.5784 - val_auc: 0.8595 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.7696 - acc: 0.6517 - auc: 0.8272\n",
      "Epoch 2: val_loss improved from 0.78267 to 0.58391, saving model to files/modelN_fold5.h5\n",
      "139/139 [==============================] - 947s 7s/step - loss: 0.7696 - acc: 0.6517 - auc: 0.8272 - val_loss: 0.5839 - val_acc: 0.7640 - val_auc: 0.9205 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.5764 - acc: 0.7705 - auc: 0.9091\n",
      "Epoch 3: val_loss improved from 0.58391 to 0.34812, saving model to files/modelN_fold5.h5\n",
      "139/139 [==============================] - 969s 7s/step - loss: 0.5764 - acc: 0.7705 - auc: 0.9091 - val_loss: 0.3481 - val_acc: 0.8613 - val_auc: 0.9707 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.3487 - acc: 0.8600 - auc: 0.9656\n",
      "Epoch 4: val_loss improved from 0.34812 to 0.33618, saving model to files/modelN_fold5.h5\n",
      "139/139 [==============================] - 945s 7s/step - loss: 0.3487 - acc: 0.8600 - auc: 0.9656 - val_loss: 0.3362 - val_acc: 0.8721 - val_auc: 0.9814 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.2470 - acc: 0.9068 - auc: 0.9821\n",
      "Epoch 5: val_loss improved from 0.33618 to 0.21202, saving model to files/modelN_fold5.h5\n",
      "139/139 [==============================] - 960s 7s/step - loss: 0.2470 - acc: 0.9068 - auc: 0.9821 - val_loss: 0.2120 - val_acc: 0.9279 - val_auc: 0.9883 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.2161 - acc: 0.9203 - auc: 0.9859\n",
      "Epoch 6: val_loss did not improve from 0.21202\n",
      "139/139 [==============================] - 953s 7s/step - loss: 0.2161 - acc: 0.9203 - auc: 0.9859 - val_loss: 0.2470 - val_acc: 0.8919 - val_auc: 0.9894 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.1728 - acc: 0.9383 - auc: 0.9911\n",
      "Epoch 7: val_loss did not improve from 0.21202\n",
      "139/139 [==============================] - 940s 7s/step - loss: 0.1728 - acc: 0.9383 - auc: 0.9911 - val_loss: 0.2945 - val_acc: 0.8793 - val_auc: 0.9783 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.1535 - acc: 0.9424 - auc: 0.9927\n",
      "Epoch 8: val_loss did not improve from 0.21202\n",
      "139/139 [==============================] - 954s 7s/step - loss: 0.1535 - acc: 0.9424 - auc: 0.9927 - val_loss: 0.3045 - val_acc: 0.8847 - val_auc: 0.9798 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.1440 - acc: 0.9482 - auc: 0.9934\n",
      "Epoch 9: val_loss did not improve from 0.21202\n",
      "139/139 [==============================] - 953s 7s/step - loss: 0.1440 - acc: 0.9482 - auc: 0.9934 - val_loss: 0.3010 - val_acc: 0.8937 - val_auc: 0.9855 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "139/139 [==============================] - ETA: 0s - loss: 0.1288 - acc: 0.9482 - auc: 0.9948\n",
      "Epoch 10: val_loss did not improve from 0.21202\n",
      "139/139 [==============================] - 938s 7s/step - loss: 0.1288 - acc: 0.9482 - auc: 0.9948 - val_loss: 0.6028 - val_acc: 0.8468 - val_auc: 0.9706 - lr: 1.0000e-04\n",
      "3\n",
      "Evaluating the test set...\n",
      "44/44 [==============================] - 95s 2s/step\n",
      "44/44 [==============================] - 91s 2s/step\n",
      "44/44 [==============================] - 97s 2s/step\n",
      "44/44 [==============================] - 95s 2s/step\n",
      "44/44 [==============================] - 93s 2s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Yellow_rust       0.95      0.98      0.97       233\n",
      "  Brown_rust       0.97      0.93      0.95       239\n",
      "     Healthy       0.96      0.98      0.97       222\n",
      "\n",
      "    accuracy                           0.96       694\n",
      "   macro avg       0.96      0.96      0.96       694\n",
      "weighted avg       0.96      0.96      0.96       694\n",
      "\n",
      "AUC-ROC (Yellow_rust): 0.9987\n",
      "AUC-ROC (Brown_rust): 0.9964\n",
      "AUC-ROC (Healthy): 0.9981\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive/')\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from keras.metrics import AUC\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
    "from patchify import patchify\n",
    "# import tensorflow_hub as hub\n",
    "# Assuming you have already imported or defined the ViT model\n",
    "# ...\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "#from project import ViT\n",
    "hp = {\n",
    "    \"image_size\": 512,\n",
    "    \"num_channels\": 3,\n",
    "    \"patch_size\": 64,\n",
    "    \"num_classes\": 3,\n",
    "    \"class_names\": [\"Yellow_rust\",\"Brown_rust\", \"Healthy\"],\n",
    "    \"num_layers\": 24,\n",
    "    \"hidden_dim\": 256,\n",
    "    \"mlp_dim\": 1024,\n",
    "    \"num_heads\": 4,\n",
    "    \"dropout_rate\": 0.1,\n",
    "    \"batch_size\": 16,\n",
    "    \"lr\": 1e-4,\n",
    "    \"num_epochs\": 10\n",
    "}\n",
    "hp[\"num_patches\"] = (hp[\"image_size\"] ** 2) // (hp[\"patch_size\"] ** 2)\n",
    "hp[\"flat_patches_shape\"] = (hp[\"num_patches\"], hp[\"patch_size\"] * hp[\"patch_size\"] * hp[\"num_channels\"])\n",
    "\n",
    "\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "\n",
    "def load_data(path, split=0.20):\n",
    "    images = glob(os.path.join(path, \"*\", \"*.jpg\"))\n",
    "\n",
    "    # Separate images by class\n",
    "    images_class_BKL = [image for image in images if \"Yellow_rust\" in image]\n",
    "    images_class_NV = [image for image in images if \"Brown_rust\" in image]\n",
    "    images_class_MEL2 = [image for image in images if \"Healthy\" in image]\n",
    "    images_class_MEL2 = [image for image in images if \"Healthy\" in image]\n",
    "\n",
    "    # Oversample to 33,000 to match the largest class (BKL)\n",
    "    target_size = len(images_class_BKL)\n",
    "    #print(images_class_BKL)\n",
    "    images_class_NV = np.random.choice(images_class_NV, size=target_size, replace=True).tolist()\n",
    "    images_class_MEL2 = np.random.choice(images_class_MEL2, size=target_size, replace=True).tolist()\n",
    "\n",
    "    # Concatenate lists again and shuffle\n",
    "    images = shuffle(images_class_BKL + images_class_NV + images_class_MEL2)\n",
    "\n",
    "    split_size = int(len(images) * split)\n",
    "    train_x, valid_x = train_test_split(images, test_size=split_size, random_state=42)\n",
    "    train_x, test_x = train_test_split(train_x, test_size=split_size, random_state=42)\n",
    "    print(f\"Train: {len(train_x)} - Valid: {len(valid_x)} - Test: {len(test_x)}\")\n",
    "\n",
    "    return train_x, valid_x, test_x\n",
    "\n",
    "\n",
    "def process_image_label(path):\n",
    "    path = path.decode()\n",
    "    image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (hp[\"image_size\"], hp[\"image_size\"]))\n",
    "    image = image / 255.0\n",
    "\n",
    "    patch_shape = (hp[\"patch_size\"], hp[\"patch_size\"], hp[\"num_channels\"])\n",
    "    patches = patchify(image, patch_shape, hp[\"patch_size\"])\n",
    "    patches = np.reshape(patches, hp[\"flat_patches_shape\"])\n",
    "    patches = patches.astype(np.float32)\n",
    "\n",
    "    class_name = path.split(\"/\")[-2]\n",
    "    class_idx = hp[\"class_names\"].index(class_name)\n",
    "    class_idx = np.array(class_idx, dtype=np.int32)\n",
    "    return patches, class_idx\n",
    "\n",
    "\n",
    "def parse(path):\n",
    "    patches, labels = tf.numpy_function(process_image_label, [path], [tf.float32, tf.int32])\n",
    "    labels = tf.one_hot(labels, hp[\"num_classes\"])\n",
    "\n",
    "    patches.set_shape(hp[\"flat_patches_shape\"])\n",
    "    labels.set_shape(hp[\"num_classes\"])\n",
    "\n",
    "    return patches, labels\n",
    "\n",
    "\n",
    "def tf_dataset(images, batch=32):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((images))\n",
    "    ds = ds.map(parse).batch(batch).prefetch(8)\n",
    "    return ds\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    model = ViT(hp)\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        optimizer=tf.keras.optimizers.Adam(hp[\"lr\"], clipvalue=1.0),\n",
    "        metrics=[\"acc\", AUC(name='auc', multi_label=True)]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_dir(\"files\")\n",
    "    dataset_path = '/home/ali/Music/PYTHON/WholeDataset'\n",
    "    model_path = os.path.join(\"files\", \"model3.h5\")\n",
    "    csv_path = os.path.join(\"files\", \"log2.csv\")\n",
    "    train_x, valid_x, test_x = load_data(dataset_path)\n",
    "    images = train_x + valid_x\n",
    "    print(f\"Train: {len(train_x)} - Valid: {len(valid_x)} - Test: {len(test_x)}\")\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    fold_no = 1\n",
    "\n",
    "    for train, val in kfold.split(images):\n",
    "        print(f'Training for fold {fold_no} ...')\n",
    "        train_ds = tf_dataset(np.array(images)[train], batch=hp[\"batch_size\"])\n",
    "        valid_ds = tf_dataset(np.array(images)[val], batch=hp[\"batch_size\"])\n",
    "        model = get_model()\n",
    "        callbacks = [\n",
    "            ModelCheckpoint(f\"files/modelN_fold{fold_no}.h5\", monitor='val_loss', verbose=1, save_best_only=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, min_lr=1e-10, verbose=1),\n",
    "            CSVLogger(f\"files/log2_fold{fold_no}.csv\"),\n",
    "            EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=False),\n",
    "        ]\n",
    "        print(2)\n",
    "        model.fit(train_ds, epochs=hp[\"num_epochs\"], validation_data=valid_ds, callbacks=callbacks)\n",
    "        fold_no += 1\n",
    "        print(3)\n",
    "\n",
    "    # Evaluating on the test set\n",
    "    print(\"Evaluating the test set...\")\n",
    "    test_ds = tf_dataset(test_x, batch=hp[\"batch_size\"])\n",
    "    all_preds = []\n",
    "    custom_objects = {\"ClassToken\": ClassToken}\n",
    "    for fold_no in range(1, 6):\n",
    "        with tf.keras.utils.custom_object_scope(custom_objects):\n",
    "            fold_model = tf.keras.models.load_model(f\"files/modelN_fold{fold_no}.h5\")\n",
    "        y_pred_probs = fold_model.predict(test_ds)\n",
    "        all_preds.append(y_pred_probs)\n",
    "\n",
    "    avg_preds = np.mean(all_preds, axis=0)\n",
    "    final_preds = np.argmax(avg_preds, axis=1)\n",
    "    y_true = [hp[\"class_names\"].index(img.split(\"/\")[-2]) for img in test_x]\n",
    "    print(classification_report(y_true, final_preds, target_names=hp[\"class_names\"]))\n",
    "    roc_aucs = []\n",
    "\n",
    "    for i, class_name in enumerate(hp[\"class_names\"]):\n",
    "        auc_val = roc_auc_score((np.array(y_true) == i).astype(int), avg_preds[:, i])\n",
    "        roc_aucs.append(auc_val)\n",
    "        print(f\"AUC-ROC ({class_name}): {auc_val:.4f}\")\n",
    "\n",
    "    for i, class_name in enumerate(hp[\"class_names\"]):\n",
    "        fpr, tpr, _ = roc_curve((np.array(y_true) == i).astype(int), avg_preds[:, i])\n",
    "        plt.plot(fpr, tpr, label=f\"{class_name} (AUC = {roc_aucs[i]:.2f})\")\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], color='grey', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_25\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_26 (InputLayer)       [(None, 256, 3072)]          0         []                            \n",
      "                                                                                                  \n",
      " dense_1250 (Dense)          (None, 256, 256)             786688    ['input_26[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_30 (T  (None, 256, 256)             0         ['dense_1250[0][0]']          \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " class_token_61 (ClassToken  (None, 1, 256)               256       ['tf.__operators__.add_30[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " concatenate_25 (Concatenat  (None, 257, 256)             0         ['class_token_61[0][0]',      \n",
      " e)                                                                  'tf.__operators__.add_30[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " layer_normalization_1225 (  (None, 257, 256)             512       ['concatenate_25[0][0]']      \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_600 (  (None, 257, 256)             3155200   ['layer_normalization_1225[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1225[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1200 (Add)              (None, 257, 256)             0         ['multi_head_attention_600[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'concatenate_25[0][0]']      \n",
      "                                                                                                  \n",
      " layer_normalization_1226 (  (None, 257, 256)             512       ['add_1200[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1251 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1226[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2064 (Dropout)      (None, 257, 1024)            0         ['dense_1251[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1252 (Dense)          (None, 257, 256)             262400    ['dropout_2064[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2065 (Dropout)      (None, 257, 256)             0         ['dense_1252[0][0]']          \n",
      "                                                                                                  \n",
      " add_1201 (Add)              (None, 257, 256)             0         ['dropout_2065[0][0]',        \n",
      "                                                                     'add_1200[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1227 (  (None, 257, 256)             512       ['add_1201[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_601 (  (None, 257, 256)             3155200   ['layer_normalization_1227[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1227[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1202 (Add)              (None, 257, 256)             0         ['multi_head_attention_601[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1201[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1228 (  (None, 257, 256)             512       ['add_1202[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1253 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1228[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2066 (Dropout)      (None, 257, 1024)            0         ['dense_1253[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1254 (Dense)          (None, 257, 256)             262400    ['dropout_2066[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2067 (Dropout)      (None, 257, 256)             0         ['dense_1254[0][0]']          \n",
      "                                                                                                  \n",
      " add_1203 (Add)              (None, 257, 256)             0         ['dropout_2067[0][0]',        \n",
      "                                                                     'add_1202[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1229 (  (None, 257, 256)             512       ['add_1203[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_602 (  (None, 257, 256)             3155200   ['layer_normalization_1229[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1229[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1204 (Add)              (None, 257, 256)             0         ['multi_head_attention_602[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1203[0][0]']            \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " layer_normalization_1230 (  (None, 257, 256)             512       ['add_1204[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1255 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1230[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2068 (Dropout)      (None, 257, 1024)            0         ['dense_1255[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1256 (Dense)          (None, 257, 256)             262400    ['dropout_2068[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2069 (Dropout)      (None, 257, 256)             0         ['dense_1256[0][0]']          \n",
      "                                                                                                  \n",
      " add_1205 (Add)              (None, 257, 256)             0         ['dropout_2069[0][0]',        \n",
      "                                                                     'add_1204[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1231 (  (None, 257, 256)             512       ['add_1205[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_603 (  (None, 257, 256)             3155200   ['layer_normalization_1231[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1231[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1206 (Add)              (None, 257, 256)             0         ['multi_head_attention_603[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1205[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1232 (  (None, 257, 256)             512       ['add_1206[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1257 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1232[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2070 (Dropout)      (None, 257, 1024)            0         ['dense_1257[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1258 (Dense)          (None, 257, 256)             262400    ['dropout_2070[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2071 (Dropout)      (None, 257, 256)             0         ['dense_1258[0][0]']          \n",
      "                                                                                                  \n",
      " add_1207 (Add)              (None, 257, 256)             0         ['dropout_2071[0][0]',        \n",
      "                                                                     'add_1206[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1233 (  (None, 257, 256)             512       ['add_1207[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_604 (  (None, 257, 256)             3155200   ['layer_normalization_1233[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1233[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1208 (Add)              (None, 257, 256)             0         ['multi_head_attention_604[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1207[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1234 (  (None, 257, 256)             512       ['add_1208[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1259 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1234[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2072 (Dropout)      (None, 257, 1024)            0         ['dense_1259[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1260 (Dense)          (None, 257, 256)             262400    ['dropout_2072[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2073 (Dropout)      (None, 257, 256)             0         ['dense_1260[0][0]']          \n",
      "                                                                                                  \n",
      " add_1209 (Add)              (None, 257, 256)             0         ['dropout_2073[0][0]',        \n",
      "                                                                     'add_1208[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1235 (  (None, 257, 256)             512       ['add_1209[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_605 (  (None, 257, 256)             3155200   ['layer_normalization_1235[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1235[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1210 (Add)              (None, 257, 256)             0         ['multi_head_attention_605[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1209[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1236 (  (None, 257, 256)             512       ['add_1210[0][0]']            \n",
      " LayerNormalization)                                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " dense_1261 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1236[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2074 (Dropout)      (None, 257, 1024)            0         ['dense_1261[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1262 (Dense)          (None, 257, 256)             262400    ['dropout_2074[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2075 (Dropout)      (None, 257, 256)             0         ['dense_1262[0][0]']          \n",
      "                                                                                                  \n",
      " add_1211 (Add)              (None, 257, 256)             0         ['dropout_2075[0][0]',        \n",
      "                                                                     'add_1210[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1237 (  (None, 257, 256)             512       ['add_1211[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_606 (  (None, 257, 256)             3155200   ['layer_normalization_1237[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1237[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1212 (Add)              (None, 257, 256)             0         ['multi_head_attention_606[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1211[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1238 (  (None, 257, 256)             512       ['add_1212[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1263 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1238[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2076 (Dropout)      (None, 257, 1024)            0         ['dense_1263[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1264 (Dense)          (None, 257, 256)             262400    ['dropout_2076[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2077 (Dropout)      (None, 257, 256)             0         ['dense_1264[0][0]']          \n",
      "                                                                                                  \n",
      " add_1213 (Add)              (None, 257, 256)             0         ['dropout_2077[0][0]',        \n",
      "                                                                     'add_1212[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1239 (  (None, 257, 256)             512       ['add_1213[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_607 (  (None, 257, 256)             3155200   ['layer_normalization_1239[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1239[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1214 (Add)              (None, 257, 256)             0         ['multi_head_attention_607[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1213[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1240 (  (None, 257, 256)             512       ['add_1214[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1265 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1240[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2078 (Dropout)      (None, 257, 1024)            0         ['dense_1265[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1266 (Dense)          (None, 257, 256)             262400    ['dropout_2078[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2079 (Dropout)      (None, 257, 256)             0         ['dense_1266[0][0]']          \n",
      "                                                                                                  \n",
      " add_1215 (Add)              (None, 257, 256)             0         ['dropout_2079[0][0]',        \n",
      "                                                                     'add_1214[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1241 (  (None, 257, 256)             512       ['add_1215[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_608 (  (None, 257, 256)             3155200   ['layer_normalization_1241[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1241[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1216 (Add)              (None, 257, 256)             0         ['multi_head_attention_608[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1215[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1242 (  (None, 257, 256)             512       ['add_1216[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1267 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1242[0][\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2080 (Dropout)      (None, 257, 1024)            0         ['dense_1267[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1268 (Dense)          (None, 257, 256)             262400    ['dropout_2080[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2081 (Dropout)      (None, 257, 256)             0         ['dense_1268[0][0]']          \n",
      "                                                                                                  \n",
      " add_1217 (Add)              (None, 257, 256)             0         ['dropout_2081[0][0]',        \n",
      "                                                                     'add_1216[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1243 (  (None, 257, 256)             512       ['add_1217[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_609 (  (None, 257, 256)             3155200   ['layer_normalization_1243[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1243[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1218 (Add)              (None, 257, 256)             0         ['multi_head_attention_609[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1217[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1244 (  (None, 257, 256)             512       ['add_1218[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1269 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1244[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2082 (Dropout)      (None, 257, 1024)            0         ['dense_1269[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1270 (Dense)          (None, 257, 256)             262400    ['dropout_2082[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2083 (Dropout)      (None, 257, 256)             0         ['dense_1270[0][0]']          \n",
      "                                                                                                  \n",
      " add_1219 (Add)              (None, 257, 256)             0         ['dropout_2083[0][0]',        \n",
      "                                                                     'add_1218[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1245 (  (None, 257, 256)             512       ['add_1219[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_610 (  (None, 257, 256)             3155200   ['layer_normalization_1245[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1245[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1220 (Add)              (None, 257, 256)             0         ['multi_head_attention_610[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1219[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1246 (  (None, 257, 256)             512       ['add_1220[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1271 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1246[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2084 (Dropout)      (None, 257, 1024)            0         ['dense_1271[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1272 (Dense)          (None, 257, 256)             262400    ['dropout_2084[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2085 (Dropout)      (None, 257, 256)             0         ['dense_1272[0][0]']          \n",
      "                                                                                                  \n",
      " add_1221 (Add)              (None, 257, 256)             0         ['dropout_2085[0][0]',        \n",
      "                                                                     'add_1220[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1247 (  (None, 257, 256)             512       ['add_1221[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_611 (  (None, 257, 256)             3155200   ['layer_normalization_1247[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1247[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1222 (Add)              (None, 257, 256)             0         ['multi_head_attention_611[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1221[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1248 (  (None, 257, 256)             512       ['add_1222[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1273 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1248[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dropout_2086 (Dropout)      (None, 257, 1024)            0         ['dense_1273[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1274 (Dense)          (None, 257, 256)             262400    ['dropout_2086[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2087 (Dropout)      (None, 257, 256)             0         ['dense_1274[0][0]']          \n",
      "                                                                                                  \n",
      " add_1223 (Add)              (None, 257, 256)             0         ['dropout_2087[0][0]',        \n",
      "                                                                     'add_1222[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1249 (  (None, 257, 256)             512       ['add_1223[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_612 (  (None, 257, 256)             3155200   ['layer_normalization_1249[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1249[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1224 (Add)              (None, 257, 256)             0         ['multi_head_attention_612[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1223[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1250 (  (None, 257, 256)             512       ['add_1224[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1275 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1250[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2088 (Dropout)      (None, 257, 1024)            0         ['dense_1275[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1276 (Dense)          (None, 257, 256)             262400    ['dropout_2088[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2089 (Dropout)      (None, 257, 256)             0         ['dense_1276[0][0]']          \n",
      "                                                                                                  \n",
      " add_1225 (Add)              (None, 257, 256)             0         ['dropout_2089[0][0]',        \n",
      "                                                                     'add_1224[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1251 (  (None, 257, 256)             512       ['add_1225[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_613 (  (None, 257, 256)             3155200   ['layer_normalization_1251[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1251[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1226 (Add)              (None, 257, 256)             0         ['multi_head_attention_613[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1225[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1252 (  (None, 257, 256)             512       ['add_1226[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1277 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1252[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2090 (Dropout)      (None, 257, 1024)            0         ['dense_1277[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1278 (Dense)          (None, 257, 256)             262400    ['dropout_2090[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2091 (Dropout)      (None, 257, 256)             0         ['dense_1278[0][0]']          \n",
      "                                                                                                  \n",
      " add_1227 (Add)              (None, 257, 256)             0         ['dropout_2091[0][0]',        \n",
      "                                                                     'add_1226[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1253 (  (None, 257, 256)             512       ['add_1227[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_614 (  (None, 257, 256)             3155200   ['layer_normalization_1253[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1253[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1228 (Add)              (None, 257, 256)             0         ['multi_head_attention_614[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1227[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1254 (  (None, 257, 256)             512       ['add_1228[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1279 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1254[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2092 (Dropout)      (None, 257, 1024)            0         ['dense_1279[0][0]']          \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_1280 (Dense)          (None, 257, 256)             262400    ['dropout_2092[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2093 (Dropout)      (None, 257, 256)             0         ['dense_1280[0][0]']          \n",
      "                                                                                                  \n",
      " add_1229 (Add)              (None, 257, 256)             0         ['dropout_2093[0][0]',        \n",
      "                                                                     'add_1228[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1255 (  (None, 257, 256)             512       ['add_1229[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_615 (  (None, 257, 256)             3155200   ['layer_normalization_1255[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1255[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1230 (Add)              (None, 257, 256)             0         ['multi_head_attention_615[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1229[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1256 (  (None, 257, 256)             512       ['add_1230[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1281 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1256[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2094 (Dropout)      (None, 257, 1024)            0         ['dense_1281[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1282 (Dense)          (None, 257, 256)             262400    ['dropout_2094[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2095 (Dropout)      (None, 257, 256)             0         ['dense_1282[0][0]']          \n",
      "                                                                                                  \n",
      " add_1231 (Add)              (None, 257, 256)             0         ['dropout_2095[0][0]',        \n",
      "                                                                     'add_1230[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1257 (  (None, 257, 256)             512       ['add_1231[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_616 (  (None, 257, 256)             3155200   ['layer_normalization_1257[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1257[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1232 (Add)              (None, 257, 256)             0         ['multi_head_attention_616[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1231[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1258 (  (None, 257, 256)             512       ['add_1232[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1283 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1258[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2096 (Dropout)      (None, 257, 1024)            0         ['dense_1283[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1284 (Dense)          (None, 257, 256)             262400    ['dropout_2096[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2097 (Dropout)      (None, 257, 256)             0         ['dense_1284[0][0]']          \n",
      "                                                                                                  \n",
      " add_1233 (Add)              (None, 257, 256)             0         ['dropout_2097[0][0]',        \n",
      "                                                                     'add_1232[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1259 (  (None, 257, 256)             512       ['add_1233[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_617 (  (None, 257, 256)             3155200   ['layer_normalization_1259[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1259[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1234 (Add)              (None, 257, 256)             0         ['multi_head_attention_617[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1233[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1260 (  (None, 257, 256)             512       ['add_1234[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1285 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1260[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2098 (Dropout)      (None, 257, 1024)            0         ['dense_1285[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1286 (Dense)          (None, 257, 256)             262400    ['dropout_2098[0][0]']        \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dropout_2099 (Dropout)      (None, 257, 256)             0         ['dense_1286[0][0]']          \n",
      "                                                                                                  \n",
      " add_1235 (Add)              (None, 257, 256)             0         ['dropout_2099[0][0]',        \n",
      "                                                                     'add_1234[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1261 (  (None, 257, 256)             512       ['add_1235[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_618 (  (None, 257, 256)             3155200   ['layer_normalization_1261[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1261[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1236 (Add)              (None, 257, 256)             0         ['multi_head_attention_618[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1235[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1262 (  (None, 257, 256)             512       ['add_1236[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1287 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1262[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2100 (Dropout)      (None, 257, 1024)            0         ['dense_1287[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1288 (Dense)          (None, 257, 256)             262400    ['dropout_2100[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2101 (Dropout)      (None, 257, 256)             0         ['dense_1288[0][0]']          \n",
      "                                                                                                  \n",
      " add_1237 (Add)              (None, 257, 256)             0         ['dropout_2101[0][0]',        \n",
      "                                                                     'add_1236[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1263 (  (None, 257, 256)             512       ['add_1237[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_619 (  (None, 257, 256)             3155200   ['layer_normalization_1263[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1263[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1238 (Add)              (None, 257, 256)             0         ['multi_head_attention_619[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1237[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1264 (  (None, 257, 256)             512       ['add_1238[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1289 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1264[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2102 (Dropout)      (None, 257, 1024)            0         ['dense_1289[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1290 (Dense)          (None, 257, 256)             262400    ['dropout_2102[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2103 (Dropout)      (None, 257, 256)             0         ['dense_1290[0][0]']          \n",
      "                                                                                                  \n",
      " add_1239 (Add)              (None, 257, 256)             0         ['dropout_2103[0][0]',        \n",
      "                                                                     'add_1238[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1265 (  (None, 257, 256)             512       ['add_1239[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_620 (  (None, 257, 256)             3155200   ['layer_normalization_1265[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1265[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1240 (Add)              (None, 257, 256)             0         ['multi_head_attention_620[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1239[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1266 (  (None, 257, 256)             512       ['add_1240[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1291 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1266[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2104 (Dropout)      (None, 257, 1024)            0         ['dense_1291[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1292 (Dense)          (None, 257, 256)             262400    ['dropout_2104[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2105 (Dropout)      (None, 257, 256)             0         ['dense_1292[0][0]']          \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " add_1241 (Add)              (None, 257, 256)             0         ['dropout_2105[0][0]',        \n",
      "                                                                     'add_1240[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1267 (  (None, 257, 256)             512       ['add_1241[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_621 (  (None, 257, 256)             3155200   ['layer_normalization_1267[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1267[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1242 (Add)              (None, 257, 256)             0         ['multi_head_attention_621[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1241[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1268 (  (None, 257, 256)             512       ['add_1242[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1293 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1268[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2106 (Dropout)      (None, 257, 1024)            0         ['dense_1293[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1294 (Dense)          (None, 257, 256)             262400    ['dropout_2106[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2107 (Dropout)      (None, 257, 256)             0         ['dense_1294[0][0]']          \n",
      "                                                                                                  \n",
      " add_1243 (Add)              (None, 257, 256)             0         ['dropout_2107[0][0]',        \n",
      "                                                                     'add_1242[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1269 (  (None, 257, 256)             512       ['add_1243[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_622 (  (None, 257, 256)             3155200   ['layer_normalization_1269[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1269[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1244 (Add)              (None, 257, 256)             0         ['multi_head_attention_622[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1243[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1270 (  (None, 257, 256)             512       ['add_1244[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1295 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1270[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2108 (Dropout)      (None, 257, 1024)            0         ['dense_1295[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1296 (Dense)          (None, 257, 256)             262400    ['dropout_2108[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2109 (Dropout)      (None, 257, 256)             0         ['dense_1296[0][0]']          \n",
      "                                                                                                  \n",
      " add_1245 (Add)              (None, 257, 256)             0         ['dropout_2109[0][0]',        \n",
      "                                                                     'add_1244[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1271 (  (None, 257, 256)             512       ['add_1245[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_623 (  (None, 257, 256)             3155200   ['layer_normalization_1271[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1271[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1246 (Add)              (None, 257, 256)             0         ['multi_head_attention_623[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1245[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1272 (  (None, 257, 256)             512       ['add_1246[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1297 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1272[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2110 (Dropout)      (None, 257, 1024)            0         ['dense_1297[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1298 (Dense)          (None, 257, 256)             262400    ['dropout_2110[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2111 (Dropout)      (None, 257, 256)             0         ['dense_1298[0][0]']          \n",
      "                                                                                                  \n",
      " add_1247 (Add)              (None, 257, 256)             0         ['dropout_2111[0][0]',        \n",
      "                                                                     'add_1246[0][0]']            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " layer_normalization_1273 (  (None, 257, 256)             512       ['add_1247[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_3  (None, 256)                  0         ['layer_normalization_1273[0][\n",
      " 0 (SlicingOpLambda)                                                0]']                          \n",
      "                                                                                                  \n",
      " dense_1299 (Dense)          (None, 4)                    1028      ['tf.__operators__.getitem_30[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 89151492 (340.09 MB)\n",
      "Trainable params: 89151492 (340.09 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Train: 2778 - Valid: 925 - Test: 925\n",
      "Train: 2778 - Valid: 925 - Test: 925\n",
      "Training for fold 1 ...\n",
      "2\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.9403 - acc: 0.6063 - auc: 0.8351\n",
      "Epoch 1: val_loss improved from inf to 0.65785, saving model to files/modelN_fold1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186/186 [==============================] - 1371s 7s/step - loss: 0.9403 - acc: 0.6063 - auc: 0.8351 - val_loss: 0.6578 - val_acc: 0.7099 - val_auc: 0.9205 - lr: 1.0000e-04\n",
      "3\n",
      "Training for fold 2 ...\n",
      "2\n",
      "186/186 [==============================] - ETA: 0s - loss: 1.2056 - acc: 0.4646 - auc: 0.7268\n",
      "Epoch 1: val_loss improved from inf to 0.77241, saving model to files/modelN_fold2.h5\n",
      "186/186 [==============================] - 1421s 7s/step - loss: 1.2056 - acc: 0.4646 - auc: 0.7268 - val_loss: 0.7724 - val_acc: 0.6289 - val_auc: 0.9205 - lr: 1.0000e-04\n",
      "3\n",
      "Training for fold 3 ...\n",
      "2\n",
      "186/186 [==============================] - ETA: 0s - loss: 1.1700 - acc: 0.4892 - auc: 0.7544\n",
      "Epoch 1: val_loss improved from inf to 0.63868, saving model to files/modelN_fold3.h5\n",
      "186/186 [==============================] - 1348s 7s/step - loss: 1.1700 - acc: 0.4892 - auc: 0.7544 - val_loss: 0.6387 - val_acc: 0.7139 - val_auc: 0.9274 - lr: 1.0000e-04\n",
      "3\n",
      "Training for fold 4 ...\n",
      "2\n",
      "186/186 [==============================] - ETA: 0s - loss: 1.0379 - acc: 0.5437 - auc: 0.7975\n",
      "Epoch 1: val_loss improved from inf to 0.70421, saving model to files/modelN_fold4.h5\n",
      "186/186 [==============================] - 1354s 7s/step - loss: 1.0379 - acc: 0.5437 - auc: 0.7975 - val_loss: 0.7042 - val_acc: 0.6486 - val_auc: 0.9197 - lr: 1.0000e-04\n",
      "3\n",
      "Training for fold 5 ...\n",
      "2\n",
      "186/186 [==============================] - ETA: 0s - loss: 1.0402 - acc: 0.5501 - auc: 0.8035\n",
      "Epoch 1: val_loss improved from inf to 0.65927, saving model to files/modelN_fold5.h5\n",
      "186/186 [==============================] - 1376s 7s/step - loss: 1.0402 - acc: 0.5501 - auc: 0.8035 - val_loss: 0.6593 - val_acc: 0.7176 - val_auc: 0.9096 - lr: 1.0000e-04\n",
      "3\n",
      "Evaluating the test set...\n",
      "58/58 [==============================] - 123s 2s/step\n",
      "58/58 [==============================] - 127s 2s/step\n",
      "58/58 [==============================] - 121s 2s/step\n",
      "58/58 [==============================] - 125s 2s/step\n",
      "58/58 [==============================] - 123s 2s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Yellow_rust       0.67      0.67      0.67       245\n",
      "  Brown_rust       0.94      0.43      0.59       212\n",
      "     Healthy       0.61      0.89      0.73       233\n",
      "Blast_Leaves       0.95      0.99      0.97       235\n",
      "\n",
      "    accuracy                           0.75       925\n",
      "   macro avg       0.79      0.74      0.74       925\n",
      "weighted avg       0.79      0.75      0.74       925\n",
      "\n",
      "AUC-ROC (Yellow_rust): 0.8826\n",
      "AUC-ROC (Brown_rust): 0.8905\n",
      "AUC-ROC (Healthy): 0.9308\n",
      "AUC-ROC (Blast_Leaves): 0.9987\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1 Epoch train and test\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "\n",
    "class ClassToken(Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        w_init = tf.random_normal_initializer()\n",
    "        self.w = tf.Variable(\n",
    "            initial_value = w_init(shape=(1, 1, input_shape[-1]), dtype=tf.float32),\n",
    "            trainable = True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        hidden_dim = self.w.shape[-1]\n",
    "\n",
    "        cls = tf.broadcast_to(self.w, [batch_size, 1, hidden_dim])\n",
    "        cls = tf.cast(cls, dtype=inputs.dtype)\n",
    "        return cls\n",
    "\n",
    "def mlp(x, cf):\n",
    "    x = Dense(cf[\"mlp_dim\"], activation=\"gelu\")(x)\n",
    "    x = Dropout(cf[\"dropout_rate\"])(x)\n",
    "    x = Dense(cf[\"hidden_dim\"])(x)\n",
    "    x = Dropout(cf[\"dropout_rate\"])(x)\n",
    "    return x\n",
    "\n",
    "def transformer_encoder(x, cf):\n",
    "    skip_1 = x\n",
    "    x = LayerNormalization()(x)\n",
    "    x = MultiHeadAttention(\n",
    "        num_heads=cf[\"num_heads\"], key_dim=cf[\"hidden_dim\"]\n",
    "    )(x, x)\n",
    "    x = Add()([x, skip_1])\n",
    "\n",
    "    skip_2 = x\n",
    "    x = LayerNormalization()(x)\n",
    "    x = mlp(x, cf)\n",
    "    x = Add()([x, skip_2])\n",
    "\n",
    "    return x\n",
    "\n",
    "def ViT(cf):\n",
    "    \"\"\" Inputs \"\"\"\n",
    "    input_shape = (cf[\"num_patches\"], cf[\"patch_size\"]*cf[\"patch_size\"]*cf[\"num_channels\"])\n",
    "    inputs = Input(input_shape)     ## (None, 256, 3072)\n",
    "\n",
    "    \"\"\" Patch + Position Embeddings \"\"\"\n",
    "    patch_embed = Dense(cf[\"hidden_dim\"])(inputs)   ## (None, 256, 768)\n",
    "\n",
    "    positions = tf.range(start=0, limit=cf[\"num_patches\"], delta=1)\n",
    "    pos_embed = Embedding(input_dim=cf[\"num_patches\"], output_dim=cf[\"hidden_dim\"])(positions) ## (256, 768)\n",
    "    embed = patch_embed + pos_embed ## (None, 256, 768)\n",
    "\n",
    "    \"\"\" Adding Class Token \"\"\"\n",
    "    token = ClassToken()(embed)\n",
    "    x = Concatenate(axis=1)([token, embed]) ## (None, 257, 768)\n",
    "\n",
    "    for _ in range(cf[\"num_layers\"]):\n",
    "        x = transformer_encoder(x, cf)\n",
    "\n",
    "    \"\"\" Classification Head \"\"\"\n",
    "    x = LayerNormalization()(x)     ## (None, 257, 768)\n",
    "    x = x[:, 0, :]\n",
    "    x = Dense(cf[\"num_classes\"], activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs, x)\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config = {}\n",
    "    config[\"num_layers\"] = 24\n",
    "#     config[\"hidden_dim\"] = 768\n",
    "#     config[\"mlp_dim\"] =3072\n",
    "    config[\"num_heads\"] = 12\n",
    "    config[\"dropout_rate\"] = 0.1\n",
    "    config[\"num_patches\"] = 256\n",
    "    config[\"patch_size\"] = 32\n",
    "    config[\"num_channels\"] = 3\n",
    "    config[\"num_classes\"] = 4\n",
    "\n",
    "    config[\"hidden_dim\"] = 256\n",
    "    config[\"mlp_dim\"] = 1024  \n",
    "\n",
    "    model = ViT(config)\n",
    "    model.summary()\n",
    "\n",
    "\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive/')\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from keras.metrics import AUC\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
    "from patchify import patchify\n",
    "# import tensorflow_hub as hub\n",
    "# Assuming you have already imported or defined the ViT model\n",
    "# ...\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "#from project import ViT\n",
    "hp = {\n",
    "    \"image_size\": 512,\n",
    "    \"num_channels\": 3,\n",
    "    \"patch_size\": 64,\n",
    "    \"num_classes\": 4,\n",
    "    \"class_names\": [\"Yellow_rust\",\"Brown_rust\", \"Healthy\",\"Blast_Leaves\"],\n",
    "    \"num_layers\": 24,\n",
    "    \"hidden_dim\": 256,\n",
    "    \"mlp_dim\": 1024,\n",
    "    \"num_heads\": 4,\n",
    "    \"dropout_rate\": 0.1,\n",
    "    \"batch_size\": 16,\n",
    "    \"lr\": 1e-4,\n",
    "    \"num_epochs\": 1\n",
    "}\n",
    "hp[\"num_patches\"] = (hp[\"image_size\"] ** 2) // (hp[\"patch_size\"] ** 2)\n",
    "hp[\"flat_patches_shape\"] = (hp[\"num_patches\"], hp[\"patch_size\"] * hp[\"patch_size\"] * hp[\"num_channels\"])\n",
    "\n",
    "\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "\n",
    "def load_data(path, split=0.20):\n",
    "    images = glob(os.path.join(path, \"*\", \"*.jpg\"))\n",
    "\n",
    "    # Separate images by class\n",
    "    images_class_BKL = [image for image in images if \"Yellow_rust\" in image]\n",
    "    images_class_NV = [image for image in images if \"Brown_rust\" in image]\n",
    "    images_class_MEL2 = [image for image in images if \"Healthy\" in image]\n",
    "    images_class_BlastLeaves = [image for image in images if \"Blast_Leaves\" in image]\n",
    "\n",
    "    # Oversample to 33,000 to match the largest class (BKL)\n",
    "    target_size = len(images_class_BKL)\n",
    "    #print(images_class_BKL)\n",
    "    images_class_NV = np.random.choice(images_class_NV, size=target_size, replace=True).tolist()\n",
    "    images_class_MEL2 = np.random.choice(images_class_MEL2, size=target_size, replace=True).tolist()\n",
    "    images_class_BlastLeaves = np.random.choice(images_class_BlastLeaves, size=target_size, replace=True).tolist()\n",
    "    # Concatenate lists again and shuffle\n",
    "    images = shuffle(images_class_BKL + images_class_NV + images_class_MEL2+ images_class_BlastLeaves)\n",
    "\n",
    "    split_size = int(len(images) * split)\n",
    "    train_x, valid_x = train_test_split(images, test_size=split_size, random_state=42)\n",
    "    train_x, test_x = train_test_split(train_x, test_size=split_size, random_state=42)\n",
    "    print(f\"Train: {len(train_x)} - Valid: {len(valid_x)} - Test: {len(test_x)}\")\n",
    "\n",
    "    return train_x, valid_x, test_x\n",
    "\n",
    "\n",
    "def process_image_label(path):\n",
    "    path = path.decode()\n",
    "    image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (hp[\"image_size\"], hp[\"image_size\"]))\n",
    "    image = image / 255.0\n",
    "\n",
    "    patch_shape = (hp[\"patch_size\"], hp[\"patch_size\"], hp[\"num_channels\"])\n",
    "    patches = patchify(image, patch_shape, hp[\"patch_size\"])\n",
    "    patches = np.reshape(patches, hp[\"flat_patches_shape\"])\n",
    "    patches = patches.astype(np.float32)\n",
    "\n",
    "    class_name = path.split(\"/\")[-2]\n",
    "    class_idx = hp[\"class_names\"].index(class_name)\n",
    "    class_idx = np.array(class_idx, dtype=np.int32)\n",
    "    return patches, class_idx\n",
    "\n",
    "\n",
    "def parse(path):\n",
    "    patches, labels = tf.numpy_function(process_image_label, [path], [tf.float32, tf.int32])\n",
    "    labels = tf.one_hot(labels, hp[\"num_classes\"])\n",
    "\n",
    "    patches.set_shape(hp[\"flat_patches_shape\"])\n",
    "    labels.set_shape(hp[\"num_classes\"])\n",
    "\n",
    "    return patches, labels\n",
    "\n",
    "\n",
    "def tf_dataset(images, batch=32):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((images))\n",
    "    ds = ds.map(parse).batch(batch).prefetch(8)\n",
    "    return ds\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    model = ViT(hp)\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        optimizer=tf.keras.optimizers.Adam(hp[\"lr\"], clipvalue=1.0),\n",
    "        metrics=[\"acc\", AUC(name='auc', multi_label=True)]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_dir(\"files\")\n",
    "    dataset_path = '/home/ali/Music/PYTHON/WholeDataset'\n",
    "    model_path = os.path.join(\"files\", \"model3.h5\")\n",
    "    csv_path = os.path.join(\"files\", \"log2.csv\")\n",
    "    train_x, valid_x, test_x = load_data(dataset_path)\n",
    "    images = train_x + valid_x\n",
    "    print(f\"Train: {len(train_x)} - Valid: {len(valid_x)} - Test: {len(test_x)}\")\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    fold_no = 1\n",
    "\n",
    "    for train, val in kfold.split(images):\n",
    "        print(f'Training for fold {fold_no} ...')\n",
    "        train_ds = tf_dataset(np.array(images)[train], batch=hp[\"batch_size\"])\n",
    "        valid_ds = tf_dataset(np.array(images)[val], batch=hp[\"batch_size\"])\n",
    "        model = get_model()\n",
    "        callbacks = [\n",
    "            ModelCheckpoint(f\"files/modelN_fold{fold_no}.h5\", monitor='val_loss', verbose=1, save_best_only=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, min_lr=1e-10, verbose=1),\n",
    "            CSVLogger(f\"files/log2_fold{fold_no}.csv\"),\n",
    "            EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=False),\n",
    "        ]\n",
    "        print(2)\n",
    "        model.fit(train_ds, epochs=hp[\"num_epochs\"], validation_data=valid_ds, callbacks=callbacks)\n",
    "        fold_no += 1\n",
    "        print(3)\n",
    "\n",
    "    # Evaluating on the test set\n",
    "    print(\"Evaluating the test set...\")\n",
    "    test_ds = tf_dataset(test_x, batch=hp[\"batch_size\"])\n",
    "    all_preds = []\n",
    "    custom_objects = {\"ClassToken\": ClassToken}\n",
    "    for fold_no in range(1, 6):\n",
    "        with tf.keras.utils.custom_object_scope(custom_objects):\n",
    "            fold_model = tf.keras.models.load_model(f\"files/modelN_fold{fold_no}.h5\")\n",
    "        y_pred_probs = fold_model.predict(test_ds)\n",
    "        all_preds.append(y_pred_probs)\n",
    "\n",
    "    avg_preds = np.mean(all_preds, axis=0)\n",
    "    final_preds = np.argmax(avg_preds, axis=1)\n",
    "    y_true = [hp[\"class_names\"].index(img.split(\"/\")[-2]) for img in test_x]\n",
    "    print(classification_report(y_true, final_preds, target_names=hp[\"class_names\"]))\n",
    "    roc_aucs = []\n",
    "\n",
    "    for i, class_name in enumerate(hp[\"class_names\"]):\n",
    "        auc_val = roc_auc_score((np.array(y_true) == i).astype(int), avg_preds[:, i])\n",
    "        roc_aucs.append(auc_val)\n",
    "        print(f\"AUC-ROC ({class_name}): {auc_val:.4f}\")\n",
    "\n",
    "    for i, class_name in enumerate(hp[\"class_names\"]):\n",
    "        fpr, tpr, _ = roc_curve((np.array(y_true) == i).astype(int), avg_preds[:, i])\n",
    "        plt.plot(fpr, tpr, label=f\"{class_name} (AUC = {roc_aucs[i]:.2f})\")\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], color='grey', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_31\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_32 (InputLayer)       [(None, 256, 3072)]          0         []                            \n",
      "                                                                                                  \n",
      " dense_1550 (Dense)          (None, 256, 256)             786688    ['input_32[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_36 (T  (None, 256, 256)             0         ['dense_1550[0][0]']          \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " class_token_72 (ClassToken  (None, 1, 256)               256       ['tf.__operators__.add_36[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " concatenate_31 (Concatenat  (None, 257, 256)             0         ['class_token_72[0][0]',      \n",
      " e)                                                                  'tf.__operators__.add_36[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " layer_normalization_1519 (  (None, 257, 256)             512       ['concatenate_31[0][0]']      \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_744 (  (None, 257, 256)             3155200   ['layer_normalization_1519[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1519[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1488 (Add)              (None, 257, 256)             0         ['multi_head_attention_744[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'concatenate_31[0][0]']      \n",
      "                                                                                                  \n",
      " layer_normalization_1520 (  (None, 257, 256)             512       ['add_1488[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1551 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1520[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2472 (Dropout)      (None, 257, 1024)            0         ['dense_1551[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1552 (Dense)          (None, 257, 256)             262400    ['dropout_2472[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2473 (Dropout)      (None, 257, 256)             0         ['dense_1552[0][0]']          \n",
      "                                                                                                  \n",
      " add_1489 (Add)              (None, 257, 256)             0         ['dropout_2473[0][0]',        \n",
      "                                                                     'add_1488[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1521 (  (None, 257, 256)             512       ['add_1489[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_745 (  (None, 257, 256)             3155200   ['layer_normalization_1521[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1521[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1490 (Add)              (None, 257, 256)             0         ['multi_head_attention_745[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1489[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1522 (  (None, 257, 256)             512       ['add_1490[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1553 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1522[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2474 (Dropout)      (None, 257, 1024)            0         ['dense_1553[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1554 (Dense)          (None, 257, 256)             262400    ['dropout_2474[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2475 (Dropout)      (None, 257, 256)             0         ['dense_1554[0][0]']          \n",
      "                                                                                                  \n",
      " add_1491 (Add)              (None, 257, 256)             0         ['dropout_2475[0][0]',        \n",
      "                                                                     'add_1490[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1523 (  (None, 257, 256)             512       ['add_1491[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_746 (  (None, 257, 256)             3155200   ['layer_normalization_1523[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1523[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1492 (Add)              (None, 257, 256)             0         ['multi_head_attention_746[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1491[0][0]']            \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " layer_normalization_1524 (  (None, 257, 256)             512       ['add_1492[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1555 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1524[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2476 (Dropout)      (None, 257, 1024)            0         ['dense_1555[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1556 (Dense)          (None, 257, 256)             262400    ['dropout_2476[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2477 (Dropout)      (None, 257, 256)             0         ['dense_1556[0][0]']          \n",
      "                                                                                                  \n",
      " add_1493 (Add)              (None, 257, 256)             0         ['dropout_2477[0][0]',        \n",
      "                                                                     'add_1492[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1525 (  (None, 257, 256)             512       ['add_1493[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_747 (  (None, 257, 256)             3155200   ['layer_normalization_1525[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1525[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1494 (Add)              (None, 257, 256)             0         ['multi_head_attention_747[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1493[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1526 (  (None, 257, 256)             512       ['add_1494[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1557 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1526[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2478 (Dropout)      (None, 257, 1024)            0         ['dense_1557[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1558 (Dense)          (None, 257, 256)             262400    ['dropout_2478[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2479 (Dropout)      (None, 257, 256)             0         ['dense_1558[0][0]']          \n",
      "                                                                                                  \n",
      " add_1495 (Add)              (None, 257, 256)             0         ['dropout_2479[0][0]',        \n",
      "                                                                     'add_1494[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1527 (  (None, 257, 256)             512       ['add_1495[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_748 (  (None, 257, 256)             3155200   ['layer_normalization_1527[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1527[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1496 (Add)              (None, 257, 256)             0         ['multi_head_attention_748[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1495[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1528 (  (None, 257, 256)             512       ['add_1496[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1559 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1528[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2480 (Dropout)      (None, 257, 1024)            0         ['dense_1559[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1560 (Dense)          (None, 257, 256)             262400    ['dropout_2480[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2481 (Dropout)      (None, 257, 256)             0         ['dense_1560[0][0]']          \n",
      "                                                                                                  \n",
      " add_1497 (Add)              (None, 257, 256)             0         ['dropout_2481[0][0]',        \n",
      "                                                                     'add_1496[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1529 (  (None, 257, 256)             512       ['add_1497[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_749 (  (None, 257, 256)             3155200   ['layer_normalization_1529[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1529[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1498 (Add)              (None, 257, 256)             0         ['multi_head_attention_749[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1497[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1530 (  (None, 257, 256)             512       ['add_1498[0][0]']            \n",
      " LayerNormalization)                                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " dense_1561 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1530[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2482 (Dropout)      (None, 257, 1024)            0         ['dense_1561[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1562 (Dense)          (None, 257, 256)             262400    ['dropout_2482[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2483 (Dropout)      (None, 257, 256)             0         ['dense_1562[0][0]']          \n",
      "                                                                                                  \n",
      " add_1499 (Add)              (None, 257, 256)             0         ['dropout_2483[0][0]',        \n",
      "                                                                     'add_1498[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1531 (  (None, 257, 256)             512       ['add_1499[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_750 (  (None, 257, 256)             3155200   ['layer_normalization_1531[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1531[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1500 (Add)              (None, 257, 256)             0         ['multi_head_attention_750[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1499[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1532 (  (None, 257, 256)             512       ['add_1500[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1563 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1532[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2484 (Dropout)      (None, 257, 1024)            0         ['dense_1563[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1564 (Dense)          (None, 257, 256)             262400    ['dropout_2484[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2485 (Dropout)      (None, 257, 256)             0         ['dense_1564[0][0]']          \n",
      "                                                                                                  \n",
      " add_1501 (Add)              (None, 257, 256)             0         ['dropout_2485[0][0]',        \n",
      "                                                                     'add_1500[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1533 (  (None, 257, 256)             512       ['add_1501[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_751 (  (None, 257, 256)             3155200   ['layer_normalization_1533[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1533[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1502 (Add)              (None, 257, 256)             0         ['multi_head_attention_751[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1501[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1534 (  (None, 257, 256)             512       ['add_1502[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1565 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1534[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2486 (Dropout)      (None, 257, 1024)            0         ['dense_1565[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1566 (Dense)          (None, 257, 256)             262400    ['dropout_2486[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2487 (Dropout)      (None, 257, 256)             0         ['dense_1566[0][0]']          \n",
      "                                                                                                  \n",
      " add_1503 (Add)              (None, 257, 256)             0         ['dropout_2487[0][0]',        \n",
      "                                                                     'add_1502[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1535 (  (None, 257, 256)             512       ['add_1503[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_752 (  (None, 257, 256)             3155200   ['layer_normalization_1535[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1535[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1504 (Add)              (None, 257, 256)             0         ['multi_head_attention_752[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1503[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1536 (  (None, 257, 256)             512       ['add_1504[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1567 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1536[0][\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2488 (Dropout)      (None, 257, 1024)            0         ['dense_1567[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1568 (Dense)          (None, 257, 256)             262400    ['dropout_2488[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2489 (Dropout)      (None, 257, 256)             0         ['dense_1568[0][0]']          \n",
      "                                                                                                  \n",
      " add_1505 (Add)              (None, 257, 256)             0         ['dropout_2489[0][0]',        \n",
      "                                                                     'add_1504[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1537 (  (None, 257, 256)             512       ['add_1505[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_753 (  (None, 257, 256)             3155200   ['layer_normalization_1537[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1537[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1506 (Add)              (None, 257, 256)             0         ['multi_head_attention_753[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1505[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1538 (  (None, 257, 256)             512       ['add_1506[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1569 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1538[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2490 (Dropout)      (None, 257, 1024)            0         ['dense_1569[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1570 (Dense)          (None, 257, 256)             262400    ['dropout_2490[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2491 (Dropout)      (None, 257, 256)             0         ['dense_1570[0][0]']          \n",
      "                                                                                                  \n",
      " add_1507 (Add)              (None, 257, 256)             0         ['dropout_2491[0][0]',        \n",
      "                                                                     'add_1506[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1539 (  (None, 257, 256)             512       ['add_1507[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_754 (  (None, 257, 256)             3155200   ['layer_normalization_1539[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1539[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1508 (Add)              (None, 257, 256)             0         ['multi_head_attention_754[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1507[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1540 (  (None, 257, 256)             512       ['add_1508[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1571 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1540[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2492 (Dropout)      (None, 257, 1024)            0         ['dense_1571[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1572 (Dense)          (None, 257, 256)             262400    ['dropout_2492[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2493 (Dropout)      (None, 257, 256)             0         ['dense_1572[0][0]']          \n",
      "                                                                                                  \n",
      " add_1509 (Add)              (None, 257, 256)             0         ['dropout_2493[0][0]',        \n",
      "                                                                     'add_1508[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1541 (  (None, 257, 256)             512       ['add_1509[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_755 (  (None, 257, 256)             3155200   ['layer_normalization_1541[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1541[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1510 (Add)              (None, 257, 256)             0         ['multi_head_attention_755[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1509[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1542 (  (None, 257, 256)             512       ['add_1510[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1573 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1542[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dropout_2494 (Dropout)      (None, 257, 1024)            0         ['dense_1573[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1574 (Dense)          (None, 257, 256)             262400    ['dropout_2494[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2495 (Dropout)      (None, 257, 256)             0         ['dense_1574[0][0]']          \n",
      "                                                                                                  \n",
      " add_1511 (Add)              (None, 257, 256)             0         ['dropout_2495[0][0]',        \n",
      "                                                                     'add_1510[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1543 (  (None, 257, 256)             512       ['add_1511[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_756 (  (None, 257, 256)             3155200   ['layer_normalization_1543[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1543[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1512 (Add)              (None, 257, 256)             0         ['multi_head_attention_756[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1511[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1544 (  (None, 257, 256)             512       ['add_1512[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1575 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1544[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2496 (Dropout)      (None, 257, 1024)            0         ['dense_1575[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1576 (Dense)          (None, 257, 256)             262400    ['dropout_2496[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2497 (Dropout)      (None, 257, 256)             0         ['dense_1576[0][0]']          \n",
      "                                                                                                  \n",
      " add_1513 (Add)              (None, 257, 256)             0         ['dropout_2497[0][0]',        \n",
      "                                                                     'add_1512[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1545 (  (None, 257, 256)             512       ['add_1513[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_757 (  (None, 257, 256)             3155200   ['layer_normalization_1545[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1545[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1514 (Add)              (None, 257, 256)             0         ['multi_head_attention_757[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1513[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1546 (  (None, 257, 256)             512       ['add_1514[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1577 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1546[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2498 (Dropout)      (None, 257, 1024)            0         ['dense_1577[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1578 (Dense)          (None, 257, 256)             262400    ['dropout_2498[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2499 (Dropout)      (None, 257, 256)             0         ['dense_1578[0][0]']          \n",
      "                                                                                                  \n",
      " add_1515 (Add)              (None, 257, 256)             0         ['dropout_2499[0][0]',        \n",
      "                                                                     'add_1514[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1547 (  (None, 257, 256)             512       ['add_1515[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_758 (  (None, 257, 256)             3155200   ['layer_normalization_1547[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1547[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1516 (Add)              (None, 257, 256)             0         ['multi_head_attention_758[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1515[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1548 (  (None, 257, 256)             512       ['add_1516[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1579 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1548[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2500 (Dropout)      (None, 257, 1024)            0         ['dense_1579[0][0]']          \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_1580 (Dense)          (None, 257, 256)             262400    ['dropout_2500[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2501 (Dropout)      (None, 257, 256)             0         ['dense_1580[0][0]']          \n",
      "                                                                                                  \n",
      " add_1517 (Add)              (None, 257, 256)             0         ['dropout_2501[0][0]',        \n",
      "                                                                     'add_1516[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1549 (  (None, 257, 256)             512       ['add_1517[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_759 (  (None, 257, 256)             3155200   ['layer_normalization_1549[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1549[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1518 (Add)              (None, 257, 256)             0         ['multi_head_attention_759[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1517[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1550 (  (None, 257, 256)             512       ['add_1518[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1581 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1550[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2502 (Dropout)      (None, 257, 1024)            0         ['dense_1581[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1582 (Dense)          (None, 257, 256)             262400    ['dropout_2502[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2503 (Dropout)      (None, 257, 256)             0         ['dense_1582[0][0]']          \n",
      "                                                                                                  \n",
      " add_1519 (Add)              (None, 257, 256)             0         ['dropout_2503[0][0]',        \n",
      "                                                                     'add_1518[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1551 (  (None, 257, 256)             512       ['add_1519[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_760 (  (None, 257, 256)             3155200   ['layer_normalization_1551[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1551[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1520 (Add)              (None, 257, 256)             0         ['multi_head_attention_760[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1519[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1552 (  (None, 257, 256)             512       ['add_1520[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1583 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1552[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2504 (Dropout)      (None, 257, 1024)            0         ['dense_1583[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1584 (Dense)          (None, 257, 256)             262400    ['dropout_2504[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2505 (Dropout)      (None, 257, 256)             0         ['dense_1584[0][0]']          \n",
      "                                                                                                  \n",
      " add_1521 (Add)              (None, 257, 256)             0         ['dropout_2505[0][0]',        \n",
      "                                                                     'add_1520[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1553 (  (None, 257, 256)             512       ['add_1521[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_761 (  (None, 257, 256)             3155200   ['layer_normalization_1553[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1553[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1522 (Add)              (None, 257, 256)             0         ['multi_head_attention_761[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1521[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1554 (  (None, 257, 256)             512       ['add_1522[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1585 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1554[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2506 (Dropout)      (None, 257, 1024)            0         ['dense_1585[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1586 (Dense)          (None, 257, 256)             262400    ['dropout_2506[0][0]']        \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dropout_2507 (Dropout)      (None, 257, 256)             0         ['dense_1586[0][0]']          \n",
      "                                                                                                  \n",
      " add_1523 (Add)              (None, 257, 256)             0         ['dropout_2507[0][0]',        \n",
      "                                                                     'add_1522[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1555 (  (None, 257, 256)             512       ['add_1523[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_762 (  (None, 257, 256)             3155200   ['layer_normalization_1555[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1555[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1524 (Add)              (None, 257, 256)             0         ['multi_head_attention_762[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1523[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1556 (  (None, 257, 256)             512       ['add_1524[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1587 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1556[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2508 (Dropout)      (None, 257, 1024)            0         ['dense_1587[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1588 (Dense)          (None, 257, 256)             262400    ['dropout_2508[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2509 (Dropout)      (None, 257, 256)             0         ['dense_1588[0][0]']          \n",
      "                                                                                                  \n",
      " add_1525 (Add)              (None, 257, 256)             0         ['dropout_2509[0][0]',        \n",
      "                                                                     'add_1524[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1557 (  (None, 257, 256)             512       ['add_1525[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_763 (  (None, 257, 256)             3155200   ['layer_normalization_1557[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1557[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1526 (Add)              (None, 257, 256)             0         ['multi_head_attention_763[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1525[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1558 (  (None, 257, 256)             512       ['add_1526[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1589 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1558[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2510 (Dropout)      (None, 257, 1024)            0         ['dense_1589[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1590 (Dense)          (None, 257, 256)             262400    ['dropout_2510[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2511 (Dropout)      (None, 257, 256)             0         ['dense_1590[0][0]']          \n",
      "                                                                                                  \n",
      " add_1527 (Add)              (None, 257, 256)             0         ['dropout_2511[0][0]',        \n",
      "                                                                     'add_1526[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1559 (  (None, 257, 256)             512       ['add_1527[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_764 (  (None, 257, 256)             3155200   ['layer_normalization_1559[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1559[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1528 (Add)              (None, 257, 256)             0         ['multi_head_attention_764[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1527[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1560 (  (None, 257, 256)             512       ['add_1528[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1591 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1560[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2512 (Dropout)      (None, 257, 1024)            0         ['dense_1591[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1592 (Dense)          (None, 257, 256)             262400    ['dropout_2512[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2513 (Dropout)      (None, 257, 256)             0         ['dense_1592[0][0]']          \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " add_1529 (Add)              (None, 257, 256)             0         ['dropout_2513[0][0]',        \n",
      "                                                                     'add_1528[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1561 (  (None, 257, 256)             512       ['add_1529[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_765 (  (None, 257, 256)             3155200   ['layer_normalization_1561[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1561[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1530 (Add)              (None, 257, 256)             0         ['multi_head_attention_765[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1529[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1562 (  (None, 257, 256)             512       ['add_1530[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1593 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1562[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2514 (Dropout)      (None, 257, 1024)            0         ['dense_1593[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1594 (Dense)          (None, 257, 256)             262400    ['dropout_2514[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2515 (Dropout)      (None, 257, 256)             0         ['dense_1594[0][0]']          \n",
      "                                                                                                  \n",
      " add_1531 (Add)              (None, 257, 256)             0         ['dropout_2515[0][0]',        \n",
      "                                                                     'add_1530[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1563 (  (None, 257, 256)             512       ['add_1531[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_766 (  (None, 257, 256)             3155200   ['layer_normalization_1563[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1563[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1532 (Add)              (None, 257, 256)             0         ['multi_head_attention_766[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1531[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1564 (  (None, 257, 256)             512       ['add_1532[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1595 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1564[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2516 (Dropout)      (None, 257, 1024)            0         ['dense_1595[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1596 (Dense)          (None, 257, 256)             262400    ['dropout_2516[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2517 (Dropout)      (None, 257, 256)             0         ['dense_1596[0][0]']          \n",
      "                                                                                                  \n",
      " add_1533 (Add)              (None, 257, 256)             0         ['dropout_2517[0][0]',        \n",
      "                                                                     'add_1532[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1565 (  (None, 257, 256)             512       ['add_1533[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_767 (  (None, 257, 256)             3155200   ['layer_normalization_1565[0][\n",
      " MultiHeadAttention)                                                0]',                          \n",
      "                                                                     'layer_normalization_1565[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1534 (Add)              (None, 257, 256)             0         ['multi_head_attention_767[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1533[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1566 (  (None, 257, 256)             512       ['add_1534[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1597 (Dense)          (None, 257, 1024)            263168    ['layer_normalization_1566[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_2518 (Dropout)      (None, 257, 1024)            0         ['dense_1597[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1598 (Dense)          (None, 257, 256)             262400    ['dropout_2518[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_2519 (Dropout)      (None, 257, 256)             0         ['dense_1598[0][0]']          \n",
      "                                                                                                  \n",
      " add_1535 (Add)              (None, 257, 256)             0         ['dropout_2519[0][0]',        \n",
      "                                                                     'add_1534[0][0]']            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " layer_normalization_1567 (  (None, 257, 256)             512       ['add_1535[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_3  (None, 256)                  0         ['layer_normalization_1567[0][\n",
      " 6 (SlicingOpLambda)                                                0]']                          \n",
      "                                                                                                  \n",
      " dense_1599 (Dense)          (None, 4)                    1028      ['tf.__operators__.getitem_36[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 89151492 (340.09 MB)\n",
      "Trainable params: 89151492 (340.09 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Train: 2778 - Valid: 925 - Test: 925\n",
      "Train: 2778 - Valid: 925 - Test: 925\n",
      "Training for fold 1 ...\n",
      "2\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 1.1659 - acc: 0.4986 - auc: 0.7550\n",
      "Epoch 1: val_loss improved from inf to 0.63354, saving model to files/modelN_fold1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186/186 [==============================] - 1410s 7s/step - loss: 1.1659 - acc: 0.4986 - auc: 0.7550 - val_loss: 0.6335 - val_acc: 0.7625 - val_auc: 0.9323 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.6223 - acc: 0.7451 - auc: 0.9195\n",
      "Epoch 2: val_loss improved from 0.63354 to 0.37204, saving model to files/modelN_fold1.h5\n",
      "186/186 [==============================] - 1306s 7s/step - loss: 0.6223 - acc: 0.7451 - auc: 0.9195 - val_loss: 0.3720 - val_acc: 0.8664 - val_auc: 0.9743 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.3530 - acc: 0.8764 - auc: 0.9725\n",
      "Epoch 3: val_loss improved from 0.37204 to 0.26881, saving model to files/modelN_fold1.h5\n",
      "186/186 [==============================] - 1276s 7s/step - loss: 0.3530 - acc: 0.8764 - auc: 0.9725 - val_loss: 0.2688 - val_acc: 0.8934 - val_auc: 0.9887 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.2738 - acc: 0.8997 - auc: 0.9825\n",
      "Epoch 4: val_loss improved from 0.26881 to 0.24477, saving model to files/modelN_fold1.h5\n",
      "186/186 [==============================] - 1262s 7s/step - loss: 0.2738 - acc: 0.8997 - auc: 0.9825 - val_loss: 0.2448 - val_acc: 0.9163 - val_auc: 0.9907 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1917 - acc: 0.9288 - auc: 0.9906\n",
      "Epoch 5: val_loss did not improve from 0.24477\n",
      "186/186 [==============================] - 1188s 6s/step - loss: 0.1917 - acc: 0.9288 - auc: 0.9906 - val_loss: 0.2468 - val_acc: 0.9069 - val_auc: 0.9897 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1594 - acc: 0.9389 - auc: 0.9936\n",
      "Epoch 6: val_loss improved from 0.24477 to 0.19598, saving model to files/modelN_fold1.h5\n",
      "186/186 [==============================] - 1257s 7s/step - loss: 0.1594 - acc: 0.9389 - auc: 0.9936 - val_loss: 0.1960 - val_acc: 0.9298 - val_auc: 0.9936 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1859 - acc: 0.9355 - auc: 0.9914\n",
      "Epoch 7: val_loss did not improve from 0.19598\n",
      "186/186 [==============================] - 1237s 7s/step - loss: 0.1859 - acc: 0.9355 - auc: 0.9914 - val_loss: 0.2450 - val_acc: 0.9258 - val_auc: 0.9912 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1492 - acc: 0.9450 - auc: 0.9941\n",
      "Epoch 8: val_loss improved from 0.19598 to 0.12376, saving model to files/modelN_fold1.h5\n",
      "186/186 [==============================] - 1251s 7s/step - loss: 0.1492 - acc: 0.9450 - auc: 0.9941 - val_loss: 0.1238 - val_acc: 0.9501 - val_auc: 0.9964 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1386 - acc: 0.9456 - auc: 0.9949\n",
      "Epoch 9: val_loss improved from 0.12376 to 0.12319, saving model to files/modelN_fold1.h5\n",
      "186/186 [==============================] - 1230s 7s/step - loss: 0.1386 - acc: 0.9456 - auc: 0.9949 - val_loss: 0.1232 - val_acc: 0.9528 - val_auc: 0.9967 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1139 - acc: 0.9585 - auc: 0.9964\n",
      "Epoch 10: val_loss did not improve from 0.12319\n",
      "186/186 [==============================] - 1243s 7s/step - loss: 0.1139 - acc: 0.9585 - auc: 0.9964 - val_loss: 0.1567 - val_acc: 0.9433 - val_auc: 0.9942 - lr: 1.0000e-04\n",
      "3\n",
      "Training for fold 2 ...\n",
      "2\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 1.0403 - acc: 0.5537 - auc: 0.8025\n",
      "Epoch 1: val_loss improved from inf to 0.61871, saving model to files/modelN_fold2.h5\n",
      "186/186 [==============================] - 1252s 6s/step - loss: 1.0403 - acc: 0.5537 - auc: 0.8025 - val_loss: 0.6187 - val_acc: 0.7746 - val_auc: 0.9277 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.6156 - acc: 0.7421 - auc: 0.9176\n",
      "Epoch 2: val_loss improved from 0.61871 to 0.58394, saving model to files/modelN_fold2.h5\n",
      "186/186 [==============================] - 1199s 6s/step - loss: 0.6156 - acc: 0.7421 - auc: 0.9176 - val_loss: 0.5839 - val_acc: 0.7517 - val_auc: 0.9644 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.3999 - acc: 0.8481 - auc: 0.9650\n",
      "Epoch 3: val_loss improved from 0.58394 to 0.26748, saving model to files/modelN_fold2.h5\n",
      "186/186 [==============================] - 1184s 6s/step - loss: 0.3999 - acc: 0.8481 - auc: 0.9650 - val_loss: 0.2675 - val_acc: 0.9015 - val_auc: 0.9855 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.2523 - acc: 0.9021 - auc: 0.9847\n",
      "Epoch 4: val_loss improved from 0.26748 to 0.22013, saving model to files/modelN_fold2.h5\n",
      "186/186 [==============================] - 1186s 6s/step - loss: 0.2523 - acc: 0.9021 - auc: 0.9847 - val_loss: 0.2201 - val_acc: 0.9163 - val_auc: 0.9902 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1814 - acc: 0.9372 - auc: 0.9912\n",
      "Epoch 5: val_loss did not improve from 0.22013\n",
      "186/186 [==============================] - 1185s 6s/step - loss: 0.1814 - acc: 0.9372 - auc: 0.9912 - val_loss: 0.2640 - val_acc: 0.9136 - val_auc: 0.9884 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1573 - acc: 0.9426 - auc: 0.9935\n",
      "Epoch 6: val_loss did not improve from 0.22013\n",
      "186/186 [==============================] - 1180s 6s/step - loss: 0.1573 - acc: 0.9426 - auc: 0.9935 - val_loss: 0.2807 - val_acc: 0.9055 - val_auc: 0.9869 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1851 - acc: 0.9345 - auc: 0.9917\n",
      "Epoch 7: val_loss improved from 0.22013 to 0.14309, saving model to files/modelN_fold2.h5\n",
      "186/186 [==============================] - 1198s 6s/step - loss: 0.1851 - acc: 0.9345 - auc: 0.9917 - val_loss: 0.1431 - val_acc: 0.9541 - val_auc: 0.9954 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1192 - acc: 0.9585 - auc: 0.9961\n",
      "Epoch 8: val_loss improved from 0.14309 to 0.13549, saving model to files/modelN_fold2.h5\n",
      "186/186 [==============================] - 1242s 7s/step - loss: 0.1192 - acc: 0.9585 - auc: 0.9961 - val_loss: 0.1355 - val_acc: 0.9474 - val_auc: 0.9961 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1261 - acc: 0.9554 - auc: 0.9956\n",
      "Epoch 9: val_loss did not improve from 0.13549\n",
      "186/186 [==============================] - 1236s 7s/step - loss: 0.1261 - acc: 0.9554 - auc: 0.9956 - val_loss: 0.1560 - val_acc: 0.9555 - val_auc: 0.9939 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1105 - acc: 0.9612 - auc: 0.9961\n",
      "Epoch 10: val_loss improved from 0.13549 to 0.12072, saving model to files/modelN_fold2.h5\n",
      "186/186 [==============================] - 1206s 6s/step - loss: 0.1105 - acc: 0.9612 - auc: 0.9961 - val_loss: 0.1207 - val_acc: 0.9595 - val_auc: 0.9955 - lr: 1.0000e-04\n",
      "3\n",
      "Training for fold 3 ...\n",
      "2\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 1.0608 - acc: 0.5176 - auc: 0.7857\n",
      "Epoch 1: val_loss improved from inf to 0.98112, saving model to files/modelN_fold3.h5\n",
      "186/186 [==============================] - 1260s 6s/step - loss: 1.0608 - acc: 0.5176 - auc: 0.7857 - val_loss: 0.9811 - val_acc: 0.5601 - val_auc: 0.9089 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.6069 - acc: 0.7522 - auc: 0.9196\n",
      "Epoch 2: val_loss improved from 0.98112 to 0.57810, saving model to files/modelN_fold3.h5\n",
      "186/186 [==============================] - 1252s 7s/step - loss: 0.6069 - acc: 0.7522 - auc: 0.9196 - val_loss: 0.5781 - val_acc: 0.7665 - val_auc: 0.9508 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.3598 - acc: 0.8653 - auc: 0.9710\n",
      "Epoch 3: val_loss did not improve from 0.57810\n",
      "186/186 [==============================] - 1180s 6s/step - loss: 0.3598 - acc: 0.8653 - auc: 0.9710 - val_loss: 0.8897 - val_acc: 0.6869 - val_auc: 0.9424 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.3030 - acc: 0.8923 - auc: 0.9785\n",
      "Epoch 4: val_loss improved from 0.57810 to 0.33601, saving model to files/modelN_fold3.h5\n",
      "186/186 [==============================] - 1194s 6s/step - loss: 0.3030 - acc: 0.8923 - auc: 0.9785 - val_loss: 0.3360 - val_acc: 0.8812 - val_auc: 0.9812 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1879 - acc: 0.9325 - auc: 0.9909\n",
      "Epoch 5: val_loss did not improve from 0.33601\n",
      "186/186 [==============================] - 1185s 6s/step - loss: 0.1879 - acc: 0.9325 - auc: 0.9909 - val_loss: 1.1000 - val_acc: 0.6788 - val_auc: 0.9326 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.2651 - acc: 0.9024 - auc: 0.9832\n",
      "Epoch 6: val_loss improved from 0.33601 to 0.27708, saving model to files/modelN_fold3.h5\n",
      "186/186 [==============================] - 1196s 6s/step - loss: 0.2651 - acc: 0.9024 - auc: 0.9832 - val_loss: 0.2771 - val_acc: 0.8947 - val_auc: 0.9901 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1792 - acc: 0.9392 - auc: 0.9918\n",
      "Epoch 7: val_loss improved from 0.27708 to 0.25221, saving model to files/modelN_fold3.h5\n",
      "186/186 [==============================] - 1250s 7s/step - loss: 0.1792 - acc: 0.9392 - auc: 0.9918 - val_loss: 0.2522 - val_acc: 0.9069 - val_auc: 0.9920 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1598 - acc: 0.9392 - auc: 0.9932\n",
      "Epoch 8: val_loss did not improve from 0.25221\n",
      "186/186 [==============================] - 1181s 6s/step - loss: 0.1598 - acc: 0.9392 - auc: 0.9932 - val_loss: 0.3134 - val_acc: 0.8677 - val_auc: 0.9853 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1578 - acc: 0.9426 - auc: 0.9933\n",
      "Epoch 9: val_loss improved from 0.25221 to 0.21255, saving model to files/modelN_fold3.h5\n",
      "186/186 [==============================] - 1196s 6s/step - loss: 0.1578 - acc: 0.9426 - auc: 0.9933 - val_loss: 0.2126 - val_acc: 0.9204 - val_auc: 0.9909 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1187 - acc: 0.9581 - auc: 0.9961\n",
      "Epoch 10: val_loss improved from 0.21255 to 0.12043, saving model to files/modelN_fold3.h5\n",
      "186/186 [==============================] - 1238s 7s/step - loss: 0.1187 - acc: 0.9581 - auc: 0.9961 - val_loss: 0.1204 - val_acc: 0.9474 - val_auc: 0.9966 - lr: 1.0000e-04\n",
      "3\n",
      "Training for fold 4 ...\n",
      "2\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 1.1187 - acc: 0.4992 - auc: 0.7637\n",
      "Epoch 1: val_loss improved from inf to 0.67635, saving model to files/modelN_fold4.h5\n",
      "186/186 [==============================] - 1250s 6s/step - loss: 1.1187 - acc: 0.4992 - auc: 0.7637 - val_loss: 0.6764 - val_acc: 0.7014 - val_auc: 0.9217 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.6199 - acc: 0.7395 - auc: 0.9163\n",
      "Epoch 2: val_loss improved from 0.67635 to 0.40944, saving model to files/modelN_fold4.h5\n",
      "186/186 [==============================] - 1252s 7s/step - loss: 0.6199 - acc: 0.7395 - auc: 0.9163 - val_loss: 0.4094 - val_acc: 0.8351 - val_auc: 0.9812 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.3760 - acc: 0.8633 - auc: 0.9683\n",
      "Epoch 3: val_loss improved from 0.40944 to 0.24210, saving model to files/modelN_fold4.h5\n",
      "186/186 [==============================] - 1282s 7s/step - loss: 0.3760 - acc: 0.8633 - auc: 0.9683 - val_loss: 0.2421 - val_acc: 0.9135 - val_auc: 0.9896 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.2574 - acc: 0.9045 - auc: 0.9838\n",
      "Epoch 4: val_loss did not improve from 0.24210\n",
      "186/186 [==============================] - 1233s 7s/step - loss: 0.2574 - acc: 0.9045 - auc: 0.9838 - val_loss: 0.2941 - val_acc: 0.8838 - val_auc: 0.9903 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.2108 - acc: 0.9258 - auc: 0.9885\n",
      "Epoch 5: val_loss did not improve from 0.24210\n",
      "186/186 [==============================] - 1228s 7s/step - loss: 0.2108 - acc: 0.9258 - auc: 0.9885 - val_loss: 0.3855 - val_acc: 0.8743 - val_auc: 0.9894 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1808 - acc: 0.9399 - auc: 0.9908\n",
      "Epoch 6: val_loss improved from 0.24210 to 0.16590, saving model to files/modelN_fold4.h5\n",
      "186/186 [==============================] - 1245s 7s/step - loss: 0.1808 - acc: 0.9399 - auc: 0.9908 - val_loss: 0.1659 - val_acc: 0.9419 - val_auc: 0.9959 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1593 - acc: 0.9447 - auc: 0.9935\n",
      "Epoch 7: val_loss did not improve from 0.16590\n",
      "186/186 [==============================] - 1257s 7s/step - loss: 0.1593 - acc: 0.9447 - auc: 0.9935 - val_loss: 0.2010 - val_acc: 0.9189 - val_auc: 0.9945 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1400 - acc: 0.9490 - auc: 0.9946\n",
      "Epoch 8: val_loss improved from 0.16590 to 0.14890, saving model to files/modelN_fold4.h5\n",
      "186/186 [==============================] - 1199s 6s/step - loss: 0.1400 - acc: 0.9490 - auc: 0.9946 - val_loss: 0.1489 - val_acc: 0.9432 - val_auc: 0.9967 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1224 - acc: 0.9561 - auc: 0.9960\n",
      "Epoch 9: val_loss improved from 0.14890 to 0.12808, saving model to files/modelN_fold4.h5\n",
      "186/186 [==============================] - 1190s 6s/step - loss: 0.1224 - acc: 0.9561 - auc: 0.9960 - val_loss: 0.1281 - val_acc: 0.9473 - val_auc: 0.9975 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1242 - acc: 0.9575 - auc: 0.9951\n",
      "Epoch 10: val_loss improved from 0.12808 to 0.09466, saving model to files/modelN_fold4.h5\n",
      "186/186 [==============================] - 1197s 6s/step - loss: 0.1242 - acc: 0.9575 - auc: 0.9951 - val_loss: 0.0947 - val_acc: 0.9662 - val_auc: 0.9980 - lr: 1.0000e-04\n",
      "3\n",
      "Training for fold 5 ...\n",
      "2\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 1.0044 - acc: 0.5508 - auc: 0.8049\n",
      "Epoch 1: val_loss improved from inf to 0.71674, saving model to files/modelN_fold5.h5\n",
      "186/186 [==============================] - 1266s 6s/step - loss: 1.0044 - acc: 0.5508 - auc: 0.8049 - val_loss: 0.7167 - val_acc: 0.7284 - val_auc: 0.9206 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.5763 - acc: 0.7658 - auc: 0.9306\n",
      "Epoch 2: val_loss improved from 0.71674 to 0.34266, saving model to files/modelN_fold5.h5\n",
      "186/186 [==============================] - 1258s 7s/step - loss: 0.5763 - acc: 0.7658 - auc: 0.9306 - val_loss: 0.3427 - val_acc: 0.8824 - val_auc: 0.9800 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.3713 - acc: 0.8714 - auc: 0.9680\n",
      "Epoch 3: val_loss improved from 0.34266 to 0.21447, saving model to files/modelN_fold5.h5\n",
      "186/186 [==============================] - 1206s 6s/step - loss: 0.3713 - acc: 0.8714 - auc: 0.9680 - val_loss: 0.2145 - val_acc: 0.9338 - val_auc: 0.9900 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.2346 - acc: 0.9129 - auc: 0.9862\n",
      "Epoch 4: val_loss improved from 0.21447 to 0.20124, saving model to files/modelN_fold5.h5\n",
      "186/186 [==============================] - 1200s 6s/step - loss: 0.2346 - acc: 0.9129 - auc: 0.9862 - val_loss: 0.2012 - val_acc: 0.9351 - val_auc: 0.9922 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1911 - acc: 0.9295 - auc: 0.9910\n",
      "Epoch 5: val_loss improved from 0.20124 to 0.13315, saving model to files/modelN_fold5.h5\n",
      "186/186 [==============================] - 1257s 7s/step - loss: 0.1911 - acc: 0.9295 - auc: 0.9910 - val_loss: 0.1331 - val_acc: 0.9568 - val_auc: 0.9951 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1595 - acc: 0.9413 - auc: 0.9937\n",
      "Epoch 6: val_loss did not improve from 0.13315\n",
      "186/186 [==============================] - 1179s 6s/step - loss: 0.1595 - acc: 0.9413 - auc: 0.9937 - val_loss: 0.1603 - val_acc: 0.9527 - val_auc: 0.9930 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1497 - acc: 0.9480 - auc: 0.9937\n",
      "Epoch 7: val_loss did not improve from 0.13315\n",
      "186/186 [==============================] - 1283s 7s/step - loss: 0.1497 - acc: 0.9480 - auc: 0.9937 - val_loss: 0.1574 - val_acc: 0.9486 - val_auc: 0.9952 - lr: 1.0000e-04\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186/186 [==============================] - ETA: 0s - loss: 0.1327 - acc: 0.9531 - auc: 0.9954\n",
      "Epoch 8: val_loss did not improve from 0.13315\n",
      "186/186 [==============================] - 1174s 6s/step - loss: 0.1327 - acc: 0.9531 - auc: 0.9954 - val_loss: 0.2457 - val_acc: 0.9203 - val_auc: 0.9909 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1349 - acc: 0.9531 - auc: 0.9955\n",
      "Epoch 9: val_loss did not improve from 0.13315\n",
      "186/186 [==============================] - 1224s 7s/step - loss: 0.1349 - acc: 0.9531 - auc: 0.9955 - val_loss: 0.4302 - val_acc: 0.8865 - val_auc: 0.9795 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.0962 - acc: 0.9652 - auc: 0.9977\n",
      "Epoch 10: val_loss did not improve from 0.13315\n",
      "186/186 [==============================] - 1184s 6s/step - loss: 0.0962 - acc: 0.9652 - auc: 0.9977 - val_loss: 0.1598 - val_acc: 0.9473 - val_auc: 0.9954 - lr: 1.0000e-04\n",
      "3\n",
      "Evaluating the test set...\n",
      "58/58 [==============================] - 116s 2s/step\n",
      "58/58 [==============================] - 118s 2s/step\n",
      "58/58 [==============================] - 118s 2s/step\n",
      "58/58 [==============================] - 119s 2s/step\n",
      "58/58 [==============================] - 115s 2s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Yellow_rust       0.98      0.97      0.97       229\n",
      "  Brown_rust       0.96      0.95      0.95       234\n",
      "     Healthy       0.98      0.98      0.98       238\n",
      "Blast_Leaves       0.97      1.00      0.98       224\n",
      "\n",
      "    accuracy                           0.97       925\n",
      "   macro avg       0.97      0.97      0.97       925\n",
      "weighted avg       0.97      0.97      0.97       925\n",
      "\n",
      "AUC-ROC (Yellow_rust): 0.9977\n",
      "AUC-ROC (Brown_rust): 0.9955\n",
      "AUC-ROC (Healthy): 0.9985\n",
      "AUC-ROC (Blast_Leaves): 0.9999\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 10 epochs train and test\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "\n",
    "class ClassToken(Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        w_init = tf.random_normal_initializer()\n",
    "        self.w = tf.Variable(\n",
    "            initial_value = w_init(shape=(1, 1, input_shape[-1]), dtype=tf.float32),\n",
    "            trainable = True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        hidden_dim = self.w.shape[-1]\n",
    "\n",
    "        cls = tf.broadcast_to(self.w, [batch_size, 1, hidden_dim])\n",
    "        cls = tf.cast(cls, dtype=inputs.dtype)\n",
    "        return cls\n",
    "\n",
    "def mlp(x, cf):\n",
    "    x = Dense(cf[\"mlp_dim\"], activation=\"gelu\")(x)\n",
    "    x = Dropout(cf[\"dropout_rate\"])(x)\n",
    "    x = Dense(cf[\"hidden_dim\"])(x)\n",
    "    x = Dropout(cf[\"dropout_rate\"])(x)\n",
    "    return x\n",
    "\n",
    "def transformer_encoder(x, cf):\n",
    "    skip_1 = x\n",
    "    x = LayerNormalization()(x)\n",
    "    x = MultiHeadAttention(\n",
    "        num_heads=cf[\"num_heads\"], key_dim=cf[\"hidden_dim\"]\n",
    "    )(x, x)\n",
    "    x = Add()([x, skip_1])\n",
    "\n",
    "    skip_2 = x\n",
    "    x = LayerNormalization()(x)\n",
    "    x = mlp(x, cf)\n",
    "    x = Add()([x, skip_2])\n",
    "\n",
    "    return x\n",
    "\n",
    "def ViT(cf):\n",
    "    \"\"\" Inputs \"\"\"\n",
    "    input_shape = (cf[\"num_patches\"], cf[\"patch_size\"]*cf[\"patch_size\"]*cf[\"num_channels\"])\n",
    "    inputs = Input(input_shape)     ## (None, 256, 3072)\n",
    "\n",
    "    \"\"\" Patch + Position Embeddings \"\"\"\n",
    "    patch_embed = Dense(cf[\"hidden_dim\"])(inputs)   ## (None, 256, 768)\n",
    "\n",
    "    positions = tf.range(start=0, limit=cf[\"num_patches\"], delta=1)\n",
    "    pos_embed = Embedding(input_dim=cf[\"num_patches\"], output_dim=cf[\"hidden_dim\"])(positions) ## (256, 768)\n",
    "    embed = patch_embed + pos_embed ## (None, 256, 768)\n",
    "\n",
    "    \"\"\" Adding Class Token \"\"\"\n",
    "    token = ClassToken()(embed)\n",
    "    x = Concatenate(axis=1)([token, embed]) ## (None, 257, 768)\n",
    "\n",
    "    for _ in range(cf[\"num_layers\"]):\n",
    "        x = transformer_encoder(x, cf)\n",
    "\n",
    "    \"\"\" Classification Head \"\"\"\n",
    "    x = LayerNormalization()(x)     ## (None, 257, 768)\n",
    "    x = x[:, 0, :]\n",
    "    x = Dense(cf[\"num_classes\"], activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs, x)\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config = {}\n",
    "    config[\"num_layers\"] = 24\n",
    "#     config[\"hidden_dim\"] = 768\n",
    "#     config[\"mlp_dim\"] =3072\n",
    "    config[\"num_heads\"] = 12\n",
    "    config[\"dropout_rate\"] = 0.1\n",
    "    config[\"num_patches\"] = 256\n",
    "    config[\"patch_size\"] = 32\n",
    "    config[\"num_channels\"] = 3\n",
    "    config[\"num_classes\"] = 4\n",
    "\n",
    "    config[\"hidden_dim\"] = 256\n",
    "    config[\"mlp_dim\"] = 1024  \n",
    "\n",
    "    model = ViT(config)\n",
    "    model.summary()\n",
    "\n",
    "\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive/')\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from keras.metrics import AUC\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
    "from patchify import patchify\n",
    "# import tensorflow_hub as hub\n",
    "# Assuming you have already imported or defined the ViT model\n",
    "# ...\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "#from project import ViT\n",
    "hp = {\n",
    "    \"image_size\": 512,\n",
    "    \"num_channels\": 3,\n",
    "    \"patch_size\": 64,\n",
    "    \"num_classes\": 4,\n",
    "    \"class_names\": [\"Yellow_rust\",\"Brown_rust\", \"Healthy\",\"Blast_Leaves\"],\n",
    "    \"num_layers\": 24,\n",
    "    \"hidden_dim\": 256,\n",
    "    \"mlp_dim\": 1024,\n",
    "    \"num_heads\": 4,\n",
    "    \"dropout_rate\": 0.1,\n",
    "    \"batch_size\": 16,\n",
    "    \"lr\": 1e-4,\n",
    "    \"num_epochs\": 10\n",
    "}\n",
    "hp[\"num_patches\"] = (hp[\"image_size\"] ** 2) // (hp[\"patch_size\"] ** 2)\n",
    "hp[\"flat_patches_shape\"] = (hp[\"num_patches\"], hp[\"patch_size\"] * hp[\"patch_size\"] * hp[\"num_channels\"])\n",
    "\n",
    "\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "\n",
    "def load_data(path, split=0.20):\n",
    "    images = glob(os.path.join(path, \"*\", \"*.jpg\"))\n",
    "\n",
    "    # Separate images by class\n",
    "    images_class_BKL = [image for image in images if \"Yellow_rust\" in image]\n",
    "    images_class_NV = [image for image in images if \"Brown_rust\" in image]\n",
    "    images_class_MEL2 = [image for image in images if \"Healthy\" in image]\n",
    "    images_class_BlastLeaves = [image for image in images if \"Blast_Leaves\" in image]\n",
    "\n",
    "    # Oversample to 33,000 to match the largest class (BKL)\n",
    "    target_size = len(images_class_BKL)\n",
    "    #print(images_class_BKL)\n",
    "    images_class_NV = np.random.choice(images_class_NV, size=target_size, replace=True).tolist()\n",
    "    images_class_MEL2 = np.random.choice(images_class_MEL2, size=target_size, replace=True).tolist()\n",
    "    images_class_BlastLeaves = np.random.choice(images_class_BlastLeaves, size=target_size, replace=True).tolist()\n",
    "    # Concatenate lists again and shuffle\n",
    "    images = shuffle(images_class_BKL + images_class_NV + images_class_MEL2+ images_class_BlastLeaves)\n",
    "\n",
    "    split_size = int(len(images) * split)\n",
    "    train_x, valid_x = train_test_split(images, test_size=split_size, random_state=42)\n",
    "    train_x, test_x = train_test_split(train_x, test_size=split_size, random_state=42)\n",
    "    print(f\"Train: {len(train_x)} - Valid: {len(valid_x)} - Test: {len(test_x)}\")\n",
    "\n",
    "    return train_x, valid_x, test_x\n",
    "\n",
    "\n",
    "def process_image_label(path):\n",
    "    path = path.decode()\n",
    "    image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (hp[\"image_size\"], hp[\"image_size\"]))\n",
    "    image = image / 255.0\n",
    "\n",
    "    patch_shape = (hp[\"patch_size\"], hp[\"patch_size\"], hp[\"num_channels\"])\n",
    "    patches = patchify(image, patch_shape, hp[\"patch_size\"])\n",
    "    patches = np.reshape(patches, hp[\"flat_patches_shape\"])\n",
    "    patches = patches.astype(np.float32)\n",
    "\n",
    "    class_name = path.split(\"/\")[-2]\n",
    "    class_idx = hp[\"class_names\"].index(class_name)\n",
    "    class_idx = np.array(class_idx, dtype=np.int32)\n",
    "    return patches, class_idx\n",
    "\n",
    "\n",
    "def parse(path):\n",
    "    patches, labels = tf.numpy_function(process_image_label, [path], [tf.float32, tf.int32])\n",
    "    labels = tf.one_hot(labels, hp[\"num_classes\"])\n",
    "\n",
    "    patches.set_shape(hp[\"flat_patches_shape\"])\n",
    "    labels.set_shape(hp[\"num_classes\"])\n",
    "\n",
    "    return patches, labels\n",
    "\n",
    "\n",
    "def tf_dataset(images, batch=32):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((images))\n",
    "    ds = ds.map(parse).batch(batch).prefetch(8)\n",
    "    return ds\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    model = ViT(hp)\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        optimizer=tf.keras.optimizers.Adam(hp[\"lr\"], clipvalue=1.0),\n",
    "        metrics=[\"acc\", AUC(name='auc', multi_label=True)]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_dir(\"files\")\n",
    "    dataset_path = '/home/ali/Music/PYTHON/WholeDataset'\n",
    "    model_path = os.path.join(\"files\", \"model3.h5\")\n",
    "    csv_path = os.path.join(\"files\", \"log2.csv\")\n",
    "    train_x, valid_x, test_x = load_data(dataset_path)\n",
    "    images = train_x + valid_x\n",
    "    print(f\"Train: {len(train_x)} - Valid: {len(valid_x)} - Test: {len(test_x)}\")\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    fold_no = 1\n",
    "\n",
    "    for train, val in kfold.split(images):\n",
    "        print(f'Training for fold {fold_no} ...')\n",
    "        train_ds = tf_dataset(np.array(images)[train], batch=hp[\"batch_size\"])\n",
    "        valid_ds = tf_dataset(np.array(images)[val], batch=hp[\"batch_size\"])\n",
    "        model = get_model()\n",
    "        callbacks = [\n",
    "            ModelCheckpoint(f\"files/modelN_fold{fold_no}.h5\", monitor='val_loss', verbose=1, save_best_only=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, min_lr=1e-10, verbose=1),\n",
    "            CSVLogger(f\"files/log2_fold{fold_no}.csv\"),\n",
    "            EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=False),\n",
    "        ]\n",
    "        print(2)\n",
    "        model.fit(train_ds, epochs=hp[\"num_epochs\"], validation_data=valid_ds, callbacks=callbacks)\n",
    "        fold_no += 1\n",
    "        print(3)\n",
    "\n",
    "    # Evaluating on the test set\n",
    "    print(\"Evaluating the test set...\")\n",
    "    test_ds = tf_dataset(test_x, batch=hp[\"batch_size\"])\n",
    "    all_preds = []\n",
    "    custom_objects = {\"ClassToken\": ClassToken}\n",
    "    for fold_no in range(1, 6):\n",
    "        with tf.keras.utils.custom_object_scope(custom_objects):\n",
    "            fold_model = tf.keras.models.load_model(f\"files/modelN_fold{fold_no}.h5\")\n",
    "        y_pred_probs = fold_model.predict(test_ds)\n",
    "        all_preds.append(y_pred_probs)\n",
    "\n",
    "    avg_preds = np.mean(all_preds, axis=0)\n",
    "    final_preds = np.argmax(avg_preds, axis=1)\n",
    "    y_true = [hp[\"class_names\"].index(img.split(\"/\")[-2]) for img in test_x]\n",
    "    print(classification_report(y_true, final_preds, target_names=hp[\"class_names\"]))\n",
    "    roc_aucs = []\n",
    "\n",
    "    for i, class_name in enumerate(hp[\"class_names\"]):\n",
    "        auc_val = roc_auc_score((np.array(y_true) == i).astype(int), avg_preds[:, i])\n",
    "        roc_aucs.append(auc_val)\n",
    "        print(f\"AUC-ROC ({class_name}): {auc_val:.4f}\")\n",
    "\n",
    "    for i, class_name in enumerate(hp[\"class_names\"]):\n",
    "        fpr, tpr, _ = roc_curve((np.array(y_true) == i).astype(int), avg_preds[:, i])\n",
    "        plt.plot(fpr, tpr, label=f\"{class_name} (AUC = {roc_aucs[i]:.2f})\")\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], color='grey', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1157\n",
      "1128\n",
      "1500\n",
      "1157\n",
      "1157\n",
      "1157\n",
      "4628\n",
      "Train: 2778 - Valid: 925 - Test: 925\n",
      "Evaluating the test set...\n",
      "58/58 [==============================] - 136s 2s/step\n",
      "58/58 [==============================] - 123s 2s/step\n",
      "58/58 [==============================] - 114s 2s/step\n",
      "58/58 [==============================] - 110s 2s/step\n",
      "58/58 [==============================] - 116s 2s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Yellow_rust       0.95      0.97      0.96       214\n",
      "  Brown_rust       0.97      0.94      0.95       233\n",
      "     Healthy       0.98      0.97      0.97       245\n",
      "Blast_Leaves       0.98      1.00      0.99       233\n",
      "\n",
      "    accuracy                           0.97       925\n",
      "   macro avg       0.97      0.97      0.97       925\n",
      "weighted avg       0.97      0.97      0.97       925\n",
      "\n",
      "AUC-ROC (Yellow_rust): 0.9985\n",
      "AUC-ROC (Brown_rust): 0.9982\n",
      "AUC-ROC (Healthy): 0.9984\n",
      "AUC-ROC (Blast_Leaves): 0.9999\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAAsTAAALEwEAmpwYAABQhklEQVR4nO3dd3hUdfb48fcJIB0SEkCkhiIdAiQUIRSp0mwICC5iL4t17btf1/Xn7uKuvaxYUKyArKKhgwiCICU0qUoVAgEhQCBAKMn5/XFvZoeQMoFMJsmc1/Pkycyt596ZuefW8xFVxRhjTPAKCXQAxhhjAssSgTHGBDlLBMYYE+QsERhjTJCzRGCMMUHOEoExxgQ5SwSFjIhsFJHugY6jsBCRZ0TkgwDNe4KIvBCIeec3ERkpInMvctyL/k6KyBIRaXMx414sEXlARF4syHkWdZYIciAiu0TklIikiMh+d8NQwZ/zVNXmqrrQn/PIICKlReSfIrLbXc6tIvK4iEhBzD+LeLqLSIJ3N1X9h6re6af5iYg8KCIbROSEiCSIyBQRaemP+V0sEXlORD67lGmo6ueq2seHeV2Q/C72Oykig4DjqrrGff+ciJx1f09HRWSpiHTKNE6oiLzj/t5Oish6Ebkti2mPEJF4d1qJIjJLRLq4vd8HRopItRxiKxKffUGxRJC7QapaAYgC2gBPBzacvBORktn0mgL0BPoDFYE/AHcDr/shBhGRwvZ9ex14CHgQqAJcCXwDDMjvGeXwGfhdAOd9L/Bppm6T3d9TBLAA5zsIgIhcBnwH1AU6AZWBx4GxIvKo13CPAq8B/wCqA3WA/wDXAqhqKjALGJVDbPn22Qfys803qmp/2fwBu4BeXu//Bczwet8RWAocBdYB3b36VQE+AvYBR4BvvPoNBNa64y0FWmWeJ3AFcAqo4tWvDXAIKOW+vx3Y7E5/DlDXa1gF/ghsBXZmsWw9gVSgdqbuHYA0oKH7fiHwT2AFcAz4NlNMOa2DhcDfgSXusjQEbnNjPg7sAO5xhy3vDpMOpLh/VwDPAZ+5w9Rzl+tWYLe7Lv7sNb+ywMfu+tgMPAEkZPPZNnKXs30On/8E4G1ghhvvcqCBV//XgT3uelkFxHr1ew74L/CZ2/9OoD3wk7uuEoG3gMu8xmkOzAMOAweAZ4B+wBngrLtO1rnDVgbGu9PZC7wAlHD7jXbX+atAkttvNPCj21/cfr+7sa0HWuDsBJx155cCTMv8OwBKuHFtd9fJKjJ9h9zhLnM/z1qZ1slnXu+buZ9nVff9HW5M5TNNa5gbTyV3uVOAm3L57Y4EFlzCZ78QuNPrvWf9ZfX7At4BXso0jW+BR93XVwBfAQfd4R8M9PbtvFgDHUBh/sv0A6jl/mBed9/XdH9k/XGOrHq77zO+1DOAyUAYUAro5nZv437ZO7g/qlvd+ZTOYp7fA3d5xfNvYJz7+lpgG9AUKAn8BVia6Ys6Dychlc1i2cYCP2Sz3L/xvw30QpwNTQucjfVX/G/DnNs6WIizwW7uxlgKZ4+rAc7GqBtwEmjrDt+dTBtusk4E7+Ns9FsDp4Gm3svkrvNawM+Zp+c13XuB33L5/Ce4y9Pejf9zYJJX/1uAcLffn4D9QBmvuM8C17nrpizQDidxlnSXZTPwsDt8RZyN+p+AMu77DpnXgde8pwLvup9JNZxEnfGZjQbOAQ+48yrL+YmgL84GPNT9HJoCNbyW+YUcfgeP4/wOGrvjtgbCs1h3zYETOXyWl7mf1yGgpNttEvBxFtMq6S5PX5zEeC5jnBw+u7bA4Uv47BeSeyLw/L6Arjg7BeL2D8NJhFe4n/8q4Fl3uevj7AT1DfQ2LuOvsB2qF0bfiMhxnA/5d+CvbvdbgJmqOlNV01V1HhAP9BeRGsA1wL2qekRVz6rqD+54dwPvqupyVU1T1Y9xNmYds5j3F8DN4JxaAYa73cD5Mv9TVTer6jmcw+QoEanrNf4/VfWwqp7KYtoROBuerCS6/TN8qqobVPUE8H/AUBEpkdM68Bp3gqpuVNVz7nqYoarb1fEDMBeIzSaO7PxNVU+p6jqco5DWbvehwD/cdZ4AvJHDNMJzWH5vU1V1hbuOP8c5RQiAqn6mqknusr0MlMbZQGb4SVW/cdfNKVVdparL3OF34WzIu7nDDgT2q+rLqpqqqsdVdXlWAYlIdZx1/LCqnlDV33H28Id7DbZPVd9055X58z+Lk2ia4Gy4NquqL+sCnCObv6jqL+5nuE5Vk7IYLhTniCGzoSJyFGcjeRcwxF23kM130u1/yO0fDhzyGic7x3GOHrLi62efG+/f12Kc5JDxXR6C8/nvA2Jwdo6eV9UzqroDZ2dmeJZTDQBLBLm7TlUr4uytNuF/G8i6wE3uRa+j7pe7C1ADqI2zN3Iki+nVBf6UabzaOHsOmX0FdHITS1ec0yaLvabzutc0DuPsodX0Gn9PDst1yI01KzXc/llN5zecPfsIcl4HWcYgIteIyDIROewO35/zk44v9nu9PglkXMC/ItP8clr+JLJffl/mhYg8JiKbRSTZXZbKnL8smZf9ShGZ7l4IPYaTvDOGr41zusUXdXE+g0Sv9f4uzpFBlvP2pqrf45yWehv4XUTeE5FKPs7b1ziP4CSbzL5U1VCcc/sbcI6SMmT5nXTPwUe4/ZOACB/Oy1cEkrPp5+tnnxvPOlbnMGAS7o4bMAJnxwGcz+uKTL+TZ3DWQaFgicBH7t7rBOAlt9MenD3lUK+/8qo61u1XRURCs5jUHuDvmcYrp6oTs5jnEZw95mE4X6xJ7hcuYzr3ZJpOWVVd6j2JHBbpO6CDiNT27igiHXB+7N97dfYepg7OHuWhXNbBBTGISGmc5PYSUN3dIMzESWC5xeuLRJxTQlnFndl8oJaIRF/MjEQkFucaxFAgzF2WZP63LHDh8rwDbAEaqWolnI1BxvB7cE4ZZCXzdPbgHEVGeK33SqraPIdxzp+g6huq2g7nPP2VOKd8ch3PnXeDXIYB57SliEjNrHqq6iGco+Pn3B0dcL6T14hI+UyD34izvMtwrrGcxjnllpOmOEeLWfHlsz8BlPN6f3kWw2ReVxOBIe5ReQec7zo462xnpt9JRVXtTyFhiSBvXgN6i0hrnIuAg0Skr4iUEJEy7u2PtdzD7FnAf0QkTERKiUhXdxrvA/eKSAf3TpryIjJARLLaewLnVNAonEPNL7y6jwOeFpHmACJSWURu8nVBVPU7nB/EVyLS3F2Gju5yvaOqW70Gv0VEmolIOeB54L+qmpbTOshmtpfhnD45CJwTkWsA71saDwDhIpLdIX1uvsRZJ2HuBmhMdgO6y/cfYKIb82Vu/MNF5Ckf5lUR51z1QaCkiDyLczEzt3GOASki0gS4z6vfdKCGiDwszm29Fd2kDM56qZdx15X7/ZoLvCwilUQkREQaiEg3fCAiMe73rxTOBi8V52gzY17ZJSSAD4D/JyKN3O9vKxEJzzyQqp7B2bBnG5Oq/oJzk8MTbqdPgQRgiojUc383fXFO8T2nqsmqmoxzrv1tEblORMq5w10jIv/ymnw3nN9gVvP15bNfC9zgTr8hzoXsHKlzm+whdx3NUdWjbq8VwHEReVJEyrq/lRYiEpPbNAuKJYI8UNWDwCfAs6q6B+eC7TM4G4M9OHtVGev0Dzh7zltwri087E4jHufc6Fs4h8/bcC5EZScO5y6H/e458YxYpgIvApPc0wwbcK5L5MWNOLfwzca5E+MznDtRHsg03Kc4R0P7cS5kPujGkNs6OI+qHnfH/RJn2Ue4y5fRfwvOXtUO9xA6q9NlOXkeZ0OyE2cj9F+cvcfsPMj/TpEcxTnlcT0wzYd5zcFZb7/inC5LJedTUQCP4SzzcZwdgskZPdx10xsYhLOetwI93N4Zt1gmichq9/UonMS6CWdd/hffT3dUcud/xI09CedGBHA+/2bu+v8mi3Ffwfn85uIktfE4F0uz8i7O7yAn/wbuFpFqqnoa5465PTh3aB1z5/dnVc2ID/d6zKM4N0hkfO/G4Nz+iYiUwTnl+HEO883ts38V5+6pA+50Pr9wEln6wl0Gz06bu9M0EOf60k7+lywudocn32Vc4TYmSyKyEOdOj4A83XspROQ+YLiq+rSnbPKfiCwBxrh7ywU1zwdwbml9IteBDeDclmVMseCea66Pcx65Ec6tmG8FNKggp6qdAzDPNwt6nkWdJQJTnFyGczoiEudwfxLOuWBjTA7s1JAxxgQ5u1hsjDFBrsidGoqIiNB69eoFOgxjjClSVq1adUhVq2bVr8glgnr16hEfHx/oMIwxpkgRkd+y62enhowxJshZIjDGmCBnicAYY4KcJQJjjAlylgiMMSbI+S0RiMiHIvK7iGzIpr+IyBsisk1EfhaRtv6KxRhjTPb8eUQwAadZuexcg1MPphFOXfJ3/BiLMcaYbPjtOQJVXSQi9XIY5FrgE7ehlWUiEioiNfLQZF6+ODL5S45Nn+77CMf3w4mDFzWvg6SRRFqW/RRIt3IfxpgspIWU4Fyp0pytLAz9YmW+Tz+QD5TV5Pz67QlutwsSgYjcjXPUQJ06dS56hllt9E+udFbq7gbZtQvjSjuDpp1F0p0NeZrk/WDqZIizoS+XLhf2zMgBWfQyxgSvY5WrsatRDCXSzlJn7xK/zKNIPFmsqu8B7wFER0df1G7zkclfsv+vTrvz5WL+1zBQuZgYpkYe4ssmR2lcpTG/HzvNoRMXtmVS9+x2yqSncYLSnCgZxpESFzTK5JPKae0JS+uaZb9ro2oyosPFJzpjTPGRmprK3Llz+WXNGqpUqcKgQYOoV+81v8wrkIlgL+e3KVvL7eYXGUcCl//tb4QNGwrAlF+nMHPHTOIP7CG6SjQf9fuIYe/+xO7EYzxQ+Uc6n1rgGb/e2d/ZVao+63p+YRtrY4xfpaenM378eJKSkrjqqqvo3r07pUqV8tv8ApkI4oAxIjIJp6HnZH9fHygXE+NJAgAz131I/MkEorU0/RN3cOCNnjxy6AQVy5SkefJ6Z6C6Xdyh29C85RCaR1sSMMb4x8mTJylbtiwhISFcffXVVK5cmSuuyGuLrXnnt0QgIhOB7kCEiCQAfwVKAajqOGAmTrui24CTwG3+iiUrU36dQvzJBNqknuWxpMpAGjtTnVNCERVKQ8Uu0HIIRBdoWMaYIKSqrF+/ntmzZ9OzZ0/atWtH06ZNC2z+/rxr6OZc+ivwR3/NPzcz130IQMuUCjwf7mkXm2ujatLRTv0YYwpIcnIyM2bMYOvWrdSqVeuSboi5WEXiYnF+OXD8NE+8+xNHSiwisVQC0adSqRxyHZPv6RTo0IwxQWj9+vVMnz4dVaVv3760b9+ekJCCL/gQVIkgKeU0mxKPUa7uCgCiUsOocNVdAY7KGBOsypYtS61atRg4cCBhYWEBiyOoEgFAsxqVKFejEuwvzUOVq4KdBjLGFJD09HR++ukn0tLS6Nq1Kw0bNqRBgwaIBPYBoqBLBMYYEwj79+8nLi6OxMREmjdvjqoiIgFPAhCsieD4fkhNhtLVAx2JMaaYO3fuHIsWLWLJkiWULVuWm266iaZNmxaKBJAhOBNBRq2glkMCG4cxptg7fPgwS5YsoWXLlvTp04dy5coFOqQLBF0iOFJiEZvkNNFlKtszAsYYvzhz5gxbtmyhVatWVKtWjTFjxgT0YnBugi4RhDALgP5aPsCRGGOKo+3btzN9+nSOHj1KjRo1qFq1aqFOAhCEiaBS+lFqnErlpujRgQ7FGFOMnDp1irlz57J27VrCw8MZPXo0VatWDXRYPgm6RACAnRYyxuSj9PR0PvzwQ5KSkujSpQvdunWjZMmis3ktOpEaY0wh410krmfPnlSuXJkaNWoEOqw8s8brjTEmj1SVdevW8eabb7J69WoAmjRpUiSTAATREcGB46c5dupsoMMwxhRxR48eZfr06Wzfvp3atWtTt27dQId0yYImESSlnKaaHKV8+gmgcqDDMcYUQT///DMzZsxAVbnmmmuIiYkpVA+GXaygSQQA1Uscc16ULxpX8o0xhUu5cuWoXbs2AwcOJDQ0NNDh5JugSgSAc8dQxcsDHYUxpghIS0vzFInr1q1boSkSl9+CLxEYY4wPEhMTiYuLY//+/bRo0aJQFYnLb5YIjDHGy7lz5/jhhx9YsmQJ5cqVY+jQoQXabGQgBFUiOBKixMtpogMdiDGm0Dp8+DBLly6ldevW9OnTh7JlywY6JL8LqkSQXCIdKEH/+v0DHYoxphA5c+YMmzdvpnXr1kWiSFx+C6pEABCtpbnpypsCHYYxppDYtm0b06dPJzk5mSuuuKJIFInLb0GTCELTkjgWkh7oMIwxhcTJkyeZO3cu69atIyIigttuu63IFInLb0GTCCqnH+VYCPYMgTHGUyTu8OHDxMbG0rVr1yJVJC6/BdWSp0mIPUNgTBA7ceIE5cqVIyQkhF69ehEaGsrll9s2wYrOGWOKPVVlzZo1vPXWW6xatQpwisRZEnAEzRHBkRDlZIgGOgxjTAE7evQo06ZNY8eOHdSpU4fIyMhAh1ToBE0icG4dxW4dNSaIrFu3jhkzZiAi9O/fn+jo6GL5ZPClCppEAFAuXehvt44aEzQqVKhA3bp1GThwIJUrW9Xh7ARVIjDGFG9paWksWbIEVaVbt240aNCABg0aBDqsQs8SgTGmWEhMTOTbb7/lwIEDtGzZ0lMkzuTOEoExpkg7e/YsP/zwA0uXLqV8+fIMGzaMJk2aBDqsIsWviUBE+gGvAyWAD1R1bKb+dYCPgVB3mKdUdaY/YzLGFC9Hjhzhp59+Iioqit69ewdFkbj85rdEICIlgLeB3kACsFJE4lR1k9dgfwG+VNV3RKQZMBOo56+YjDHFw+nTp9m8eTNRUVFUq1aNBx54oFi1GFbQ/HlE0B7Ypqo7AERkEnAt4J0IFKjkvq4M7PNjPMaYYmDr1q1Mnz6d48ePU7NmTapWrWpJ4BL5MxHUBPZ4vU8AOmQa5jlgrog8AJQHemU1IRG5G7gboE6dOvkeqDGm8Dt58iRz5szh559/pmrVqtx0001BWyQuvwX6YvHNwARVfVlEOgGfikgLVT2vTKiqvge8BxAdHW2PBxsTZDKKxB05coSuXbsSGxsb1EXi8ps/1+ReoLbX+1puN293AP0AVPUnESkDRAC/+zEuY0wRkZKSQvny5QkJCaF3796EhoZSvXr1QIdV7Piz6NxKoJGIRIrIZcBwIC7TMLuBngAi0hQoAxz0Y0zGmCJAVVm9evV5ReIaN25sScBP/HZEoKrnRGQMMAfn1tAPVXWjiDwPxKtqHPAn4H0ReQTnwvFoVbVTP8YEsSNHjjBt2jR27txJ3bp1qV+/fqBDKvb8epLNfSZgZqZuz3q93gR09mcMxpiiY+3atcycORMRYcCAAbRr186eDi4AdrXFGFNoVKxYkcjISAYMGEClSpVyH8HkC0sExpiASUtL48cff0RV6d69uxWJCxBLBMaYgNi7dy9xcXH8/vvvtGrVyorEBZAlAmNMgTp79iwLFixg2bJlVKhQgeHDh9O4ceNAhxXULBEYYwrUkSNHWLFiBW3btqVXr16UKVMm0CEFPUsExhi/S01NZfPmzbRp08ZTJM5aDCs8LBEYY/zq119/Zfr06aSkpFC7dm0iIiIsCRQylgiMMX5x4sQJ5syZw/r166lWrRrDhg0jIiIi0GGZLFgiMMbku/T0dD766COOHDlC9+7d6dKlCyVKlAh0WCYblgiMMfnGu0hcnz59CA0NpVq1aoEOy+TC56JzIlLOn4EYY4ouVSU+Pp4333yT+Ph4AK688kpLAkVErkcEInIV8AFQAagjIq2Be1T1fn8HZ4wp/A4fPsy0adPYtWsXkZGRNGzYMNAhmTzy5dTQq0Bf3BLSqrpORLr6NSpjTJGwZs0aZs6cSYkSJRg0aBBt2rSxp4OLIJ+uEajqnkwfbpp/wjHGFCWVK1emQYMG9O/f34rEFWG+JII97ukhFZFSwEPAZv+GZYwpjM6dO+cpEtejRw/q169v7QUUA74kgnuB13Eao98LzAXs+oAxQSYhIYG4uDgOHjxI69atrUhcMeJLImisqiO9O4hIZ2CJf0IyxhQmZ86c8RSJq1SpEjfffDNXXnlloMMy+ciXRPAm0NaHbsaYYig5OZmVK1cSHR1Nr169KF26dKBDMvks20QgIp2Aq4CqIvKoV69KOG0QG2OKqdTUVDZt2kTbtm2pWrUqDz74oF0MLsZyOiK4DOfZgZJARa/ux4Ah/gzKGBM4W7ZsYcaMGZw4cYI6deoQERFhSaCYyzYRqOoPwA8iMkFVfyvAmIwxAXDixAlmzZrFxo0bqV69OjfffLMViQsSvlwjOCki/waaA54WJFT1ar9FZYwpUOnp6Xz44YckJyfTo0cPOnfubEXigogvieBzYDIwEOdW0luBg/4MyhhTMI4fP06FChUICQmhX79+hIaGUrVq1UCHZQqYL0XnwlV1PHBWVX9Q1dsBOxowpghTVVauXMlbb73lKRLXqFEjSwJBypcjgrPu/0QRGQDsA6r4LyRjjD8lJSUxbdo0fvvtN+rXr29F4oxPieAFEakM/Ann+YFKwMP+DMoY4x+rV69m1qxZlCxZksGDBxMVFWVPB5vcE4GqTndfJgM9wPNksTGmiAkNDaVhw4b079+fihUr5j6CCQo5PVBWAhiKU2NotqpuEJGBwDNAWaBNwYRojLlY586dY9GiRQBcffXVViTOZCmnI4LxQG1gBfCGiOwDooGnVPWbAojNGHMJ9uzZQ1xcHIcOHSIqKsqKxJls5ZQIooFWqpouImWA/UADVU0qmNCMMRfjzJkzzJ8/nxUrVlC5cmVGjhxpF4RNjnK6ffSMqqYDqGoqsCOvSUBE+onILyKyTUSeymaYoSKySUQ2isgXeZm+MeZCycnJrFq1ipiYGO677z5LAiZXOR0RNBGRn93XAjRw3wugqtoqpwm71xjeBnoDCcBKEYlT1U1ewzQCngY6q+oREbGWro25CKdOnWLTpk20a9eOqlWr8tBDD9nFYOOznBJB00ucdntgm6ruABCRScC1wCavYe4C3lbVIwCq+vslztOYoLN582ZmzpzJiRMnqFu3LhEREZYETJ7kVHTuUgvN1QT2eL1PADpkGuZKABFZglPa+jlVnZ15QiJyN3A3QJ06dS4xLGOKh5SUFGbNmsWmTZu4/PLLGTFihBWJMxfFp8br/Tz/RkB3oBawSERaqupR74FU9T3gPYDo6Ggt4BiNKXTS09P56KOPSE5O5uqrr+aqq66yInHmovkzEezFuf00Qy23m7cEYLmqngV2isivOIlhpR/jMqbIOnbsGBUrVvQUiQsLC7OjAHPJfCk6h4iUFZHGeZz2SqCRiESKyGXAcCAu0zDf4BwNICIROKeKduRxPsYUe6rK8uXLeeutt1i50tlPatSokSUBky9yTQQiMghYC8x230eJSOYN+gVU9RwwBpgDbAa+VNWNIvK8iAx2B5sDJInIJmAB8Lg9p2DM+Q4dOsRHH33E7NmzqVOnjjUcb/KdL6eGnsO5A2ghgKquFZFIXyauqjOBmZm6Pev1WoFH3T9jTCarV69m5syZlCpViuuuu45WrVrZ08Em3/lUhlpVkzN9+eyCrTEFICwsjMaNG3PNNddQoUKFQIdjiilfEsFGERkBlHAfAHsQWOrfsIwJTufOneOHH34AoGfPnkRGRhIZ6dMBuDEXzZeLxQ/gtFd8GvgCpxz1w36MyZigtHv3bsaNG8ePP/7IiRMncM6cGuN/vhwRNFHVPwN/9ncwxgSj06dPM3/+fFauXEloaCi33HILDRo0CHRYJoj4kgheFpHLgf8Ck1V1g59jMiaoHDt2jDVr1tC+fXt69uzJZZddFuiQTJDJ9dSQqvbAaZnsIPCuiKwXkb/4PTJjirGTJ096ngeoWrUqDz74INdcc40lARMQPj1ZrKr7cRqnWQA8ATwLvODPwIwpjlTVUyTu1KlTREZGWpE4E3C5JgIRaQoMA24EkoDJOA3ZG2Py4Pjx48ycOZMtW7ZQo0YNbrnlFnsy2BQKvhwRfIiz8e+rqvv8HI8xxVJGkbjjx4/Tq1cvOnXqREiITxVejPG7XBOBqnYqiECMKY6Sk5OpVKkSISEh9O/fn7CwMMLDwwMdljHnyTYRiMiXqjpURNZz/pPEPrVQZkwwS09PZ+XKlcyfP59evXrRvn17azLSFFo5HRE85P4fWBCBGFNcHDx4kLi4OBISEmjYsCGNG+e1cK8xBSunFsoS3Zf3q+qT3v1E5EXgyQvHMia4rVq1ilmzZnHZZZdx/fXX07JlSysSZwo9X65W9c6i2zX5HYgxxUGVKlVo0qQJf/zjH61SqCkycrpGcB9wP1BfRH726lURWOLvwIwpCs6ePcvChQsREXr16mVF4kyRlNM1gi+AWcA/gae8uh9X1cN+jcqYIuC3334jLi6Ow4cP065dO1TVjgBMkZRTIlBV3SUif8zcQ0SqWDIwwer06dN89913xMfHExYWxqhRo+wowBRpuR0RDARW4dw+6r2ro0B9P8ZlTKF1/Phx1q5dS8eOHenRo4fVBzJFXk53DQ10/9uujgl6J0+eZOPGjcTExBAREcFDDz1kLYaZYsOXWkOdgbWqekJEbgHaAq+p6m6/R2dMgKkqGzduZNasWaSmplK/fn3Cw8MtCZhixZdaQ+8ArUWkNU6xuQ+AT4Fu/gzMmEA7fvw4M2bM4JdffuGKK65g8ODBVh7CFEu+JIJzqqoici3wlqqOF5E7/B2YMYHkXSSud+/edOzY0YrEmWLLl0RwXESeBv4AxIpICFDKv2EZExhHjx71FIkbMGAAYWFhVKlSJdBhGeNXvuziDMNpuP52t4GaWsC//RqVMQUsPT2dn376ibfffpv4+HgAGjRoYEnABAVfylDvF5HPgRgRGQisUNVP/B+aMQXj999/Jy4ujr1793LllVfSpEmTQIdkTIHy5a6hoThHAAtxniV4U0QeV9X/+jk2Y/wuPj6eWbNmUaZMGW644QZatGhhTweboOPLNYI/AzGq+juAiFQFvgMsEZgiK6McREREBM2bN6dv376UL18+0GEZExC+JIKQjCTgSsK3awvGFDpnz55lwYIFiAi9e/emXr161KtXL9BhGRNQviSC2SIyB5jovh8GzPRfSMb4x65du4iLi+PIkSNER0dbkThjXL5cLH5cRG4Aurid3lPVqf4Ny5j8k5qayrx581i9erUViTMmCzm1R9AIeAloAKwHHlPVvQUVmDH5JSUlhfXr19OpUyd69OhBqVL2GIwx3nI61/8hMB24EacC6Zt5nbiI9BORX0Rkm4g8lcNwN4qIikh0XudhTFZOnDjB8uXLATxF4vr06WNJwJgs5HRqqKKqvu++/kVEVudlwiJSAngbp6nLBGCliMSp6qZMw1UEHgKW52X6xmRFVdmwYQOzZs3i9OnTNGzYkPDwcLsjyJgc5JQIyohIG/7XDkFZ7/eqmltiaA9sU9UdACIyCbgW2JRpuP8HvAg8nsfYjTlPcnIyM2bMYOvWrdSsWdOKxBnjo5wSQSLwitf7/V7vFbg6l2nXBPZ4vU8AOngPICJtgdqqOkNEsk0EInI3cDdAnTp1cpmtCUbp6el8/PHHpKSk0LdvX9q3b29F4ozxUU4N0/Tw54zd4nWvAKNzG1ZV3wPeA4iOjlZ/xmWKFu8icQMHDiQsLIywsLBAh2VMkeLPXaa9QG2v97XcbhkqAi2AhSKyC+gIxNkFY+OL9PR0li5dyttvv83KlSsBqF+/viUBYy6CLw+UXayVQCMRicRJAMOBERk9VTUZiMh4LyILcW5RjfdjTKYYOHDgAHFxcezbt4/GjRvTrFmzQIdkTJHmt0SgqudEZAwwBygBfKiqG0XkeSBeVeP8NW9TfK1cuZLZs2dTpkwZhgwZQrNmzezpYGMukS/VRwUYCdRX1edFpA5wuaquyG1cVZ1JpnIUqvpsNsN29yliE5QyykFUq1aNFi1a0LdvX8qVKxfosIwpFnw5IvgPkI5zl9DzwHHgKyDGj3EZA8CZM2f4/vvvCQkJoU+fPtStW5e6desGOixjihVfEkEHVW0rImsAVPWIiFzm57iMYceOHUybNo2jR4/Svn17KxJnjJ/4kgjOuk8JK3jaI0j3a1QmqKWmpjJ37lzWrFlDlSpVGD16tB0FGONHviSCN4CpQDUR+TswBPiLX6MyQS0lJYUNGzbQuXNnunXrZvWBjPEzX8pQfy4iq4CeOOUlrlPVzX6PzASVjI1/x44diYiI4OGHH7aLwcYUEF/uGqoDnASmeXdT1d3+DMwEB1Vl/fr1zJ49mzNnztCoUSPCw8MtCRhTgHw5NTQD5/qAAGWASOAXoLkf4zJBIDk5menTp7Nt2zZq1aplReKMCRBfTg219H7vFoq7328RmaCQnp7OhAkTOHHiBP369SMmJsaKxBkTIHl+slhVV4tIh9yHNOZCR44coXLlyoSEhDBo0CCqVKlCaGhooMMyJqj5co3gUa+3IUBbYJ/fIjLFUkaRuIULF9K7d286dOhA/fr1Ax2WMQbfjggqer0+h3PN4Cv/hGOKo/379xMXF0diYiJNmjSxInHGFDI5JgL3QbKKqvpYAcVjipkVK1YwZ84cypYty0033WRJwJhCKNtEICIl3QqinQsyIFM8ZJSDqF69Oi1btqRv376ULVs20GFdsrNnz5KQkEBqamqgQzEmS2XKlKFWrVp5ehAzpyOCFTjXA9aKSBwwBTiR0VNVv77YQE3xdebMGebPn0+JEiWKZZG4hIQEKlasSL169azukSl0VJWkpCQSEhKIjIz0eTxfrhGUAZJwqo9mPE+ggCUCc57t27czbdo0kpOTi22RuNTUVEsCptASEcLDwzl48GCexsspEVRz7xjawP8SQAZrN9h4nDp1irlz57J27VrCw8O57bbbqFOnTqDD8htLAqYwu5jvZ06JoARQgfMTQAZLBMbjxIkTbNq0iS5dutCtWzdKlvRnC6jGmPyW0y82UVWfL7BITJGSkpLC+vXr6dSpExERETz00ENWH8iYIiqnZ/rt+NdcQFVZu3Ytb7/9NvPnzycpKQnAkkABUVW6dOnCrFmzPN2mTJlCv379Lhh24cKFDBw4EIAJEyYwZsyYAovTVxMmTGDfvuyfT3344YdZtGiR5/2hQ4coVaoU48aNO2+4ChUqXDBd7+X95JNPaNGiBS1btqRNmza89NJLlxz77bff7mk6NTuqyoMPPkjDhg1p1aoVq1ev9vT7+OOPadSoEY0aNeLjjz/2dO/VqxdHjhy55PjyIqdE0LPAojBFwtGjR/n888/59ttvqVq1Kvfee68ViStgIsK4ceN49NFHSU1NJSUlhWeeeYa333470KFx7ty5PI+TUyJISkpi2bJldO3a1dNtypQpdOzYkYkTJ/o8j1mzZvHaa68xd+5c1q9fz7Jly6hcuXKeY81s9OjRzJ49O9d5b926la1bt/Lee+9x3333AXD48GH+9re/sXz5clasWMHf/vY3z8b/D3/4A//5z38uOb68yPbUkKoeLshATOGWnp7Oxx9/zMmTJ+nfvz/R0dFBf9H0b9M2smnfsXydZrMrKvHXQTkX9m3RogWDBg3ixRdf5MSJE9xyyy38/e9/Z8OGDZw9e5bnnnuOa6+9Ntvxd+3axe23386hQ4eoWrUqH330ETVr1qRhw4bs2LGD5ORkwsPDWbBgAV27dqVr166MHz+eRo0aXTCt5557ju3bt7Njxw7q1KlD3759iY+P56233gJg4MCBPPbYY8TGxnLHHXcQHx+PiHD77bdTu3Zt4uPjGTlyJGXLluWnn34671mTr7766oIjnYkTJ/Lyyy8zYsQIEhISqFWrVq7r9J///CcvvfQSV1xxBQClS5fmrrvuynW83HTt2pVdu3blOMy3337LqFGjEBE6duzI0aNHSUxM9JRaqVKlCgC9e/dm9uzZ3HzzzQwePJjY2Fj+/Oc/X3KMvrKreiZHhw8fJjQ0lJCQEAYPHkxYWJgViSsE/vrXv9K2bVsuu+wyBg4cyNVXX82HH37oad+5V69e2Y77wAMPcOutt3Lrrbfy4Ycf8uCDD/LNN9/QuHFjNm3axM6dO2nbti2LFy+mQ4cO7NmzJ8skkGHTpk38+OOPlC1blgkTJmQ5zNq1a9m7dy8bNmwAnKPL0NBQ3nrrLV566SWio6MvGGfJkiUMGTLE837Pnj0kJibSvn17hg4dyuTJk/nTn/6U67rasGED7dq1y3W4zz//nH//+98XdG/YsCH//e9/cx0/K3v37qV27dqe97Vq1WLv3r3ZdgcICwvj9OnTJCUlFdgRtyUCk6W0tDSWLl3KDz/84CkSl5cHVIJBbnvu/lS+fHmGDRtGhQoV+PLLL5k2bZrnvHdqaiq7d2ffbtRPP/3E1187jwH94Q9/4IknngAgNjaWRYsWsXPnTp5++mnef/99unXrRkxMTI6xDB48ONenxuvXr8+OHTt44IEHGDBgAH369Ml1GRMTE6latarn/eTJkxk6dCgAw4cP5/bbb88xEeT1iHXkyJGMHDkyT+P4S7Vq1di3b1+BJQIrAG8ukJiYyAcffMD3339P48aNad7c2iAqjEJCQggJCUFV+eqrr1i7di1r165l9+7dNG3aNM/T69q1K4sXL2bFihX079+fo0ePsnDhQmJjY3Mcr3z58p7XJUuWJD093fM+oxRHWFgY69ato3v37owbN44777wz13jKli17XimPiRMnMmHCBOrVq8fgwYP5+eef2bp1q2fYM2fOeIY9fPgwERERADRv3pxVq1blOr/PP/+cqKioC/68j0ryqmbNmuzZs8fzPiEhgZo1a2bbPUNqamqBlmSxRGDOs3z5ct5//31SUlIYOnQoN9100wV3ZJjCpW/fvrz55puoOo/3rFmzJsfhr7rqKiZNmgQ4G7+MDX379u1ZunQpISEhlClThqioKN59993zLtbmpl69eqxdu5b09HT27NnDihUrAOdun/T0dG688UZeeOEFz90zFStW5Pjx41lOq2nTpmzbtg2AX3/9lZSUFPbu3cuuXbvYtWsXTz/9tOeicbdu3fjss88A5wHHL7/8kh49egDw9NNP8/jjj7N//37AKYPywQcfXDC/kSNHepKp99/FnhYC52jpk08+QVU9F6lr1KhB3759mTt3LkeOHOHIkSPMnTuXvn37As6dRvv376devXoXPd+8skRgADwbkcsvv5zWrVtz//33X9RepSl4//d//8fZs2dp1aoVzZs35//+7/9yHP7NN9/ko48+olWrVnz66ae8/vrrgHMRtXbt2nTs2BFwThUdP36cli1b5jS583Tu3JnIyEiaNWvGgw8+SNu2bQHnXHn37t2Jiorilltu4Z///Cfg3Hlz7733EhUVxalTp86b1oABA1i4cCHgHA1cf/315/W/8cYbPYng9ddf5+uvvyYqKoqOHTty0003eRJY//79GTNmDL169aJ58+a0bduWY8cu/SL/zTffTKdOnfjll1+oVasW48ePB2DcuHGe21v79+9P/fr1adiwIXfddZfnbqAqVarwf//3f8TExBATE8Ozzz7ruXC8atUqOnbsWKAPZkrGBqCoiI6O1vj4+DyPN7OXU/64/3eb8jukIu306dOeInEZeyQme5s3b7YEWYC6dOnC9OnTg+oGhYceeojBgwfTs+fF38Gf1fdURFap6oVX5bEjgqC2bds23nnnHVauXAn876jAmMLi5ZdfzvHCd3HUokWLS0oCF8PuGgpCJ0+eZO7cuaxbt46IiAjPPd3GZOejjz7ynELK0LlzZ78/yNahQ/A1j54fzzjklSWCIHTq1Ck2b95M165diY2NtSJxJle33XYbt912W6DDMH7i11NDItJPRH4RkW0i8lQW/R8VkU0i8rOIzBeR4tOCSSFz/Phxli5diqoSHh7Oww8/TI8ePSwJGGP8d0Tgtnf8NtAbSABWikicqnpfrV0DRKvqSRG5D/gXMMxfMQWjjCJxc+bMIS0tjcaNGxMeHl4smo00xuQPf+4Otge2qeoOABGZBFwLeBKBqi7wGn4ZcIsf4wk6R44cYfr06ezYsYO6desyaNAgKxJnjLmAPxNBTWCP1/sEIKcrP3cAs7LqISJ3A3cDxbrlq/yUnp7OJ598wsmTJxkwYADt2rUL+iJxxpisFYrbR0XkFiAauLDiE6Cq76lqtKpGe9ceMRdKSkoiPT2dkJAQrr32Wu6//36rFFrMlChRgqioKFq3bk3btm1ZunRpoEO6aEePHs2x5PKpU6fo1q0baWlpnm6vvfYaZcqUITk52dMtq/YWunfvTsYzRykpKdxzzz00aNCAdu3a0b17d5YvX35JsW/ZsoVOnTpRunTpHNs32LlzJx06dKBhw4YMGzbMUwrj9OnTDBs2jIYNG9KhQwdPJdP169czevToS4otr/x5RLAX8L4nsZbb7Twi0gv4M9BNVU/7MZ5iLS0tjSVLlrBo0SJ69epFx44dC/QR9aA06ynYvz5/p3l5S7hmbI6DlC1blrVr1wIwZ84cnn76aX744Yfzhjl37lxAbgRIS0ujRIkSPg+fkQjuv//+LPt/+OGH3HDDDedNc+LEicTExPD111/7fCfTnXfeSWRkJFu3biUkJISdO3eyadOlPVxapUoV3njjDb755psch3vyySd55JFHGD58OPfeey/jx4/nvvvuY/z48YSFhbFt2zYmTZrEk08+yeTJk2nZsiUJCQns3r27wM6A+POIYCXQSEQiReQyYDgQ5z2AiLQB3gUGq+rvfoylWNu3bx/vv/8+CxYsoGnTpnkqCWCKtmPHjhEWFgbgKRA3ePBgmjVrRmpqKrfddpunVa4FC5xLcgMGDODnn38GoE2bNjz/vNMi7bPPPsv777/PwoUL6d69O0OGDKFJkyaMHDkyx4cN69Wrx5NPPknbtm2ZMmXKeXvihw4d8uyQbNy4kfbt2xMVFUWrVq3YunUrTz31FNu3bycqKorHH3/8gml//vnn57WtsH37dlJSUnjhhRd8bpxm+/btLF++nBdeeIGQEGeTFxkZyYABA3waPzvVqlUjJiaGUqVKZTuMqvL99997CtfdeuutnsTx7bffcuuttwIwZMgQ5s+f71nPgwYN8tSDKgh+22VQ1XMiMgaYA5QAPlTVjSLyPBCvqnE4p4IqAFPcUxe7VXWwv2IqjpYtW8bcuXOpUKECw4cPp3HjxoEOKXjksufuL6dOnSIqKorU1FQSExP5/vvvPf1Wr17Nhg0biIyM5OWXX0ZEWL9+PVu2bKFPnz78+uuvxMbGsnjxYurWrUvJkiVZsmQJAIsXL2bcuHEkJiayZs0aNm7cyBVXXEHnzp1ZsmQJXbp0yTam8PBwTyG5zM1IZhg3bhwPPfQQI0eO5MyZM6SlpTF27Fg2bNjgOcLxdubMGXbs2HHeke2kSZMYPnw4sbGx/PLLLxw4cIDq1avnuL42btxIVFSUT0cqw4YN45dffrmg+6OPPsqoUaNyHT+zpKQkQkNDPUdn3u0OeLdJULJkSSpXrkxSUhIRERFER0czduxYT4lwf/PrsaOqzgRmZur2rNfr7FvPMDlSVUSEK664gjZt2tC7d2/KlCkT6LBMAfA+NfTTTz8xatQoT4Mv7du397Qb8eOPP/LAAw8A0KRJE+rWretJBG+88YZnr3jevHmcPHmSnTt30rhxY0/jLxmtf0VFRbFr164cE8GwYbnf9d2pUyf+/ve/k5CQwA033JBjYzfgHE1krjE0ceJEpk6dSkhICDfeeCNTpkxhzJgx2V4Dy+u1scmTJ+dpeH/JaI+goNjTREXM6dOnmTdvHiVLlqRfv37UqVPH7qQKYp06deLQoUMcPHgQOL9tgOzExMQQHx9P/fr16d27N4cOHeL9998/rxWv0qVLe16XKFEi1/aIs2uTwLs9gREjRtChQwdmzJhB//79effdd6lfv36208zcHsH69evZunUrvXv3BpwjhsjISMaMGUN4ePgFDb5ntEkQGhrKunXrfLp+kd9HBOHh4Rw9etRzzca73YGMNglq1arFuXPnPE2EgrVHYHKwdetW/vOf/7B69WpPgyQmuG3ZsoW0tLQsnw+JjY3l888/B5x6/rt376Zx48Zcdtll1K5dmylTptCpUydiY2N56aWX8tTuQE7q1avnaQjGu5b/jh07qF+/Pg8++CDXXnstP//8c47tEYSFhZGWluZJBhMnTuS5557ztEewb98+9u3bx2+//UZMTAxLlizxtDkQHx/P6dOnqV27Ng0aNCA6Opq//vWvnt/Mrl27mDFjxgXznDx5cpZtElxMEgDniKRHjx6e9fDxxx97rnkMHjyYjz/+2LOerr76as8RzK+//kqLFi0uap4XwxJBEXDy5Em+/vprvvjiC0qXLs3tt99Onz597JbQIJVxjSAqKophw4bx8ccfZ7mne//995Oenk7Lli0ZNmwYEyZM8Ozpx8bGUq1aNcqWLUtsbCwJCQm5tkTmq8cee4x33nmHNm3acOjQIU/3L7/8khYtWhAVFcWGDRsYNWoU4eHhdO7cmRYtWmR5sbhPnz78+OOPgHN9IHObBNdffz2TJk2ievXqvP766/Tv35+oqCgefvhhJk6c6Lk4/MEHH3DgwAEaNmxIixYtGD16NNWqVbuk5dy/fz+1atXilVde4YUXXqBWrVqedg769+/vObXz4osv8sorr9CwYUOSkpK44447ALjjjjtISkqiYcOGvPLKK4wd+79rTgsWLLjki9l5Ye0RFAFJSUm8//77dOzYkdjY2Dzdnmfyl7VHULBWr17Nq6++yqeffhroUArM6dOn6datGz/++ONF3wKc1/YI7BpBIXXs2DHWr1/PVVdd5SkSZxeDTbBp27YtPXr0yPPzCUXZ7t27GTt2bIE+B2KJoJBRVVavXs28efNIS0ujadOmVKlSxZKACbjrr7+enTt3ntftxRdf9HvLdrfffrtfp1/YNGrUKNc7qvKbJYJC5PDhw0ybNo1du3ZRr149Bg0a5GnH1JhAmzp1aqBDMH5iiaCQyCgSd+rUKQYOHEjbtm3tYrAxpkBYIgiwQ4cOUaVKFUJCQrjuuuuoUqUKlSpVCnRYxpggYrePBkhaWhoLFy7knXfeYcWKFYBz/7UlAWNMQbNEEAB79+7lvffe44cffqB58+a0atUq0CGZIqRChQrnvc+qBLOvFi5cyMCBAz2vvUtajx49+rwHwvIqMTHRM+0MDz/8MDVr1vQ8eQzw3HPPXVDGuV69ep5nEPbv38/w4cM9JaT79+/Pr7/+etFxASxatIi2bdtSsmTJHJdx1apVtGzZkoYNG/Lggw96Hkg7fPgwvXv3plGjRvTu3dvzVPP06dN59tlns51eYWWJoIAtW7aM8ePHc+rUKW6++WZuuOEGypUrF+iwjLkgEVyqV155hbvuusvzPj09nalTp1K7du0LymZnR1W5/vrr6d69O9u3b2fVqlX885//5MCBA5cUW506dZgwYQIjRozIcbj77ruP999/n61bt7J161Zmz54NwNixY+nZsydbt26lZ8+enofBBgwYwLRp0zh58uQlxVfQ7BpBAckoElezZk3atm1Lr1697JbQIu7FFS+y5fCWfJ1mkypNeLL9kxc9/sGDB7n33nvZvXs34DTi0rlzZ1asWMFDDz3kqWHz0UcfnVepdteuXYwbN44SJUrw2Wef8eabbwLOnvMrr7zC/v37+de//sWQIUMYNWoUN9xwA9dddx0AI0eOZOjQoeeViwb46quveOGFFzzvFy5cSPPmzRk2bBgTJ06kR48euS7PggULKFWqFPfee6+nW+vWrS96/WTIqGia8eRxVhITEzl27BgdO3YEYNSoUXzzzTdcc801fPvttyxcuBBwSkt3796dF198ERGhe/fuTJ8+naFDh15ynAXFEoGfpaamMm/ePEqVKkW/fv2oXbu2p/SsMRcjo8REhsOHDzN4sFO9/aGHHuKRRx6hS5cu7N69m759+7J582aaNGnC4sWLKVmyJN999x3PPPMMX331lWca9erV495776VChQo89thjAIwfP57ExER+/PFHtmzZwuDBgxkyZAh33HEHr776Ktdddx3JycksXbrUUzMnw86dOwkLCzuveN3EiRO5+eabufbaa3nmmWc4e/ZsjrX8ATZs2HBeMbycxMbGZlm36KWXXqJXr7wXOt67d6+nAiucX0L6wIED1KhRA4DLL7/8vCOU6OhoFi9ebInAOH755RdmzJhBSkoKnTp18hwVmOLhUvbcL4V3GWpwrhFklF357rvvzmt569ixY6SkpJCcnMytt97K1q1bERHOnj3r07yuu+46QkJCaNasmWdj161bN+6//34OHjzIV199xY033njBU7CJiYl4Nyt75swZZs6cySuvvELFihXp0KEDc+bMYeDAgflWQnrx4sV5Gj6/iMh5sRZ0Cen8YInAD06cOMHs2bPZsGED1apVY9iwYZ7Ss8b4U3p6OsuWLbvgtOOYMWPo0aMHU6dOZdeuXXTv3t2n6Xnv0XvXJRs1ahSfffYZkyZN4qOPPrpgvMwlpOfMmcPRo0c9reedPHmSsmXLMnDgQMLDw0lMTDxv/OPHjxMaGkrz5s19vmCd30cENWvWJCEhwfPeu4R09erVSUxMpEaNGiQmJp5XwK6gS0jnB7tY7AenT59m69atdO/enbvvvtuSgCkwffr08ZzfBzxHDsnJyZ7v4YQJE7IcN6eS0JmNHj2a1157DYBmzZpd0P/KK6/0NMYOzmmhDz74wFNCeufOnZ4Gcbp27UpcXJxn3l9//TWtW7emRIkSXH311Zw+fZr33nvPM62ff/45y73/xYsXZ1lC+mKSAECNGjWoVKkSy5YtQ1X55JNPsiwh7V1aGgq+hHR+sESQT5KTk1m8eDGqSpUqVXj44Yfp1q1b0BTKMoXDG2+8QXx8PK1ataJZs2aeZiOfeOIJnn76adq0aZNtIzODBg1i6tSpREVF5XqapXr16jRt2jTbxuPLly9PgwYN2LZtGydPnmT27NnnlVUuX748Xbp0Ydq0abRq1YoxY8bQpUsXoqKiGDduHB988AHgnHaZOnUq3333HQ0aNKB58+Y8/fTTXH755RezejxWrlxJrVq1mDJlCvfccw/Nmzf39PO+/vKf//yHO++8k4YNG9KgQQOuueYaAJ566inmzZtHo0aN+O6773jqqac84xR0Cen8YGWoL5GqsmrVKubNm4eqcu+991p9oGLMylA7Tp48ScuWLVm9ejWVK1fOcpipU6eyatWq8+4cKu4OHDjAiBEjmD9/fkDjsDLUBSgpKYlp06bx22+/ERkZyaBBgwgLCwt0WMb41Xfffccdd9zBI488km0SAKdaaVJSUgFGFni7d+/m5ZdfDnQYeWaJ4CKlp6fz6aefkpqayuDBg4mKirI7gkxQ6NWrF7/99ptPw955551+jqZwiYmJCXQIF8USQR4dPHiQ8PBwQkJCuP7666lSpQoVK1YMdFjGGHPR7GKxj86dO8eCBQsYN26cp0hc3bp1LQkYY4o8OyLwQUJCAnFxcRw8eJBWrVpZkThjTLFiiSAXS5cuZd68eVSqVIkRI0YUeBNyxhjjb5YIspFRDqJ27dpER0fTq1ev856yNMaY4sKuEWSSmprKt99+y6xZswCoXbs2AwYMsCRgCo0SJUoQFRVF69atadu2rad09K5duy76idZ//OMfuQ6TuR2EwuLUqVN069aNtLQ0T7fXXnuNMmXKkJyc7OmWVbsN3bt399RpSklJ4Z577vG0e9C9e3eWL19+SbFt2bKFTp06Ubp06QvaXPC2c+dOOnToQMOGDRk2bBhnzpwBnCoFw4YNo2HDhnTo0MHztPb69esZPXr0JcXmzY4IvGzZsoUZM2Zw4sQJOnfubEXiTI72/+MfnN6cv2WoSzdtwuXPPJPjMN5F5+bMmcPTTz/tc33/7PzjH//gmVzmW1h9+OGH3HDDDec9xT9x4kRiYmL4+uuvs336ObM777yTyMhItm7dSkhICDt37jyvgN/FqFKlCm+88QbffPNNjsM9+eSTPPLIIwwfPpx7772X8ePHc9999zF+/HjCwsLYtm0bkyZN4sknn2Ty5Mm0bNmShIQEdu/eTZ06dS4pRrAjAsApEjdlyhQmT55MhQoVuOuuu+jZs6clAVPoHTt2LMuHGHft2kVsbCxt27Y976ghMTGRrl27EhUVRYsWLVi8eDFPPfWUp7T1yJEj8zT/7du3069fP9q1a0dsbCxbtjiJcdq0aXTo0IE2bdrQq1cvDhw4QHp6OvXq1ePo0aOe8Rs1asSBAwc4ePAgN954IzExMcTExLBkyRIAfvjhB6KiooiKiqJNmzZZ1kL6/PPPz6v1s337dlJSUnjhhReYOHGiz8uxfPlyXnjhBU8bBZGRkZdcKqJatWrExMTkWG5bVfn+++8ZMmQI4LRvkJE4vv32W2699VYAhgwZwvz58z3F/wYNGsSkSZMuKb4MdkSAc/i1Y8cOrr76aq666iqrD2R8ktueu79kbLRTU1NJTEzk+++/v2CYatWqMW/ePMqUKcPWrVu5+eabiY+P54svvqBv3778+c9/Ji0tjZMnTxIbG8tbb711XmlrX919992MGzeORo0asXz5cu6//36+//57unTpwrJlyxARPvjgA/71r3/x8ssvc+211zJ16lRuu+02li9fTt26dalevTojRozIsh2Fl156ibfffpvOnTuTkpJyQVXVM2fOsGPHDk9DMwCTJk1i+PDhxMbG8ssvv3DgwAGqV6+e43Js3LiRqKgon377w4YN45dffrmg+6OPPsqoUaN8W3FekpKSCA0N9ZTy9m73YO/evZ72S0qWLEnlypVJSkoiIiKC6Ohoxo4dyxNPPJHneWYWtIkgOTmZdevWERsb6ykSZ9cBTFHgfWrop59+YtSoUWzYsOG8Yc6ePcuYMWNYu3YtJUqU8LTxGxMTw+23387Zs2e57rrrziuwllcpKSksXbqUm266ydPt9OnTgHPL9bBhw0hMTOTMmTNERkYCzkb0+eef57bbbmPSpEkMGzYMyL4dhc6dO/Poo48ycuRIbrjhhvMaigE4dOgQoaGh53WbOHEiU6dOJSQkhBtvvJEpU6YwZsyYfGv3YPLkyXka3l/ys90DvyYCEekHvA6UAD5Q1bGZ+pcGPgHaAUnAMFXd5c+YVJX4+Hi+++47VJUWLVpQpUoVSwKmSOrUqROHDh3i4MGD53V/9dVXqV69OuvWrSM9Pd2zJ921a1cWLVrEjBkzGD169EXvxYJTZiU0NDTLI4kHHniARx99lMGDB7Nw4UKee+45T7zbtm3j4MGDfPPNN/zlL3/xTCurdhSeeuopBgwYwMyZM+ncuTNz5syhSZMmnv6Z2z1Yv349W7dupXfv3gCeJDRmzBjCw8M9jcxnOHz4MBEREYSGhrJu3TrS0tJyPSrI7yOC8PBwjh49yrlz5yhZsuR57R7UrFmTPXv2UKtWLc6dO0dycjLh4eFA/rZ74LdrBCJSAngbuAZoBtwsIpkLl98BHFHVhsCrwIv+igfgVNmKTJgwgZkzZ1KrVi3uv/9+qxRqirQtW7aQlpbm2ThkSE5OpkaNGoSEhPDpp5967qj57bffqF69OnfddRd33nknq1evBqBUqVI+t1qWoVKlSkRGRjJlyhTA2clat26dZ/4ZGzPvZixFhOuvv55HH32Upk2beuLOrh2F7du307JlS5588kliYmI81yAyhIWFkZaW5kkGEydO5LnnnvO0e7Bv3z727dvHb7/95rn2sH//fgDi4+M5ffo0tWvXpkGDBkRHR/PXv/7Vcw5+165dzJgx44Llnjx5cpbtHlxsQhURevTo4WmAx7t9A+92D/773/9y9dVXe45g8rXdA1X1yx/QCZjj9f5p4OlMw8wBOrmvSwKHcEtjZ/fXrl07vRjTezbTfzz1uI4dO1bXrFmj6enpFzUdE9w2bdoU6BA0JCREW7dura1bt9ZWrVrp9OnTVVV1586d2rx5c1VV/fXXX7Vly5baqlUrfeKJJ7R8+fKqqjphwgRt3ry5RkVFaZcuXXTHjh2qqvrEE09okyZNdMSIEdnOV0S0Zs2anr+XX35Zd+zYoX379tVWrVpp06ZN9W9/+5uqqn7zzTcaGRmpbdu21ccee0y7devmmc7KlSsV0AkTJni6HTx4UIcOHaotW7bUpk2b6j333KOqqmPGjNHmzZtry5Ytdfjw4ZqamnpBXLfffrvOmzdPVVUjIyN18+bN5/V/5JFHdOzYsZ642rRpo61bt9bOnTvrqlWrPMMlJyfrnXfeqfXr19fmzZtrt27ddMWKFT58ItlLTEzUmjVrasWKFbVy5cpas2ZNTU5OVlXVa665Rvfu3auqqtu3b9eYmBht0KCBDhkyxLOcp06d0iFDhmiDBg00JiZGt2/f7pn2H//4R42Li8tyvll9T4F4zWa76rf2CERkCNBPVe903/8B6KCqY7yG2eAOk+C+3+4OcyjTtO4G7gaoU6dOO18rH3r7ckQMJ8uGceNrX1l9IHPRrD2Cwmf16tW8+uqrfPrpp4EOpcCcPn2abt268eOPP17QXjQU0/YIVPU94D1wGqa5mGkM/WJlvsZkjCkc2rZtS48ePXw6v19c7N69m7Fjx2aZBC6GPxPBXqC21/tabreshkkQkZJAZZyLxsaYAEhKSqJnz54XdJ8/f/4F1yEKk9tvvz3QIRSoRo0a5WvdM38mgpVAIxGJxNngDwdGZBomDrgV+AkYAnyv/jpXZUw+0WL8xHl4ePhFPU9gCo+L2YT67a4hVT0HjMG5ILwZ+FJVN4rI8yIy2B1sPBAuItuAR4Gnsp6aMYVDmTJlSEpKuqgfmzH+pqokJSVdcBtuboKm8Xpj8sPZs2dJSEg47951YwqTMmXKUKtWrQvKWhT5i8XGFBalSpXyPCVrTHFhReeMMSbIWSIwxpggZ4nAGGOCXJG7WCwiB4G8P1rsiMApYxFMbJmDgy1zcLiUZa6rqlWz6lHkEsGlEJH47K6aF1e2zMHBljk4+GuZ7dSQMcYEOUsExhgT5IItEbwX6AACwJY5ONgyBwe/LHNQXSMwxhhzoWA7IjDGGJOJJQJjjAlyxTIRiEg/EflFRLaJyAUVTUWktIhMdvsvF5F6AQgzX/mwzI+KyCYR+VlE5otI3UDEmZ9yW2av4W4UERWRIn+roS/LLCJD3c96o4h8UdAx5jcfvtt1RGSBiKxxv9/9AxFnfhGRD0Xkd7cFx6z6i4i84a6Pn0Wk7SXPNLs2LIvqH1AC2A7UBy4D1gHNMg1zPzDOfT0cmBzouAtgmXsA5dzX9wXDMrvDVQQWAcuA6EDHXQCfcyNgDRDmvq8W6LgLYJnfA+5zXzcDdgU67ktc5q5AW2BDNv37A7MAAToCyy91nsXxiKA9sE1Vd6jqGWAScG2mYa4FPnZf/xfoKUW7pZFcl1lVF6jqSfftMpwW44oyXz5ngP8HvAgUh7rRvizzXcDbqnoEQFV/L+AY85svy6xAJfd1ZWBfAcaX71R1EXA4h0GuBT5RxzIgVERqXMo8i2MiqAns8Xqf4HbLchh1GtBJBgpvO3y582WZvd2Bs0dRlOW6zO4hc21VnVGQgfmRL5/zlcCVIrJERJaJSL8Ci84/fFnm54BbRCQBmAk8UDChBUxef++5svYIgoyI3AJEA90CHYs/iUgI8AowOsChFLSSOKeHuuMc9S0SkZaqejSQQfnZzcAEVX1ZRDoBn4pIC1VND3RgRUVxPCLYC9T2el/L7ZblMCJSEudwMqlAovMPX5YZEekF/BkYrKqnCyg2f8ltmSsCLYCFIrIL51xqXBG/YOzL55wAxKnqWVXdCfyKkxiKKl+W+Q7gSwBV/Qkog1Ocrbjy6feeF8UxEawEGolIpIhchnMxOC7TMHHAre7rIcD36l6FKaJyXWYRaQO8i5MEivp5Y8hlmVU1WVUjVLWeqtbDuS4yWFWLcjunvny3v8E5GkBEInBOFe0owBjzmy/LvBvoCSAiTXESwcECjbJgxQGj3LuHOgLJqpp4KRMsdqeGVPWciIwB5uDccfChqm4UkeeBeFWNA8bjHD5uw7koMzxwEV86H5f530AFYIp7XXy3qg4OWNCXyMdlLlZ8XOY5QB8R2QSkAY+rapE92vVxmf8EvC8ij+BcOB5dlHfsRGQiTjKPcK97/BUoBaCq43Cug/QHtgEngdsueZ5FeH0ZY4zJB8Xx1JAxxpg8sERgjDFBzhKBMcYEOUsExhgT5CwRGGNMkLNEYAolEUkTkbVef/VyGDYlH+Y3QUR2uvNa7T6hmtdpfCAizdzXz2Tqt/RSY3Snk7FeNojINBEJzWX4qKJejdP4n90+agolEUlR1Qr5PWwO05gATFfV/4pIH+AlVW11CdO75Jhym66IfAz8qqp/z2H40ThVV8fkdyym+LAjAlMkiEgFtx2F1SKyXkQuqDQqIjVEZJHXHnOs272PiPzkjjtFRHLbQC8CGrrjPupOa4OIPOx2Ky8iM0Rkndt9mNt9oYhEi8hYoKwbx+duvxT3/yQRGeAV8wQRGSIiJUTk3yKy0q0xf48Pq+Un3GJjItLeXcY1IrJURBq7T+I+DwxzYxnmxv6hiKxwh82qYqsJNoGuvW1/9pfVH85TsWvdv6k4T8FXcvtF4DxVmXFEm+L+/xPwZ/d1CZx6QxE4G/bybvcngWezmN8EYIj7+iZgOdAOWA+Ux3kqeyPQBrgReN9r3Mru/4W4bR5kxOQ1TEaM1wMfu68vw6kiWRa4G/iL2700EA9EZhFnitfyTQH6ue8rASXd172Ar9zXo4G3vMb/B3CL+zoUpxZR+UB/3vYX2L9iV2LCFBunVDUq442IlAL+ISJdgXScPeHqwH6vcVYCH7rDfqOqa0WkG05jJUvc0hqX4exJZ+XfIvIXnDo1d+DUr5mqqifcGL4GYoHZwMsi8iLO6aTFeViuWcDrIlIa6AcsUtVT7umoViIyxB2uMk6xuJ2Zxi8rImvd5d8MzPMa/mMRaYRTZqFUNvPvAwwWkcfc92WAOu60TJCyRGCKipFAVaCdqp4Vp6JoGe8BVHWRmygGABNE5BXgCDBPVW/2YR6Pq+p/M96ISM+sBlLVX8Vp66A/8IKIzFfV531ZCFVNFZGFQF9gGE5DK+C0NvWAqs7JZRKnVDVKRMrh1N/5I/AGTgM8C1T1evfC+sJsxhfgRlX9xZd4TXCwawSmqKgM/O4mgR7ABW0ui9MO8wFVfR/4AKe5v2VAZxHJOOdfXkSu9HGei4HrRKSciJTHOa2zWESuAE6q6mc4xfyyajP2rHtkkpXJOIXCMo4uwNmo35cxjohc6c4zS+q0Nvcg8Cf5Xyn1jFLEo70GPY5ziizDHOABcQ+PxKlKa4KcJQJTVHwORIvIemAUsCWLYboD60RkDc7e9uuqehBnwzhRRH7GOS3UxJcZqupqnGsHK3CuGXygqmuAlsAK9xTNX4EXshj9PeDnjIvFmczFaRjoO3WaXwQncW0CVovTaPm75HLE7sbyM07DLP8C/ukuu/d4C4BmGReLcY4cSrmxbXTfmyBnt48aY0yQsyMCY4wJcpYIjDEmyFkiMMaYIGeJwBhjgpwlAmOMCXKWCIwxJshZIjDGmCD3/wHRtiwP5jfY9AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#test only\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import matplotlib.pyplot as plt\n",
    "#from project import ViT\n",
    "from glob import glob\n",
    "from sklearn.utils import shuffle\n",
    "#from project import ClassToken\n",
    "import cv2\n",
    "from patchify import patchify\n",
    "hp = {\n",
    "    \"image_size\": 512,\n",
    "    \"num_channels\": 3,\n",
    "    \"patch_size\": 64,\n",
    "    \"num_classes\": 4,\n",
    "    \"class_names\": [\"Yellow_rust\",\"Brown_rust\", \"Healthy\",\"Blast_Leaves\"],\n",
    "    \"num_layers\": 24,\n",
    "    \"hidden_dim\": 768,\n",
    "    \"mlp_dim\": 3072,\n",
    "    \"num_heads\": 4,\n",
    "    \"dropout_rate\": 0.1,\n",
    "    \"batch_size\": 16,\n",
    "    \"lr\": 1e-4,\n",
    "    \"num_epochs\": 5\n",
    "}\n",
    "hp[\"num_patches\"] = (hp[\"image_size\"] ** 2) // (hp[\"patch_size\"] ** 2)\n",
    "hp[\"flat_patches_shape\"] = (hp[\"num_patches\"], hp[\"patch_size\"] * hp[\"patch_size\"] * hp[\"num_channels\"])\n",
    "\n",
    "\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "\n",
    "def load_data(path, split=0.20):\n",
    "    images = glob(os.path.join(path, \"*\", \"*.jpg\"))\n",
    "\n",
    "    # Separate images by class\n",
    "    images_class_BKL = [image for image in images if \"Yellow_rust\" in image]\n",
    "    images_class_NV = [image for image in images if \"Brown_rust\" in image]\n",
    "    images_class_MEL2 = [image for image in images if \"Healthy\" in image]\n",
    "    images_class_BlastLeaves = [image for image in images if \"Blast_Leaves\" in image]\n",
    "    print(len(images_class_BKL))\n",
    "    print(len(images_class_NV))\n",
    "    print(len(images_class_MEL2))\n",
    "    # Oversample to 33,000 to match the largest class (BKL)\n",
    "    target_size = len(images_class_BKL)\n",
    "    #print(images_class_BKL)\n",
    "    images_class_NV = np.random.choice(images_class_NV, size=target_size, replace=True).tolist()\n",
    "    images_class_MEL2 = np.random.choice(images_class_MEL2, size=target_size, replace=True).tolist()\n",
    "    images_class_BlastLeaves = np.random.choice(images_class_BlastLeaves, size=target_size, replace=True).tolist()\n",
    "    # Concatenate lists again and shuffle\n",
    "    images = shuffle(images_class_BKL + images_class_NV + images_class_MEL2+ images_class_BlastLeaves)\n",
    "\n",
    "    print(len(images_class_BKL))\n",
    "    print(len(images_class_NV))\n",
    "    print(len(images_class_MEL2))\n",
    "    print(len(images))\n",
    "    split_size = int(len(images) * split)\n",
    "    train_x, valid_x = train_test_split(images, test_size=split_size, random_state=42)\n",
    "    train_x, test_x = train_test_split(train_x, test_size=split_size, random_state=42)\n",
    "    print(f\"Train: {len(train_x)} - Valid: {len(valid_x)} - Test: {len(test_x)}\")\n",
    "\n",
    "    return train_x, valid_x, test_x\n",
    "\n",
    "\n",
    "def process_image_label(path):\n",
    "    path = path.decode()\n",
    "    image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (hp[\"image_size\"], hp[\"image_size\"]))\n",
    "    image = image / 255.0\n",
    "\n",
    "    patch_shape = (hp[\"patch_size\"], hp[\"patch_size\"], hp[\"num_channels\"])\n",
    "    patches = patchify(image, patch_shape, hp[\"patch_size\"])\n",
    "    patches = np.reshape(patches, hp[\"flat_patches_shape\"])\n",
    "    patches = patches.astype(np.float32)\n",
    "\n",
    "    class_name = path.split(\"/\")[-2]\n",
    "    class_idx = hp[\"class_names\"].index(class_name)\n",
    "    class_idx = np.array(class_idx, dtype=np.int32)\n",
    "\n",
    "    return patches, class_idx\n",
    "\n",
    "\n",
    "def parse(path):\n",
    "    patches, labels = tf.numpy_function(process_image_label, [path], [tf.float32, tf.int32])\n",
    "    labels = tf.one_hot(labels, hp[\"num_classes\"])\n",
    "\n",
    "    patches.set_shape(hp[\"flat_patches_shape\"])\n",
    "    labels.set_shape(hp[\"num_classes\"])\n",
    "\n",
    "    return patches, labels\n",
    "\n",
    "\n",
    "def tf_dataset(images, batch=32):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((images))\n",
    "    ds = ds.map(parse).batch(batch).prefetch(8)\n",
    "    return ds\n",
    "\n",
    "# The main execution part\n",
    "if __name__ == \"__main__\":\n",
    "    dataset_path = '/home/ali/Music/PYTHON/WholeDataset'\n",
    "    _, _, test_x = load_data(dataset_path)\n",
    "    \n",
    "    # Evaluating on the test set\n",
    "    print(\"Evaluating the test set...\")\n",
    "    test_ds = tf_dataset(test_x, batch=hp[\"batch_size\"])\n",
    "    all_preds = []\n",
    "\n",
    "    for fold_no in range(1, 6):\n",
    "        fold_model = tf.keras.models.load_model(f\"files/modelN_fold{fold_no}.h5\", custom_objects={'ClassToken': ClassToken})\n",
    " #fold_model = tf.keras.models.load_model(f\"files/modelN_fold{fold_no}.h5\")\n",
    "        y_pred_probs = fold_model.predict(test_ds)\n",
    "        all_preds.append(y_pred_probs)\n",
    "\n",
    "    avg_preds = np.mean(all_preds, axis=0)\n",
    "    final_preds = np.argmax(avg_preds, axis=1)\n",
    "    y_true = [hp[\"class_names\"].index(img.split(\"/\")[-2]) for img in test_x]\n",
    "    print(classification_report(y_true, final_preds, target_names=hp[\"class_names\"]))\n",
    "    \n",
    "    roc_aucs = []\n",
    "\n",
    "    for i, class_name in enumerate(hp[\"class_names\"]):\n",
    "        auc_val = roc_auc_score((np.array(y_true) == i).astype(int), avg_preds[:, i])\n",
    "        roc_aucs.append(auc_val)\n",
    "        print(f\"AUC-ROC ({class_name}): {auc_val:.4f}\")\n",
    "\n",
    "    for i, class_name in enumerate(hp[\"class_names\"]):\n",
    "        fpr, tpr, _ = roc_curve((np.array(y_true) == i).astype(int), avg_preds[:, i])\n",
    "        plt.plot(fpr, tpr, label=f\"{class_name} (AUC = {roc_aucs[i]:.2f})\")\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], color='grey', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_37\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_38 (InputLayer)       [(None, 256, 3072)]          0         []                            \n",
      "                                                                                                  \n",
      " dense_1850 (Dense)          (None, 256, 512)             1573376   ['input_38[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_42 (T  (None, 256, 512)             0         ['dense_1850[0][0]']          \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " class_token_94 (ClassToken  (None, 1, 512)               512       ['tf.__operators__.add_42[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " concatenate_37 (Concatenat  (None, 257, 512)             0         ['class_token_94[0][0]',      \n",
      " e)                                                                  'tf.__operators__.add_42[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " layer_normalization_1813 (  (None, 257, 512)             1024      ['concatenate_37[0][0]']      \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_888 (  (None, 257, 512)             1260185   ['layer_normalization_1813[0][\n",
      " MultiHeadAttention)                                      6         0]',                          \n",
      "                                                                     'layer_normalization_1813[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1776 (Add)              (None, 257, 512)             0         ['multi_head_attention_888[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'concatenate_37[0][0]']      \n",
      "                                                                                                  \n",
      " layer_normalization_1814 (  (None, 257, 512)             1024      ['add_1776[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1851 (Dense)          (None, 257, 1024)            525312    ['layer_normalization_1814[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_3144 (Dropout)      (None, 257, 1024)            0         ['dense_1851[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1852 (Dense)          (None, 257, 512)             524800    ['dropout_3144[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3145 (Dropout)      (None, 257, 512)             0         ['dense_1852[0][0]']          \n",
      "                                                                                                  \n",
      " add_1777 (Add)              (None, 257, 512)             0         ['dropout_3145[0][0]',        \n",
      "                                                                     'add_1776[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1815 (  (None, 257, 512)             1024      ['add_1777[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_889 (  (None, 257, 512)             1260185   ['layer_normalization_1815[0][\n",
      " MultiHeadAttention)                                      6         0]',                          \n",
      "                                                                     'layer_normalization_1815[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1778 (Add)              (None, 257, 512)             0         ['multi_head_attention_889[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1777[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1816 (  (None, 257, 512)             1024      ['add_1778[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1853 (Dense)          (None, 257, 1024)            525312    ['layer_normalization_1816[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_3146 (Dropout)      (None, 257, 1024)            0         ['dense_1853[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1854 (Dense)          (None, 257, 512)             524800    ['dropout_3146[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3147 (Dropout)      (None, 257, 512)             0         ['dense_1854[0][0]']          \n",
      "                                                                                                  \n",
      " add_1779 (Add)              (None, 257, 512)             0         ['dropout_3147[0][0]',        \n",
      "                                                                     'add_1778[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1817 (  (None, 257, 512)             1024      ['add_1779[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_890 (  (None, 257, 512)             1260185   ['layer_normalization_1817[0][\n",
      " MultiHeadAttention)                                      6         0]',                          \n",
      "                                                                     'layer_normalization_1817[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1780 (Add)              (None, 257, 512)             0         ['multi_head_attention_890[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1779[0][0]']            \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " layer_normalization_1818 (  (None, 257, 512)             1024      ['add_1780[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1855 (Dense)          (None, 257, 1024)            525312    ['layer_normalization_1818[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_3148 (Dropout)      (None, 257, 1024)            0         ['dense_1855[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1856 (Dense)          (None, 257, 512)             524800    ['dropout_3148[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3149 (Dropout)      (None, 257, 512)             0         ['dense_1856[0][0]']          \n",
      "                                                                                                  \n",
      " add_1781 (Add)              (None, 257, 512)             0         ['dropout_3149[0][0]',        \n",
      "                                                                     'add_1780[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1819 (  (None, 257, 512)             1024      ['add_1781[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_891 (  (None, 257, 512)             1260185   ['layer_normalization_1819[0][\n",
      " MultiHeadAttention)                                      6         0]',                          \n",
      "                                                                     'layer_normalization_1819[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1782 (Add)              (None, 257, 512)             0         ['multi_head_attention_891[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1781[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1820 (  (None, 257, 512)             1024      ['add_1782[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1857 (Dense)          (None, 257, 1024)            525312    ['layer_normalization_1820[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_3150 (Dropout)      (None, 257, 1024)            0         ['dense_1857[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1858 (Dense)          (None, 257, 512)             524800    ['dropout_3150[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3151 (Dropout)      (None, 257, 512)             0         ['dense_1858[0][0]']          \n",
      "                                                                                                  \n",
      " add_1783 (Add)              (None, 257, 512)             0         ['dropout_3151[0][0]',        \n",
      "                                                                     'add_1782[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1821 (  (None, 257, 512)             1024      ['add_1783[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_892 (  (None, 257, 512)             1260185   ['layer_normalization_1821[0][\n",
      " MultiHeadAttention)                                      6         0]',                          \n",
      "                                                                     'layer_normalization_1821[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1784 (Add)              (None, 257, 512)             0         ['multi_head_attention_892[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1783[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1822 (  (None, 257, 512)             1024      ['add_1784[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1859 (Dense)          (None, 257, 1024)            525312    ['layer_normalization_1822[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_3152 (Dropout)      (None, 257, 1024)            0         ['dense_1859[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1860 (Dense)          (None, 257, 512)             524800    ['dropout_3152[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3153 (Dropout)      (None, 257, 512)             0         ['dense_1860[0][0]']          \n",
      "                                                                                                  \n",
      " add_1785 (Add)              (None, 257, 512)             0         ['dropout_3153[0][0]',        \n",
      "                                                                     'add_1784[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1823 (  (None, 257, 512)             1024      ['add_1785[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_893 (  (None, 257, 512)             1260185   ['layer_normalization_1823[0][\n",
      " MultiHeadAttention)                                      6         0]',                          \n",
      "                                                                     'layer_normalization_1823[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1786 (Add)              (None, 257, 512)             0         ['multi_head_attention_893[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1785[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1824 (  (None, 257, 512)             1024      ['add_1786[0][0]']            \n",
      " LayerNormalization)                                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " dense_1861 (Dense)          (None, 257, 1024)            525312    ['layer_normalization_1824[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_3154 (Dropout)      (None, 257, 1024)            0         ['dense_1861[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1862 (Dense)          (None, 257, 512)             524800    ['dropout_3154[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3155 (Dropout)      (None, 257, 512)             0         ['dense_1862[0][0]']          \n",
      "                                                                                                  \n",
      " add_1787 (Add)              (None, 257, 512)             0         ['dropout_3155[0][0]',        \n",
      "                                                                     'add_1786[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1825 (  (None, 257, 512)             1024      ['add_1787[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_894 (  (None, 257, 512)             1260185   ['layer_normalization_1825[0][\n",
      " MultiHeadAttention)                                      6         0]',                          \n",
      "                                                                     'layer_normalization_1825[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1788 (Add)              (None, 257, 512)             0         ['multi_head_attention_894[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1787[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1826 (  (None, 257, 512)             1024      ['add_1788[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1863 (Dense)          (None, 257, 1024)            525312    ['layer_normalization_1826[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_3156 (Dropout)      (None, 257, 1024)            0         ['dense_1863[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1864 (Dense)          (None, 257, 512)             524800    ['dropout_3156[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3157 (Dropout)      (None, 257, 512)             0         ['dense_1864[0][0]']          \n",
      "                                                                                                  \n",
      " add_1789 (Add)              (None, 257, 512)             0         ['dropout_3157[0][0]',        \n",
      "                                                                     'add_1788[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1827 (  (None, 257, 512)             1024      ['add_1789[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_895 (  (None, 257, 512)             1260185   ['layer_normalization_1827[0][\n",
      " MultiHeadAttention)                                      6         0]',                          \n",
      "                                                                     'layer_normalization_1827[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1790 (Add)              (None, 257, 512)             0         ['multi_head_attention_895[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1789[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1828 (  (None, 257, 512)             1024      ['add_1790[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1865 (Dense)          (None, 257, 1024)            525312    ['layer_normalization_1828[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_3158 (Dropout)      (None, 257, 1024)            0         ['dense_1865[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1866 (Dense)          (None, 257, 512)             524800    ['dropout_3158[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3159 (Dropout)      (None, 257, 512)             0         ['dense_1866[0][0]']          \n",
      "                                                                                                  \n",
      " add_1791 (Add)              (None, 257, 512)             0         ['dropout_3159[0][0]',        \n",
      "                                                                     'add_1790[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1829 (  (None, 257, 512)             1024      ['add_1791[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_896 (  (None, 257, 512)             1260185   ['layer_normalization_1829[0][\n",
      " MultiHeadAttention)                                      6         0]',                          \n",
      "                                                                     'layer_normalization_1829[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1792 (Add)              (None, 257, 512)             0         ['multi_head_attention_896[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1791[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1830 (  (None, 257, 512)             1024      ['add_1792[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1867 (Dense)          (None, 257, 1024)            525312    ['layer_normalization_1830[0][\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_3160 (Dropout)      (None, 257, 1024)            0         ['dense_1867[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1868 (Dense)          (None, 257, 512)             524800    ['dropout_3160[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3161 (Dropout)      (None, 257, 512)             0         ['dense_1868[0][0]']          \n",
      "                                                                                                  \n",
      " add_1793 (Add)              (None, 257, 512)             0         ['dropout_3161[0][0]',        \n",
      "                                                                     'add_1792[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1831 (  (None, 257, 512)             1024      ['add_1793[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_897 (  (None, 257, 512)             1260185   ['layer_normalization_1831[0][\n",
      " MultiHeadAttention)                                      6         0]',                          \n",
      "                                                                     'layer_normalization_1831[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1794 (Add)              (None, 257, 512)             0         ['multi_head_attention_897[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1793[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1832 (  (None, 257, 512)             1024      ['add_1794[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1869 (Dense)          (None, 257, 1024)            525312    ['layer_normalization_1832[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_3162 (Dropout)      (None, 257, 1024)            0         ['dense_1869[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1870 (Dense)          (None, 257, 512)             524800    ['dropout_3162[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3163 (Dropout)      (None, 257, 512)             0         ['dense_1870[0][0]']          \n",
      "                                                                                                  \n",
      " add_1795 (Add)              (None, 257, 512)             0         ['dropout_3163[0][0]',        \n",
      "                                                                     'add_1794[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1833 (  (None, 257, 512)             1024      ['add_1795[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_898 (  (None, 257, 512)             1260185   ['layer_normalization_1833[0][\n",
      " MultiHeadAttention)                                      6         0]',                          \n",
      "                                                                     'layer_normalization_1833[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1796 (Add)              (None, 257, 512)             0         ['multi_head_attention_898[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1795[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1834 (  (None, 257, 512)             1024      ['add_1796[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1871 (Dense)          (None, 257, 1024)            525312    ['layer_normalization_1834[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_3164 (Dropout)      (None, 257, 1024)            0         ['dense_1871[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1872 (Dense)          (None, 257, 512)             524800    ['dropout_3164[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3165 (Dropout)      (None, 257, 512)             0         ['dense_1872[0][0]']          \n",
      "                                                                                                  \n",
      " add_1797 (Add)              (None, 257, 512)             0         ['dropout_3165[0][0]',        \n",
      "                                                                     'add_1796[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1835 (  (None, 257, 512)             1024      ['add_1797[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_899 (  (None, 257, 512)             1260185   ['layer_normalization_1835[0][\n",
      " MultiHeadAttention)                                      6         0]',                          \n",
      "                                                                     'layer_normalization_1835[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1798 (Add)              (None, 257, 512)             0         ['multi_head_attention_899[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1797[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1836 (  (None, 257, 512)             1024      ['add_1798[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1873 (Dense)          (None, 257, 1024)            525312    ['layer_normalization_1836[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dropout_3166 (Dropout)      (None, 257, 1024)            0         ['dense_1873[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1874 (Dense)          (None, 257, 512)             524800    ['dropout_3166[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3167 (Dropout)      (None, 257, 512)             0         ['dense_1874[0][0]']          \n",
      "                                                                                                  \n",
      " add_1799 (Add)              (None, 257, 512)             0         ['dropout_3167[0][0]',        \n",
      "                                                                     'add_1798[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1837 (  (None, 257, 512)             1024      ['add_1799[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_900 (  (None, 257, 512)             1260185   ['layer_normalization_1837[0][\n",
      " MultiHeadAttention)                                      6         0]',                          \n",
      "                                                                     'layer_normalization_1837[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1800 (Add)              (None, 257, 512)             0         ['multi_head_attention_900[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1799[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1838 (  (None, 257, 512)             1024      ['add_1800[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1875 (Dense)          (None, 257, 1024)            525312    ['layer_normalization_1838[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_3168 (Dropout)      (None, 257, 1024)            0         ['dense_1875[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1876 (Dense)          (None, 257, 512)             524800    ['dropout_3168[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3169 (Dropout)      (None, 257, 512)             0         ['dense_1876[0][0]']          \n",
      "                                                                                                  \n",
      " add_1801 (Add)              (None, 257, 512)             0         ['dropout_3169[0][0]',        \n",
      "                                                                     'add_1800[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1839 (  (None, 257, 512)             1024      ['add_1801[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_901 (  (None, 257, 512)             1260185   ['layer_normalization_1839[0][\n",
      " MultiHeadAttention)                                      6         0]',                          \n",
      "                                                                     'layer_normalization_1839[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1802 (Add)              (None, 257, 512)             0         ['multi_head_attention_901[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1801[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1840 (  (None, 257, 512)             1024      ['add_1802[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1877 (Dense)          (None, 257, 1024)            525312    ['layer_normalization_1840[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_3170 (Dropout)      (None, 257, 1024)            0         ['dense_1877[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1878 (Dense)          (None, 257, 512)             524800    ['dropout_3170[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3171 (Dropout)      (None, 257, 512)             0         ['dense_1878[0][0]']          \n",
      "                                                                                                  \n",
      " add_1803 (Add)              (None, 257, 512)             0         ['dropout_3171[0][0]',        \n",
      "                                                                     'add_1802[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1841 (  (None, 257, 512)             1024      ['add_1803[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_902 (  (None, 257, 512)             1260185   ['layer_normalization_1841[0][\n",
      " MultiHeadAttention)                                      6         0]',                          \n",
      "                                                                     'layer_normalization_1841[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1804 (Add)              (None, 257, 512)             0         ['multi_head_attention_902[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1803[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1842 (  (None, 257, 512)             1024      ['add_1804[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1879 (Dense)          (None, 257, 1024)            525312    ['layer_normalization_1842[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_3172 (Dropout)      (None, 257, 1024)            0         ['dense_1879[0][0]']          \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_1880 (Dense)          (None, 257, 512)             524800    ['dropout_3172[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3173 (Dropout)      (None, 257, 512)             0         ['dense_1880[0][0]']          \n",
      "                                                                                                  \n",
      " add_1805 (Add)              (None, 257, 512)             0         ['dropout_3173[0][0]',        \n",
      "                                                                     'add_1804[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1843 (  (None, 257, 512)             1024      ['add_1805[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_903 (  (None, 257, 512)             1260185   ['layer_normalization_1843[0][\n",
      " MultiHeadAttention)                                      6         0]',                          \n",
      "                                                                     'layer_normalization_1843[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1806 (Add)              (None, 257, 512)             0         ['multi_head_attention_903[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1805[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1844 (  (None, 257, 512)             1024      ['add_1806[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1881 (Dense)          (None, 257, 1024)            525312    ['layer_normalization_1844[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_3174 (Dropout)      (None, 257, 1024)            0         ['dense_1881[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1882 (Dense)          (None, 257, 512)             524800    ['dropout_3174[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3175 (Dropout)      (None, 257, 512)             0         ['dense_1882[0][0]']          \n",
      "                                                                                                  \n",
      " add_1807 (Add)              (None, 257, 512)             0         ['dropout_3175[0][0]',        \n",
      "                                                                     'add_1806[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1845 (  (None, 257, 512)             1024      ['add_1807[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_904 (  (None, 257, 512)             1260185   ['layer_normalization_1845[0][\n",
      " MultiHeadAttention)                                      6         0]',                          \n",
      "                                                                     'layer_normalization_1845[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1808 (Add)              (None, 257, 512)             0         ['multi_head_attention_904[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1807[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1846 (  (None, 257, 512)             1024      ['add_1808[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1883 (Dense)          (None, 257, 1024)            525312    ['layer_normalization_1846[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_3176 (Dropout)      (None, 257, 1024)            0         ['dense_1883[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1884 (Dense)          (None, 257, 512)             524800    ['dropout_3176[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3177 (Dropout)      (None, 257, 512)             0         ['dense_1884[0][0]']          \n",
      "                                                                                                  \n",
      " add_1809 (Add)              (None, 257, 512)             0         ['dropout_3177[0][0]',        \n",
      "                                                                     'add_1808[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1847 (  (None, 257, 512)             1024      ['add_1809[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_905 (  (None, 257, 512)             1260185   ['layer_normalization_1847[0][\n",
      " MultiHeadAttention)                                      6         0]',                          \n",
      "                                                                     'layer_normalization_1847[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1810 (Add)              (None, 257, 512)             0         ['multi_head_attention_905[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1809[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1848 (  (None, 257, 512)             1024      ['add_1810[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1885 (Dense)          (None, 257, 1024)            525312    ['layer_normalization_1848[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_3178 (Dropout)      (None, 257, 1024)            0         ['dense_1885[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1886 (Dense)          (None, 257, 512)             524800    ['dropout_3178[0][0]']        \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dropout_3179 (Dropout)      (None, 257, 512)             0         ['dense_1886[0][0]']          \n",
      "                                                                                                  \n",
      " add_1811 (Add)              (None, 257, 512)             0         ['dropout_3179[0][0]',        \n",
      "                                                                     'add_1810[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1849 (  (None, 257, 512)             1024      ['add_1811[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_906 (  (None, 257, 512)             1260185   ['layer_normalization_1849[0][\n",
      " MultiHeadAttention)                                      6         0]',                          \n",
      "                                                                     'layer_normalization_1849[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1812 (Add)              (None, 257, 512)             0         ['multi_head_attention_906[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1811[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1850 (  (None, 257, 512)             1024      ['add_1812[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1887 (Dense)          (None, 257, 1024)            525312    ['layer_normalization_1850[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_3180 (Dropout)      (None, 257, 1024)            0         ['dense_1887[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1888 (Dense)          (None, 257, 512)             524800    ['dropout_3180[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3181 (Dropout)      (None, 257, 512)             0         ['dense_1888[0][0]']          \n",
      "                                                                                                  \n",
      " add_1813 (Add)              (None, 257, 512)             0         ['dropout_3181[0][0]',        \n",
      "                                                                     'add_1812[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1851 (  (None, 257, 512)             1024      ['add_1813[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_907 (  (None, 257, 512)             1260185   ['layer_normalization_1851[0][\n",
      " MultiHeadAttention)                                      6         0]',                          \n",
      "                                                                     'layer_normalization_1851[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1814 (Add)              (None, 257, 512)             0         ['multi_head_attention_907[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1813[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1852 (  (None, 257, 512)             1024      ['add_1814[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1889 (Dense)          (None, 257, 1024)            525312    ['layer_normalization_1852[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_3182 (Dropout)      (None, 257, 1024)            0         ['dense_1889[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1890 (Dense)          (None, 257, 512)             524800    ['dropout_3182[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3183 (Dropout)      (None, 257, 512)             0         ['dense_1890[0][0]']          \n",
      "                                                                                                  \n",
      " add_1815 (Add)              (None, 257, 512)             0         ['dropout_3183[0][0]',        \n",
      "                                                                     'add_1814[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1853 (  (None, 257, 512)             1024      ['add_1815[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_908 (  (None, 257, 512)             1260185   ['layer_normalization_1853[0][\n",
      " MultiHeadAttention)                                      6         0]',                          \n",
      "                                                                     'layer_normalization_1853[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1816 (Add)              (None, 257, 512)             0         ['multi_head_attention_908[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1815[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1854 (  (None, 257, 512)             1024      ['add_1816[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1891 (Dense)          (None, 257, 1024)            525312    ['layer_normalization_1854[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_3184 (Dropout)      (None, 257, 1024)            0         ['dense_1891[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1892 (Dense)          (None, 257, 512)             524800    ['dropout_3184[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3185 (Dropout)      (None, 257, 512)             0         ['dense_1892[0][0]']          \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " add_1817 (Add)              (None, 257, 512)             0         ['dropout_3185[0][0]',        \n",
      "                                                                     'add_1816[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1855 (  (None, 257, 512)             1024      ['add_1817[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_909 (  (None, 257, 512)             1260185   ['layer_normalization_1855[0][\n",
      " MultiHeadAttention)                                      6         0]',                          \n",
      "                                                                     'layer_normalization_1855[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1818 (Add)              (None, 257, 512)             0         ['multi_head_attention_909[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1817[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1856 (  (None, 257, 512)             1024      ['add_1818[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1893 (Dense)          (None, 257, 1024)            525312    ['layer_normalization_1856[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_3186 (Dropout)      (None, 257, 1024)            0         ['dense_1893[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1894 (Dense)          (None, 257, 512)             524800    ['dropout_3186[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3187 (Dropout)      (None, 257, 512)             0         ['dense_1894[0][0]']          \n",
      "                                                                                                  \n",
      " add_1819 (Add)              (None, 257, 512)             0         ['dropout_3187[0][0]',        \n",
      "                                                                     'add_1818[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1857 (  (None, 257, 512)             1024      ['add_1819[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_910 (  (None, 257, 512)             1260185   ['layer_normalization_1857[0][\n",
      " MultiHeadAttention)                                      6         0]',                          \n",
      "                                                                     'layer_normalization_1857[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1820 (Add)              (None, 257, 512)             0         ['multi_head_attention_910[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1819[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1858 (  (None, 257, 512)             1024      ['add_1820[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1895 (Dense)          (None, 257, 1024)            525312    ['layer_normalization_1858[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_3188 (Dropout)      (None, 257, 1024)            0         ['dense_1895[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1896 (Dense)          (None, 257, 512)             524800    ['dropout_3188[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3189 (Dropout)      (None, 257, 512)             0         ['dense_1896[0][0]']          \n",
      "                                                                                                  \n",
      " add_1821 (Add)              (None, 257, 512)             0         ['dropout_3189[0][0]',        \n",
      "                                                                     'add_1820[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1859 (  (None, 257, 512)             1024      ['add_1821[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " multi_head_attention_911 (  (None, 257, 512)             1260185   ['layer_normalization_1859[0][\n",
      " MultiHeadAttention)                                      6         0]',                          \n",
      "                                                                     'layer_normalization_1859[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " add_1822 (Add)              (None, 257, 512)             0         ['multi_head_attention_911[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_1821[0][0]']            \n",
      "                                                                                                  \n",
      " layer_normalization_1860 (  (None, 257, 512)             1024      ['add_1822[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " dense_1897 (Dense)          (None, 257, 1024)            525312    ['layer_normalization_1860[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_3190 (Dropout)      (None, 257, 1024)            0         ['dense_1897[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1898 (Dense)          (None, 257, 512)             524800    ['dropout_3190[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3191 (Dropout)      (None, 257, 512)             0         ['dense_1898[0][0]']          \n",
      "                                                                                                  \n",
      " add_1823 (Add)              (None, 257, 512)             0         ['dropout_3191[0][0]',        \n",
      "                                                                     'add_1822[0][0]']            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " layer_normalization_1861 (  (None, 257, 512)             1024      ['add_1823[0][0]']            \n",
      " LayerNormalization)                                                                              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_4  (None, 512)                  0         ['layer_normalization_1861[0][\n",
      " 2 (SlicingOpLambda)                                                0]']                          \n",
      "                                                                                                  \n",
      " dense_1899 (Dense)          (None, 4)                    2052      ['tf.__operators__.getitem_42[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 329273348 (1.23 GB)\n",
      "Trainable params: 329273348 (1.23 GB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Train: 2778 - Valid: 925 - Test: 925\n",
      "Train: 2778 - Valid: 925 - Test: 925\n",
      "Training for fold 1 ...\n",
      "2\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 1.4474 - acc: 0.4193 - auc: 0.6852 \n",
      "Epoch 1: val_loss improved from inf to 1.30863, saving model to files/modelN_fold1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186/186 [==============================] - 3247s 17s/step - loss: 1.4474 - acc: 0.4193 - auc: 0.6852 - val_loss: 1.3086 - val_acc: 0.4831 - val_auc: 0.8642 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.6127 - acc: 0.7404 - auc: 0.9206 \n",
      "Epoch 2: val_loss improved from 1.30863 to 0.46330, saving model to files/modelN_fold1.h5\n",
      "186/186 [==============================] - 3141s 17s/step - loss: 0.6127 - acc: 0.7404 - auc: 0.9206 - val_loss: 0.4633 - val_acc: 0.8111 - val_auc: 0.9709 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.3606 - acc: 0.8653 - auc: 0.9714 \n",
      "Epoch 3: val_loss improved from 0.46330 to 0.25503, saving model to files/modelN_fold1.h5\n",
      "186/186 [==============================] - 3176s 17s/step - loss: 0.3606 - acc: 0.8653 - auc: 0.9714 - val_loss: 0.2550 - val_acc: 0.9109 - val_auc: 0.9869 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.2527 - acc: 0.9109 - auc: 0.9848 \n",
      "Epoch 4: val_loss did not improve from 0.25503\n",
      "186/186 [==============================] - 2991s 16s/step - loss: 0.2527 - acc: 0.9109 - auc: 0.9848 - val_loss: 0.3990 - val_acc: 0.8381 - val_auc: 0.9851 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.2353 - acc: 0.9139 - auc: 0.9868 \n",
      "Epoch 5: val_loss improved from 0.25503 to 0.21938, saving model to files/modelN_fold1.h5\n",
      "186/186 [==============================] - 3085s 17s/step - loss: 0.2353 - acc: 0.9139 - auc: 0.9868 - val_loss: 0.2194 - val_acc: 0.9163 - val_auc: 0.9891 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1758 - acc: 0.9369 - auc: 0.9925 \n",
      "Epoch 6: val_loss did not improve from 0.21938\n",
      "186/186 [==============================] - 3080s 17s/step - loss: 0.1758 - acc: 0.9369 - auc: 0.9925 - val_loss: 0.3447 - val_acc: 0.8691 - val_auc: 0.9918 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1590 - acc: 0.9386 - auc: 0.9941 \n",
      "Epoch 7: val_loss improved from 0.21938 to 0.19368, saving model to files/modelN_fold1.h5\n",
      "186/186 [==============================] - 3240s 17s/step - loss: 0.1590 - acc: 0.9386 - auc: 0.9941 - val_loss: 0.1937 - val_acc: 0.9366 - val_auc: 0.9940 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1275 - acc: 0.9487 - auc: 0.9958 \n",
      "Epoch 8: val_loss did not improve from 0.19368\n",
      "186/186 [==============================] - 3111s 17s/step - loss: 0.1275 - acc: 0.9487 - auc: 0.9958 - val_loss: 0.2062 - val_acc: 0.9298 - val_auc: 0.9946 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1274 - acc: 0.9578 - auc: 0.9956 \n",
      "Epoch 9: val_loss improved from 0.19368 to 0.16587, saving model to files/modelN_fold1.h5\n",
      "186/186 [==============================] - 3267s 18s/step - loss: 0.1274 - acc: 0.9578 - auc: 0.9956 - val_loss: 0.1659 - val_acc: 0.9406 - val_auc: 0.9949 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1246 - acc: 0.9537 - auc: 0.9958 \n",
      "Epoch 10: val_loss did not improve from 0.16587\n",
      "186/186 [==============================] - 3093s 17s/step - loss: 0.1246 - acc: 0.9537 - auc: 0.9958 - val_loss: 0.2351 - val_acc: 0.9136 - val_auc: 0.9940 - lr: 1.0000e-04\n",
      "3\n",
      "Training for fold 2 ...\n",
      "2\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 1.2648 - acc: 0.4730 - auc: 0.7467 \n",
      "Epoch 1: val_loss improved from inf to 1.25691, saving model to files/modelN_fold2.h5\n",
      "186/186 [==============================] - 3347s 18s/step - loss: 1.2648 - acc: 0.4730 - auc: 0.7467 - val_loss: 1.2569 - val_acc: 0.3954 - val_auc: 0.8146 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.7208 - acc: 0.6857 - auc: 0.8989 \n",
      "Epoch 2: val_loss improved from 1.25691 to 0.61646, saving model to files/modelN_fold2.h5\n",
      "186/186 [==============================] - 3308s 18s/step - loss: 0.7208 - acc: 0.6857 - auc: 0.8989 - val_loss: 0.6165 - val_acc: 0.7031 - val_auc: 0.9644 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.4257 - acc: 0.8336 - auc: 0.9621 \n",
      "Epoch 3: val_loss improved from 0.61646 to 0.35377, saving model to files/modelN_fold2.h5\n",
      "186/186 [==============================] - 3352s 18s/step - loss: 0.4257 - acc: 0.8336 - auc: 0.9621 - val_loss: 0.3538 - val_acc: 0.8489 - val_auc: 0.9869 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.2623 - acc: 0.9078 - auc: 0.9837 \n",
      "Epoch 4: val_loss did not improve from 0.35377\n",
      "186/186 [==============================] - 3158s 17s/step - loss: 0.2623 - acc: 0.9078 - auc: 0.9837 - val_loss: 0.4203 - val_acc: 0.8408 - val_auc: 0.9905 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.2400 - acc: 0.9139 - auc: 0.9864 \n",
      "Epoch 5: val_loss improved from 0.35377 to 0.34801, saving model to files/modelN_fold2.h5\n",
      "186/186 [==============================] - 3293s 18s/step - loss: 0.2400 - acc: 0.9139 - auc: 0.9864 - val_loss: 0.3480 - val_acc: 0.8327 - val_auc: 0.9931 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1951 - acc: 0.9311 - auc: 0.9906 \n",
      "Epoch 6: val_loss improved from 0.34801 to 0.33415, saving model to files/modelN_fold2.h5\n",
      "186/186 [==============================] - 3400s 18s/step - loss: 0.1951 - acc: 0.9311 - auc: 0.9906 - val_loss: 0.3341 - val_acc: 0.8637 - val_auc: 0.9925 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1706 - acc: 0.9332 - auc: 0.9928 \n",
      "Epoch 7: val_loss improved from 0.33415 to 0.17517, saving model to files/modelN_fold2.h5\n",
      "186/186 [==============================] - 3366s 18s/step - loss: 0.1706 - acc: 0.9332 - auc: 0.9928 - val_loss: 0.1752 - val_acc: 0.9312 - val_auc: 0.9962 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1566 - acc: 0.9440 - auc: 0.9935 \n",
      "Epoch 8: val_loss improved from 0.17517 to 0.17413, saving model to files/modelN_fold2.h5\n",
      "186/186 [==============================] - 3358s 18s/step - loss: 0.1566 - acc: 0.9440 - auc: 0.9935 - val_loss: 0.1741 - val_acc: 0.9312 - val_auc: 0.9959 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1267 - acc: 0.9534 - auc: 0.9957 \n",
      "Epoch 9: val_loss did not improve from 0.17413\n",
      "186/186 [==============================] - 3157s 17s/step - loss: 0.1267 - acc: 0.9534 - auc: 0.9957 - val_loss: 0.1810 - val_acc: 0.9420 - val_auc: 0.9926 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1201 - acc: 0.9629 - auc: 0.9960 \n",
      "Epoch 10: val_loss did not improve from 0.17413\n",
      "186/186 [==============================] - 3223s 17s/step - loss: 0.1201 - acc: 0.9629 - auc: 0.9960 - val_loss: 0.2189 - val_acc: 0.9136 - val_auc: 0.9948 - lr: 1.0000e-04\n",
      "3\n",
      "Training for fold 3 ...\n",
      "2\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 1.2698 - acc: 0.4851 - auc: 0.7484 \n",
      "Epoch 1: val_loss improved from inf to 0.93925, saving model to files/modelN_fold3.h5\n",
      "186/186 [==============================] - 3448s 18s/step - loss: 1.2698 - acc: 0.4851 - auc: 0.7484 - val_loss: 0.9392 - val_acc: 0.5061 - val_auc: 0.8636 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.6728 - acc: 0.7080 - auc: 0.9005 \n",
      "Epoch 2: val_loss improved from 0.93925 to 0.47781, saving model to files/modelN_fold3.h5\n",
      "186/186 [==============================] - 3346s 18s/step - loss: 0.6728 - acc: 0.7080 - auc: 0.9005 - val_loss: 0.4778 - val_acc: 0.8003 - val_auc: 0.9666 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.4306 - acc: 0.8336 - auc: 0.9602 \n",
      "Epoch 3: val_loss improved from 0.47781 to 0.27830, saving model to files/modelN_fold3.h5\n",
      "186/186 [==============================] - 3432s 18s/step - loss: 0.4306 - acc: 0.8336 - auc: 0.9602 - val_loss: 0.2783 - val_acc: 0.8920 - val_auc: 0.9850 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.2829 - acc: 0.8916 - auc: 0.9820 \n",
      "Epoch 4: val_loss did not improve from 0.27830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186/186 [==============================] - 3126s 17s/step - loss: 0.2829 - acc: 0.8916 - auc: 0.9820 - val_loss: 0.6126 - val_acc: 0.7625 - val_auc: 0.9762 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.2239 - acc: 0.9183 - auc: 0.9881 \n",
      "Epoch 5: val_loss did not improve from 0.27830\n",
      "186/186 [==============================] - 3202s 17s/step - loss: 0.2239 - acc: 0.9183 - auc: 0.9881 - val_loss: 0.4121 - val_acc: 0.8259 - val_auc: 0.9844 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1679 - acc: 0.9399 - auc: 0.9927 \n",
      "Epoch 6: val_loss did not improve from 0.27830\n",
      "186/186 [==============================] - 3156s 17s/step - loss: 0.1679 - acc: 0.9399 - auc: 0.9927 - val_loss: 0.6995 - val_acc: 0.7220 - val_auc: 0.9834 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1932 - acc: 0.9311 - auc: 0.9909 \n",
      "Epoch 7: val_loss did not improve from 0.27830\n",
      "186/186 [==============================] - 3158s 17s/step - loss: 0.1932 - acc: 0.9311 - auc: 0.9909 - val_loss: 0.3575 - val_acc: 0.8812 - val_auc: 0.9863 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1540 - acc: 0.9443 - auc: 0.9938 \n",
      "Epoch 8: val_loss did not improve from 0.27830\n",
      "186/186 [==============================] - 3154s 17s/step - loss: 0.1540 - acc: 0.9443 - auc: 0.9938 - val_loss: 0.5423 - val_acc: 0.8381 - val_auc: 0.9734 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1246 - acc: 0.9531 - auc: 0.9963 \n",
      "Epoch 9: val_loss did not improve from 0.27830\n",
      "186/186 [==============================] - 3134s 17s/step - loss: 0.1246 - acc: 0.9531 - auc: 0.9963 - val_loss: 0.3857 - val_acc: 0.8785 - val_auc: 0.9842 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1054 - acc: 0.9605 - auc: 0.9968 \n",
      "Epoch 10: val_loss did not improve from 0.27830\n",
      "186/186 [==============================] - 3183s 17s/step - loss: 0.1054 - acc: 0.9605 - auc: 0.9968 - val_loss: 0.2963 - val_acc: 0.9096 - val_auc: 0.9875 - lr: 1.0000e-04\n",
      "3\n",
      "Training for fold 4 ...\n",
      "2\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 1.1853 - acc: 0.5154 - auc: 0.7692 \n",
      "Epoch 1: val_loss improved from inf to 1.27887, saving model to files/modelN_fold4.h5\n",
      "186/186 [==============================] - 3297s 17s/step - loss: 1.1853 - acc: 0.5154 - auc: 0.7692 - val_loss: 1.2789 - val_acc: 0.5176 - val_auc: 0.8518 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.6862 - acc: 0.7141 - auc: 0.8983 \n",
      "Epoch 2: val_loss improved from 1.27887 to 0.54356, saving model to files/modelN_fold4.h5\n",
      "186/186 [==============================] - 3334s 18s/step - loss: 0.6862 - acc: 0.7141 - auc: 0.8983 - val_loss: 0.5436 - val_acc: 0.7811 - val_auc: 0.9660 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.4311 - acc: 0.8404 - auc: 0.9599 \n",
      "Epoch 3: val_loss did not improve from 0.54356\n",
      "186/186 [==============================] - 3171s 17s/step - loss: 0.4311 - acc: 0.8404 - auc: 0.9599 - val_loss: 0.7426 - val_acc: 0.7135 - val_auc: 0.9677 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.2673 - acc: 0.8998 - auc: 0.9835 \n",
      "Epoch 4: val_loss improved from 0.54356 to 0.49973, saving model to files/modelN_fold4.h5\n",
      "186/186 [==============================] - 3555s 19s/step - loss: 0.2673 - acc: 0.8998 - auc: 0.9835 - val_loss: 0.4997 - val_acc: 0.7946 - val_auc: 0.9821 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.2016 - acc: 0.9231 - auc: 0.9899 \n",
      "Epoch 5: val_loss improved from 0.49973 to 0.20982, saving model to files/modelN_fold4.h5\n",
      "186/186 [==============================] - 3579s 19s/step - loss: 0.2016 - acc: 0.9231 - auc: 0.9899 - val_loss: 0.2098 - val_acc: 0.9176 - val_auc: 0.9931 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1597 - acc: 0.9403 - auc: 0.9940 \n",
      "Epoch 6: val_loss did not improve from 0.20982\n",
      "186/186 [==============================] - 3176s 17s/step - loss: 0.1597 - acc: 0.9403 - auc: 0.9940 - val_loss: 0.2293 - val_acc: 0.9135 - val_auc: 0.9917 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1476 - acc: 0.9517 - auc: 0.9938 \n",
      "Epoch 7: val_loss did not improve from 0.20982\n",
      "186/186 [==============================] - 3197s 17s/step - loss: 0.1476 - acc: 0.9517 - auc: 0.9938 - val_loss: 0.4870 - val_acc: 0.8730 - val_auc: 0.9758 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1648 - acc: 0.9382 - auc: 0.9933 \n",
      "Epoch 8: val_loss did not improve from 0.20982\n",
      "186/186 [==============================] - 3202s 17s/step - loss: 0.1648 - acc: 0.9382 - auc: 0.9933 - val_loss: 0.3955 - val_acc: 0.8635 - val_auc: 0.9825 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1559 - acc: 0.9440 - auc: 0.9936 \n",
      "Epoch 9: val_loss did not improve from 0.20982\n",
      "186/186 [==============================] - 3179s 17s/step - loss: 0.1559 - acc: 0.9440 - auc: 0.9936 - val_loss: 0.3159 - val_acc: 0.8892 - val_auc: 0.9901 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1369 - acc: 0.9504 - auc: 0.9951 \n",
      "Epoch 10: val_loss did not improve from 0.20982\n",
      "186/186 [==============================] - 3185s 17s/step - loss: 0.1369 - acc: 0.9504 - auc: 0.9951 - val_loss: 0.5353 - val_acc: 0.8297 - val_auc: 0.9809 - lr: 1.0000e-04\n",
      "3\n",
      "Training for fold 5 ...\n",
      "2\n",
      "Epoch 1/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 1.3001 - acc: 0.4607 - auc: 0.7255 \n",
      "Epoch 1: val_loss improved from inf to 0.93720, saving model to files/modelN_fold5.h5\n",
      "186/186 [==============================] - 3433s 18s/step - loss: 1.3001 - acc: 0.4607 - auc: 0.7255 - val_loss: 0.9372 - val_acc: 0.5284 - val_auc: 0.9120 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.6130 - acc: 0.7469 - auc: 0.9194 \n",
      "Epoch 2: val_loss improved from 0.93720 to 0.42412, saving model to files/modelN_fold5.h5\n",
      "186/186 [==============================] - 3481s 19s/step - loss: 0.6130 - acc: 0.7469 - auc: 0.9194 - val_loss: 0.4241 - val_acc: 0.8216 - val_auc: 0.9758 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.3097 - acc: 0.8819 - auc: 0.9781 \n",
      "Epoch 3: val_loss improved from 0.42412 to 0.18087, saving model to files/modelN_fold5.h5\n",
      "186/186 [==============================] - 3545s 19s/step - loss: 0.3097 - acc: 0.8819 - auc: 0.9781 - val_loss: 0.1809 - val_acc: 0.9392 - val_auc: 0.9924 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.2118 - acc: 0.9207 - auc: 0.9891 \n",
      "Epoch 4: val_loss improved from 0.18087 to 0.16538, saving model to files/modelN_fold5.h5\n",
      "186/186 [==============================] - 3377s 18s/step - loss: 0.2118 - acc: 0.9207 - auc: 0.9891 - val_loss: 0.1654 - val_acc: 0.9365 - val_auc: 0.9938 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1976 - acc: 0.9291 - auc: 0.9905 \n",
      "Epoch 5: val_loss improved from 0.16538 to 0.15181, saving model to files/modelN_fold5.h5\n",
      "186/186 [==============================] - 3627s 20s/step - loss: 0.1976 - acc: 0.9291 - auc: 0.9905 - val_loss: 0.1518 - val_acc: 0.9500 - val_auc: 0.9939 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1481 - acc: 0.9433 - auc: 0.9952 \n",
      "Epoch 6: val_loss did not improve from 0.15181\n",
      "186/186 [==============================] - 3230s 17s/step - loss: 0.1481 - acc: 0.9433 - auc: 0.9952 - val_loss: 0.1822 - val_acc: 0.9419 - val_auc: 0.9927 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1468 - acc: 0.9450 - auc: 0.9947 \n",
      "Epoch 7: val_loss did not improve from 0.15181\n",
      "186/186 [==============================] - 3258s 18s/step - loss: 0.1468 - acc: 0.9450 - auc: 0.9947 - val_loss: 0.3624 - val_acc: 0.8824 - val_auc: 0.9868 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1518 - acc: 0.9396 - auc: 0.9947 \n",
      "Epoch 8: val_loss improved from 0.15181 to 0.14295, saving model to files/modelN_fold5.h5\n",
      "186/186 [==============================] - 3534s 19s/step - loss: 0.1518 - acc: 0.9396 - auc: 0.9947 - val_loss: 0.1429 - val_acc: 0.9446 - val_auc: 0.9944 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1121 - acc: 0.9558 - auc: 0.9968 \n",
      "Epoch 9: val_loss did not improve from 0.14295\n",
      "186/186 [==============================] - 3219s 17s/step - loss: 0.1121 - acc: 0.9558 - auc: 0.9968 - val_loss: 0.2679 - val_acc: 0.9027 - val_auc: 0.9915 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.1128 - acc: 0.9561 - auc: 0.9966 \n",
      "Epoch 10: val_loss did not improve from 0.14295\n",
      "186/186 [==============================] - 3233s 17s/step - loss: 0.1128 - acc: 0.9561 - auc: 0.9966 - val_loss: 0.4101 - val_acc: 0.8703 - val_auc: 0.9867 - lr: 1.0000e-04\n",
      "3\n",
      "Evaluating the test set...\n",
      "58/58 [==============================] - 323s 5s/step\n",
      "58/58 [==============================] - 296s 5s/step\n",
      " 1/58 [..............................] - ETA: 11:37"
     ]
    }
   ],
   "source": [
    "# train only\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "\n",
    "class ClassToken(Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        w_init = tf.random_normal_initializer()\n",
    "        self.w = tf.Variable(\n",
    "            initial_value = w_init(shape=(1, 1, input_shape[-1]), dtype=tf.float32),\n",
    "            trainable = True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        hidden_dim = self.w.shape[-1]\n",
    "\n",
    "        cls = tf.broadcast_to(self.w, [batch_size, 1, hidden_dim])\n",
    "        cls = tf.cast(cls, dtype=inputs.dtype)\n",
    "        return cls\n",
    "\n",
    "def mlp(x, cf):\n",
    "    x = Dense(cf[\"mlp_dim\"], activation=\"gelu\")(x)\n",
    "    x = Dropout(cf[\"dropout_rate\"])(x)\n",
    "    x = Dense(cf[\"hidden_dim\"])(x)\n",
    "    x = Dropout(cf[\"dropout_rate\"])(x)\n",
    "    return x\n",
    "\n",
    "def transformer_encoder(x, cf):\n",
    "    skip_1 = x\n",
    "    x = LayerNormalization()(x)\n",
    "    x = MultiHeadAttention(\n",
    "        num_heads=cf[\"num_heads\"], key_dim=cf[\"hidden_dim\"]\n",
    "    )(x, x)\n",
    "    x = Add()([x, skip_1])\n",
    "\n",
    "    skip_2 = x\n",
    "    x = LayerNormalization()(x)\n",
    "    x = mlp(x, cf)\n",
    "    x = Add()([x, skip_2])\n",
    "\n",
    "    return x\n",
    "\n",
    "def ViT(cf):\n",
    "    \"\"\" Inputs \"\"\"\n",
    "    input_shape = (cf[\"num_patches\"], cf[\"patch_size\"]*cf[\"patch_size\"]*cf[\"num_channels\"])\n",
    "    inputs = Input(input_shape)     ## (None, 256, 3072)\n",
    "\n",
    "    \"\"\" Patch + Position Embeddings \"\"\"\n",
    "    patch_embed = Dense(cf[\"hidden_dim\"])(inputs)   ## (None, 256, 768)\n",
    "\n",
    "    positions = tf.range(start=0, limit=cf[\"num_patches\"], delta=1)\n",
    "    pos_embed = Embedding(input_dim=cf[\"num_patches\"], output_dim=cf[\"hidden_dim\"])(positions) ## (256, 768)\n",
    "    embed = patch_embed + pos_embed ## (None, 256, 768)\n",
    "\n",
    "    \"\"\" Adding Class Token \"\"\"\n",
    "    token = ClassToken()(embed)\n",
    "    x = Concatenate(axis=1)([token, embed]) ## (None, 257, 768)\n",
    "\n",
    "    for _ in range(cf[\"num_layers\"]):\n",
    "        x = transformer_encoder(x, cf)\n",
    "\n",
    "    \"\"\" Classification Head \"\"\"\n",
    "    x = LayerNormalization()(x)     ## (None, 257, 768)\n",
    "    x = x[:, 0, :]\n",
    "    x = Dense(cf[\"num_classes\"], activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs, x)\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config = {}\n",
    "    config[\"num_layers\"] = 24\n",
    "#     config[\"hidden_dim\"] = 768\n",
    "#     config[\"mlp_dim\"] =3072\n",
    "    config[\"num_heads\"] = 12\n",
    "    config[\"dropout_rate\"] = 0.1\n",
    "    config[\"num_patches\"] = 256\n",
    "    config[\"patch_size\"] = 32\n",
    "    config[\"num_channels\"] = 3\n",
    "    config[\"num_classes\"] = 4\n",
    "\n",
    "    config[\"hidden_dim\"] = 512\n",
    "    config[\"mlp_dim\"] = 1024  \n",
    "\n",
    "    model = ViT(config)\n",
    "    model.summary()\n",
    "\n",
    "\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive/')\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from keras.metrics import AUC\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
    "from patchify import patchify\n",
    "# import tensorflow_hub as hub\n",
    "# Assuming you have already imported or defined the ViT model\n",
    "# ...\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "#from project import ViT\n",
    "hp = {\n",
    "    \"image_size\": 512,\n",
    "    \"num_channels\": 3,\n",
    "    \"patch_size\": 64,\n",
    "    \"num_classes\": 4,\n",
    "    \"class_names\": [\"Yellow_rust\",\"Brown_rust\", \"Healthy\",\"Blast_Leaves\"],\n",
    "    \"num_layers\": 24,\n",
    "    \"hidden_dim\": 512,\n",
    "    \"mlp_dim\": 1024,\n",
    "    \"num_heads\": 4,\n",
    "    \"dropout_rate\": 0.1,\n",
    "    \"batch_size\": 16,\n",
    "    \"lr\": 1e-4,\n",
    "    \"num_epochs\": 10\n",
    "}\n",
    "hp[\"num_patches\"] = (hp[\"image_size\"] ** 2) // (hp[\"patch_size\"] ** 2)\n",
    "hp[\"flat_patches_shape\"] = (hp[\"num_patches\"], hp[\"patch_size\"] * hp[\"patch_size\"] * hp[\"num_channels\"])\n",
    "\n",
    "\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "\n",
    "def load_data(path, split=0.20):\n",
    "    images = glob(os.path.join(path, \"*\", \"*.jpg\"))\n",
    "\n",
    "    # Separate images by class\n",
    "    images_class_BKL = [image for image in images if \"Yellow_rust\" in image]\n",
    "    images_class_NV = [image for image in images if \"Brown_rust\" in image]\n",
    "    images_class_MEL2 = [image for image in images if \"Healthy\" in image]\n",
    "    images_class_BlastLeaves = [image for image in images if \"Blast_Leaves\" in image]\n",
    "\n",
    "    # Oversample to 33,000 to match the largest class (BKL)\n",
    "    target_size = len(images_class_BKL)\n",
    "    #print(images_class_BKL)\n",
    "    images_class_NV = np.random.choice(images_class_NV, size=target_size, replace=True).tolist()\n",
    "    images_class_MEL2 = np.random.choice(images_class_MEL2, size=target_size, replace=True).tolist()\n",
    "    images_class_BlastLeaves = np.random.choice(images_class_BlastLeaves, size=target_size, replace=True).tolist()\n",
    "    # Concatenate lists again and shuffle\n",
    "    images = shuffle(images_class_BKL + images_class_NV + images_class_MEL2+ images_class_BlastLeaves)\n",
    "\n",
    "    split_size = int(len(images) * split)\n",
    "    train_x, valid_x = train_test_split(images, test_size=split_size, random_state=42)\n",
    "    train_x, test_x = train_test_split(train_x, test_size=split_size, random_state=42)\n",
    "    print(f\"Train: {len(train_x)} - Valid: {len(valid_x)} - Test: {len(test_x)}\")\n",
    "\n",
    "    return train_x, valid_x, test_x\n",
    "\n",
    "\n",
    "def process_image_label(path):\n",
    "    path = path.decode()\n",
    "    image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (hp[\"image_size\"], hp[\"image_size\"]))\n",
    "    image = image / 255.0\n",
    "\n",
    "    patch_shape = (hp[\"patch_size\"], hp[\"patch_size\"], hp[\"num_channels\"])\n",
    "    patches = patchify(image, patch_shape, hp[\"patch_size\"])\n",
    "    patches = np.reshape(patches, hp[\"flat_patches_shape\"])\n",
    "    patches = patches.astype(np.float32)\n",
    "\n",
    "    class_name = path.split(\"/\")[-2]\n",
    "    class_idx = hp[\"class_names\"].index(class_name)\n",
    "    class_idx = np.array(class_idx, dtype=np.int32)\n",
    "    return patches, class_idx\n",
    "\n",
    "\n",
    "def parse(path):\n",
    "    patches, labels = tf.numpy_function(process_image_label, [path], [tf.float32, tf.int32])\n",
    "    labels = tf.one_hot(labels, hp[\"num_classes\"])\n",
    "\n",
    "    patches.set_shape(hp[\"flat_patches_shape\"])\n",
    "    labels.set_shape(hp[\"num_classes\"])\n",
    "\n",
    "    return patches, labels\n",
    "\n",
    "\n",
    "def tf_dataset(images, batch=32):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((images))\n",
    "    ds = ds.map(parse).batch(batch).prefetch(8)\n",
    "    return ds\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    model = ViT(hp)\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        optimizer=tf.keras.optimizers.Adam(hp[\"lr\"], clipvalue=1.0),\n",
    "        metrics=[\"acc\", AUC(name='auc', multi_label=True)]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_dir(\"files\")\n",
    "    dataset_path = '/home/ali/Music/PYTHON/WholeDataset'\n",
    "    model_path = os.path.join(\"files\", \"model3.h5\")\n",
    "    csv_path = os.path.join(\"files\", \"log2.csv\")\n",
    "    train_x, valid_x, test_x = load_data(dataset_path)\n",
    "    images = train_x + valid_x\n",
    "    print(f\"Train: {len(train_x)} - Valid: {len(valid_x)} - Test: {len(test_x)}\")\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    fold_no = 1\n",
    "\n",
    "    for train, val in kfold.split(images):\n",
    "        print(f'Training for fold {fold_no} ...')\n",
    "        train_ds = tf_dataset(np.array(images)[train], batch=hp[\"batch_size\"])\n",
    "        valid_ds = tf_dataset(np.array(images)[val], batch=hp[\"batch_size\"])\n",
    "        model = get_model()\n",
    "        callbacks = [\n",
    "            ModelCheckpoint(f\"files/modelN_fold{fold_no}.h5\", monitor='val_loss', verbose=1, save_best_only=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, min_lr=1e-10, verbose=1),\n",
    "            CSVLogger(f\"files/log2_fold{fold_no}.csv\"),\n",
    "            EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=False),\n",
    "        ]\n",
    "        print(2)\n",
    "        model.fit(train_ds, epochs=hp[\"num_epochs\"], validation_data=valid_ds, callbacks=callbacks)\n",
    "        fold_no += 1\n",
    "        print(3)\n",
    "\n",
    "    # Evaluating on the test set\n",
    "    print(\"Evaluating the test set...\")\n",
    "    test_ds = tf_dataset(test_x, batch=hp[\"batch_size\"])\n",
    "    all_preds = []\n",
    "    custom_objects = {\"ClassToken\": ClassToken}\n",
    "    for fold_no in range(1, 6):\n",
    "        with tf.keras.utils.custom_object_scope(custom_objects):\n",
    "            fold_model = tf.keras.models.load_model(f\"files/modelN_fold{fold_no}.h5\")\n",
    "        y_pred_probs = fold_model.predict(test_ds)\n",
    "        all_preds.append(y_pred_probs)\n",
    "\n",
    "    avg_preds = np.mean(all_preds, axis=0)\n",
    "    final_preds = np.argmax(avg_preds, axis=1)\n",
    "    y_true = [hp[\"class_names\"].index(img.split(\"/\")[-2]) for img in test_x]\n",
    "    print(classification_report(y_true, final_preds, target_names=hp[\"class_names\"]))\n",
    "    roc_aucs = []\n",
    "\n",
    "    for i, class_name in enumerate(hp[\"class_names\"]):\n",
    "        auc_val = roc_auc_score((np.array(y_true) == i).astype(int), avg_preds[:, i])\n",
    "        roc_aucs.append(auc_val)\n",
    "        print(f\"AUC-ROC ({class_name}): {auc_val:.4f}\")\n",
    "\n",
    "    for i, class_name in enumerate(hp[\"class_names\"]):\n",
    "        fpr, tpr, _ = roc_curve((np.array(y_true) == i).astype(int), avg_preds[:, i])\n",
    "        plt.plot(fpr, tpr, label=f\"{class_name} (AUC = {roc_aucs[i]:.2f})\")\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], color='grey', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 256, 3072)]          0         []                            \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 256, 512)             1573376   ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOp  (None, 256, 512)             0         ['dense[0][0]']               \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " class_token (ClassToken)    (None, 1, 512)               512       ['tf.__operators__.add[0][0]']\n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 257, 512)             0         ['class_token[0][0]',         \n",
      "                                                                     'tf.__operators__.add[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization (Layer  (None, 257, 512)             1024      ['concatenate[0][0]']         \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " multi_head_attention (Mult  (None, 257, 512)             1260185   ['layer_normalization[0][0]', \n",
      " iHeadAttention)                                          6          'layer_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " add (Add)                   (None, 257, 512)             0         ['multi_head_attention[0][0]',\n",
      "                                                                     'concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " layer_normalization_1 (Lay  (None, 257, 512)             1024      ['add[0][0]']                 \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 257, 1024)            525312    ['layer_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 257, 1024)            0         ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 257, 512)             524800    ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 257, 512)             0         ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " add_1 (Add)                 (None, 257, 512)             0         ['dropout_1[0][0]',           \n",
      "                                                                     'add[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_2 (Lay  (None, 257, 512)             1024      ['add_1[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (Mu  (None, 257, 512)             1260185   ['layer_normalization_2[0][0]'\n",
      " ltiHeadAttention)                                        6         , 'layer_normalization_2[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_2 (Add)                 (None, 257, 512)             0         ['multi_head_attention_1[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'add_1[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_3 (Lay  (None, 257, 512)             1024      ['add_2[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 257, 1024)            525312    ['layer_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 257, 1024)            0         ['dense_3[0][0]']             \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 257, 512)             524800    ['dropout_2[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)         (None, 257, 512)             0         ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      " add_3 (Add)                 (None, 257, 512)             0         ['dropout_3[0][0]',           \n",
      "                                                                     'add_2[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_4 (Lay  (None, 257, 512)             1024      ['add_3[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (Mu  (None, 257, 512)             1260185   ['layer_normalization_4[0][0]'\n",
      " ltiHeadAttention)                                        6         , 'layer_normalization_4[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_4 (Add)                 (None, 257, 512)             0         ['multi_head_attention_2[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'add_3[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_5 (Lay  (None, 257, 512)             1024      ['add_4[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 257, 1024)            525312    ['layer_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)         (None, 257, 1024)            0         ['dense_5[0][0]']             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 257, 512)             524800    ['dropout_4[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)         (None, 257, 512)             0         ['dense_6[0][0]']             \n",
      "                                                                                                  \n",
      " add_5 (Add)                 (None, 257, 512)             0         ['dropout_5[0][0]',           \n",
      "                                                                     'add_4[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_6 (Lay  (None, 257, 512)             1024      ['add_5[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (Mu  (None, 257, 512)             1260185   ['layer_normalization_6[0][0]'\n",
      " ltiHeadAttention)                                        6         , 'layer_normalization_6[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_6 (Add)                 (None, 257, 512)             0         ['multi_head_attention_3[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'add_5[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_7 (Lay  (None, 257, 512)             1024      ['add_6[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, 257, 1024)            525312    ['layer_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)         (None, 257, 1024)            0         ['dense_7[0][0]']             \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, 257, 512)             524800    ['dropout_6[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)         (None, 257, 512)             0         ['dense_8[0][0]']             \n",
      "                                                                                                  \n",
      " add_7 (Add)                 (None, 257, 512)             0         ['dropout_7[0][0]',           \n",
      "                                                                     'add_6[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_8 (Lay  (None, 257, 512)             1024      ['add_7[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " multi_head_attention_4 (Mu  (None, 257, 512)             1260185   ['layer_normalization_8[0][0]'\n",
      " ltiHeadAttention)                                        6         , 'layer_normalization_8[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_8 (Add)                 (None, 257, 512)             0         ['multi_head_attention_4[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'add_7[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_9 (Lay  (None, 257, 512)             1024      ['add_8[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dense_9 (Dense)             (None, 257, 1024)            525312    ['layer_normalization_9[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)         (None, 257, 1024)            0         ['dense_9[0][0]']             \n",
      "                                                                                                  \n",
      " dense_10 (Dense)            (None, 257, 512)             524800    ['dropout_8[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)         (None, 257, 512)             0         ['dense_10[0][0]']            \n",
      "                                                                                                  \n",
      " add_9 (Add)                 (None, 257, 512)             0         ['dropout_9[0][0]',           \n",
      "                                                                     'add_8[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_10 (La  (None, 257, 512)             1024      ['add_9[0][0]']               \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_5 (Mu  (None, 257, 512)             1260185   ['layer_normalization_10[0][0]\n",
      " ltiHeadAttention)                                        6         ',                            \n",
      "                                                                     'layer_normalization_10[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_10 (Add)                (None, 257, 512)             0         ['multi_head_attention_5[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'add_9[0][0]']               \n",
      "                                                                                                  \n",
      " layer_normalization_11 (La  (None, 257, 512)             1024      ['add_10[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_11 (Dense)            (None, 257, 1024)            525312    ['layer_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)        (None, 257, 1024)            0         ['dense_11[0][0]']            \n",
      "                                                                                                  \n",
      " dense_12 (Dense)            (None, 257, 512)             524800    ['dropout_10[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)        (None, 257, 512)             0         ['dense_12[0][0]']            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " add_11 (Add)                (None, 257, 512)             0         ['dropout_11[0][0]',          \n",
      "                                                                     'add_10[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_12 (La  (None, 257, 512)             1024      ['add_11[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_6 (Mu  (None, 257, 512)             1260185   ['layer_normalization_12[0][0]\n",
      " ltiHeadAttention)                                        6         ',                            \n",
      "                                                                     'layer_normalization_12[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_12 (Add)                (None, 257, 512)             0         ['multi_head_attention_6[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'add_11[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_13 (La  (None, 257, 512)             1024      ['add_12[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_13 (Dense)            (None, 257, 1024)            525312    ['layer_normalization_13[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)        (None, 257, 1024)            0         ['dense_13[0][0]']            \n",
      "                                                                                                  \n",
      " dense_14 (Dense)            (None, 257, 512)             524800    ['dropout_12[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)        (None, 257, 512)             0         ['dense_14[0][0]']            \n",
      "                                                                                                  \n",
      " add_13 (Add)                (None, 257, 512)             0         ['dropout_13[0][0]',          \n",
      "                                                                     'add_12[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_14 (La  (None, 257, 512)             1024      ['add_13[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_7 (Mu  (None, 257, 512)             1260185   ['layer_normalization_14[0][0]\n",
      " ltiHeadAttention)                                        6         ',                            \n",
      "                                                                     'layer_normalization_14[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_14 (Add)                (None, 257, 512)             0         ['multi_head_attention_7[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'add_13[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_15 (La  (None, 257, 512)             1024      ['add_14[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_15 (Dense)            (None, 257, 1024)            525312    ['layer_normalization_15[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)        (None, 257, 1024)            0         ['dense_15[0][0]']            \n",
      "                                                                                                  \n",
      " dense_16 (Dense)            (None, 257, 512)             524800    ['dropout_14[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)        (None, 257, 512)             0         ['dense_16[0][0]']            \n",
      "                                                                                                  \n",
      " add_15 (Add)                (None, 257, 512)             0         ['dropout_15[0][0]',          \n",
      "                                                                     'add_14[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_16 (La  (None, 257, 512)             1024      ['add_15[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_8 (Mu  (None, 257, 512)             1260185   ['layer_normalization_16[0][0]\n",
      " ltiHeadAttention)                                        6         ',                            \n",
      "                                                                     'layer_normalization_16[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_16 (Add)                (None, 257, 512)             0         ['multi_head_attention_8[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'add_15[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_17 (La  (None, 257, 512)             1024      ['add_16[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_17 (Dense)            (None, 257, 1024)            525312    ['layer_normalization_17[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)        (None, 257, 1024)            0         ['dense_17[0][0]']            \n",
      "                                                                                                  \n",
      " dense_18 (Dense)            (None, 257, 512)             524800    ['dropout_16[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)        (None, 257, 512)             0         ['dense_18[0][0]']            \n",
      "                                                                                                  \n",
      " add_17 (Add)                (None, 257, 512)             0         ['dropout_17[0][0]',          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                     'add_16[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_18 (La  (None, 257, 512)             1024      ['add_17[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_9 (Mu  (None, 257, 512)             1260185   ['layer_normalization_18[0][0]\n",
      " ltiHeadAttention)                                        6         ',                            \n",
      "                                                                     'layer_normalization_18[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_18 (Add)                (None, 257, 512)             0         ['multi_head_attention_9[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'add_17[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_19 (La  (None, 257, 512)             1024      ['add_18[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_19 (Dense)            (None, 257, 1024)            525312    ['layer_normalization_19[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_18 (Dropout)        (None, 257, 1024)            0         ['dense_19[0][0]']            \n",
      "                                                                                                  \n",
      " dense_20 (Dense)            (None, 257, 512)             524800    ['dropout_18[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)        (None, 257, 512)             0         ['dense_20[0][0]']            \n",
      "                                                                                                  \n",
      " add_19 (Add)                (None, 257, 512)             0         ['dropout_19[0][0]',          \n",
      "                                                                     'add_18[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_20 (La  (None, 257, 512)             1024      ['add_19[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_10 (M  (None, 257, 512)             1260185   ['layer_normalization_20[0][0]\n",
      " ultiHeadAttention)                                       6         ',                            \n",
      "                                                                     'layer_normalization_20[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_20 (Add)                (None, 257, 512)             0         ['multi_head_attention_10[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'add_19[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_21 (La  (None, 257, 512)             1024      ['add_20[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_21 (Dense)            (None, 257, 1024)            525312    ['layer_normalization_21[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_20 (Dropout)        (None, 257, 1024)            0         ['dense_21[0][0]']            \n",
      "                                                                                                  \n",
      " dense_22 (Dense)            (None, 257, 512)             524800    ['dropout_20[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_21 (Dropout)        (None, 257, 512)             0         ['dense_22[0][0]']            \n",
      "                                                                                                  \n",
      " add_21 (Add)                (None, 257, 512)             0         ['dropout_21[0][0]',          \n",
      "                                                                     'add_20[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_22 (La  (None, 257, 512)             1024      ['add_21[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_11 (M  (None, 257, 512)             1260185   ['layer_normalization_22[0][0]\n",
      " ultiHeadAttention)                                       6         ',                            \n",
      "                                                                     'layer_normalization_22[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_22 (Add)                (None, 257, 512)             0         ['multi_head_attention_11[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'add_21[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_23 (La  (None, 257, 512)             1024      ['add_22[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_23 (Dense)            (None, 257, 1024)            525312    ['layer_normalization_23[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_22 (Dropout)        (None, 257, 1024)            0         ['dense_23[0][0]']            \n",
      "                                                                                                  \n",
      " dense_24 (Dense)            (None, 257, 512)             524800    ['dropout_22[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_23 (Dropout)        (None, 257, 512)             0         ['dense_24[0][0]']            \n",
      "                                                                                                  \n",
      " add_23 (Add)                (None, 257, 512)             0         ['dropout_23[0][0]',          \n",
      "                                                                     'add_22[0][0]']              \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " layer_normalization_24 (La  (None, 257, 512)             1024      ['add_23[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_12 (M  (None, 257, 512)             1260185   ['layer_normalization_24[0][0]\n",
      " ultiHeadAttention)                                       6         ',                            \n",
      "                                                                     'layer_normalization_24[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_24 (Add)                (None, 257, 512)             0         ['multi_head_attention_12[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'add_23[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_25 (La  (None, 257, 512)             1024      ['add_24[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_25 (Dense)            (None, 257, 1024)            525312    ['layer_normalization_25[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_24 (Dropout)        (None, 257, 1024)            0         ['dense_25[0][0]']            \n",
      "                                                                                                  \n",
      " dense_26 (Dense)            (None, 257, 512)             524800    ['dropout_24[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_25 (Dropout)        (None, 257, 512)             0         ['dense_26[0][0]']            \n",
      "                                                                                                  \n",
      " add_25 (Add)                (None, 257, 512)             0         ['dropout_25[0][0]',          \n",
      "                                                                     'add_24[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_26 (La  (None, 257, 512)             1024      ['add_25[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_13 (M  (None, 257, 512)             1260185   ['layer_normalization_26[0][0]\n",
      " ultiHeadAttention)                                       6         ',                            \n",
      "                                                                     'layer_normalization_26[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_26 (Add)                (None, 257, 512)             0         ['multi_head_attention_13[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'add_25[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_27 (La  (None, 257, 512)             1024      ['add_26[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_27 (Dense)            (None, 257, 1024)            525312    ['layer_normalization_27[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_26 (Dropout)        (None, 257, 1024)            0         ['dense_27[0][0]']            \n",
      "                                                                                                  \n",
      " dense_28 (Dense)            (None, 257, 512)             524800    ['dropout_26[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_27 (Dropout)        (None, 257, 512)             0         ['dense_28[0][0]']            \n",
      "                                                                                                  \n",
      " add_27 (Add)                (None, 257, 512)             0         ['dropout_27[0][0]',          \n",
      "                                                                     'add_26[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_28 (La  (None, 257, 512)             1024      ['add_27[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_14 (M  (None, 257, 512)             1260185   ['layer_normalization_28[0][0]\n",
      " ultiHeadAttention)                                       6         ',                            \n",
      "                                                                     'layer_normalization_28[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_28 (Add)                (None, 257, 512)             0         ['multi_head_attention_14[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'add_27[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_29 (La  (None, 257, 512)             1024      ['add_28[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_29 (Dense)            (None, 257, 1024)            525312    ['layer_normalization_29[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_28 (Dropout)        (None, 257, 1024)            0         ['dense_29[0][0]']            \n",
      "                                                                                                  \n",
      " dense_30 (Dense)            (None, 257, 512)             524800    ['dropout_28[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_29 (Dropout)        (None, 257, 512)             0         ['dense_30[0][0]']            \n",
      "                                                                                                  \n",
      " add_29 (Add)                (None, 257, 512)             0         ['dropout_29[0][0]',          \n",
      "                                                                     'add_28[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_30 (La  (None, 257, 512)             1024      ['add_29[0][0]']              \n",
      " yerNormalization)                                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " multi_head_attention_15 (M  (None, 257, 512)             1260185   ['layer_normalization_30[0][0]\n",
      " ultiHeadAttention)                                       6         ',                            \n",
      "                                                                     'layer_normalization_30[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_30 (Add)                (None, 257, 512)             0         ['multi_head_attention_15[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'add_29[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_31 (La  (None, 257, 512)             1024      ['add_30[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_31 (Dense)            (None, 257, 1024)            525312    ['layer_normalization_31[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_30 (Dropout)        (None, 257, 1024)            0         ['dense_31[0][0]']            \n",
      "                                                                                                  \n",
      " dense_32 (Dense)            (None, 257, 512)             524800    ['dropout_30[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_31 (Dropout)        (None, 257, 512)             0         ['dense_32[0][0]']            \n",
      "                                                                                                  \n",
      " add_31 (Add)                (None, 257, 512)             0         ['dropout_31[0][0]',          \n",
      "                                                                     'add_30[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_32 (La  (None, 257, 512)             1024      ['add_31[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_16 (M  (None, 257, 512)             1260185   ['layer_normalization_32[0][0]\n",
      " ultiHeadAttention)                                       6         ',                            \n",
      "                                                                     'layer_normalization_32[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_32 (Add)                (None, 257, 512)             0         ['multi_head_attention_16[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'add_31[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_33 (La  (None, 257, 512)             1024      ['add_32[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_33 (Dense)            (None, 257, 1024)            525312    ['layer_normalization_33[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_32 (Dropout)        (None, 257, 1024)            0         ['dense_33[0][0]']            \n",
      "                                                                                                  \n",
      " dense_34 (Dense)            (None, 257, 512)             524800    ['dropout_32[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_33 (Dropout)        (None, 257, 512)             0         ['dense_34[0][0]']            \n",
      "                                                                                                  \n",
      " add_33 (Add)                (None, 257, 512)             0         ['dropout_33[0][0]',          \n",
      "                                                                     'add_32[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_34 (La  (None, 257, 512)             1024      ['add_33[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_17 (M  (None, 257, 512)             1260185   ['layer_normalization_34[0][0]\n",
      " ultiHeadAttention)                                       6         ',                            \n",
      "                                                                     'layer_normalization_34[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_34 (Add)                (None, 257, 512)             0         ['multi_head_attention_17[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'add_33[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_35 (La  (None, 257, 512)             1024      ['add_34[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_35 (Dense)            (None, 257, 1024)            525312    ['layer_normalization_35[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_34 (Dropout)        (None, 257, 1024)            0         ['dense_35[0][0]']            \n",
      "                                                                                                  \n",
      " dense_36 (Dense)            (None, 257, 512)             524800    ['dropout_34[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_35 (Dropout)        (None, 257, 512)             0         ['dense_36[0][0]']            \n",
      "                                                                                                  \n",
      " add_35 (Add)                (None, 257, 512)             0         ['dropout_35[0][0]',          \n",
      "                                                                     'add_34[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_36 (La  (None, 257, 512)             1024      ['add_35[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_18 (M  (None, 257, 512)             1260185   ['layer_normalization_36[0][0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ultiHeadAttention)                                       6         ',                            \n",
      "                                                                     'layer_normalization_36[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_36 (Add)                (None, 257, 512)             0         ['multi_head_attention_18[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'add_35[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_37 (La  (None, 257, 512)             1024      ['add_36[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_37 (Dense)            (None, 257, 1024)            525312    ['layer_normalization_37[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_36 (Dropout)        (None, 257, 1024)            0         ['dense_37[0][0]']            \n",
      "                                                                                                  \n",
      " dense_38 (Dense)            (None, 257, 512)             524800    ['dropout_36[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)        (None, 257, 512)             0         ['dense_38[0][0]']            \n",
      "                                                                                                  \n",
      " add_37 (Add)                (None, 257, 512)             0         ['dropout_37[0][0]',          \n",
      "                                                                     'add_36[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_38 (La  (None, 257, 512)             1024      ['add_37[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_19 (M  (None, 257, 512)             1260185   ['layer_normalization_38[0][0]\n",
      " ultiHeadAttention)                                       6         ',                            \n",
      "                                                                     'layer_normalization_38[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_38 (Add)                (None, 257, 512)             0         ['multi_head_attention_19[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'add_37[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_39 (La  (None, 257, 512)             1024      ['add_38[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_39 (Dense)            (None, 257, 1024)            525312    ['layer_normalization_39[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_38 (Dropout)        (None, 257, 1024)            0         ['dense_39[0][0]']            \n",
      "                                                                                                  \n",
      " dense_40 (Dense)            (None, 257, 512)             524800    ['dropout_38[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_39 (Dropout)        (None, 257, 512)             0         ['dense_40[0][0]']            \n",
      "                                                                                                  \n",
      " add_39 (Add)                (None, 257, 512)             0         ['dropout_39[0][0]',          \n",
      "                                                                     'add_38[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_40 (La  (None, 257, 512)             1024      ['add_39[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_20 (M  (None, 257, 512)             1260185   ['layer_normalization_40[0][0]\n",
      " ultiHeadAttention)                                       6         ',                            \n",
      "                                                                     'layer_normalization_40[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_40 (Add)                (None, 257, 512)             0         ['multi_head_attention_20[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'add_39[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_41 (La  (None, 257, 512)             1024      ['add_40[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_41 (Dense)            (None, 257, 1024)            525312    ['layer_normalization_41[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_40 (Dropout)        (None, 257, 1024)            0         ['dense_41[0][0]']            \n",
      "                                                                                                  \n",
      " dense_42 (Dense)            (None, 257, 512)             524800    ['dropout_40[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_41 (Dropout)        (None, 257, 512)             0         ['dense_42[0][0]']            \n",
      "                                                                                                  \n",
      " add_41 (Add)                (None, 257, 512)             0         ['dropout_41[0][0]',          \n",
      "                                                                     'add_40[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_42 (La  (None, 257, 512)             1024      ['add_41[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_21 (M  (None, 257, 512)             1260185   ['layer_normalization_42[0][0]\n",
      " ultiHeadAttention)                                       6         ',                            \n",
      "                                                                     'layer_normalization_42[0][0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_42 (Add)                (None, 257, 512)             0         ['multi_head_attention_21[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'add_41[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_43 (La  (None, 257, 512)             1024      ['add_42[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_43 (Dense)            (None, 257, 1024)            525312    ['layer_normalization_43[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_42 (Dropout)        (None, 257, 1024)            0         ['dense_43[0][0]']            \n",
      "                                                                                                  \n",
      " dense_44 (Dense)            (None, 257, 512)             524800    ['dropout_42[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_43 (Dropout)        (None, 257, 512)             0         ['dense_44[0][0]']            \n",
      "                                                                                                  \n",
      " add_43 (Add)                (None, 257, 512)             0         ['dropout_43[0][0]',          \n",
      "                                                                     'add_42[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_44 (La  (None, 257, 512)             1024      ['add_43[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_22 (M  (None, 257, 512)             1260185   ['layer_normalization_44[0][0]\n",
      " ultiHeadAttention)                                       6         ',                            \n",
      "                                                                     'layer_normalization_44[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_44 (Add)                (None, 257, 512)             0         ['multi_head_attention_22[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'add_43[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_45 (La  (None, 257, 512)             1024      ['add_44[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_45 (Dense)            (None, 257, 1024)            525312    ['layer_normalization_45[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_44 (Dropout)        (None, 257, 1024)            0         ['dense_45[0][0]']            \n",
      "                                                                                                  \n",
      " dense_46 (Dense)            (None, 257, 512)             524800    ['dropout_44[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_45 (Dropout)        (None, 257, 512)             0         ['dense_46[0][0]']            \n",
      "                                                                                                  \n",
      " add_45 (Add)                (None, 257, 512)             0         ['dropout_45[0][0]',          \n",
      "                                                                     'add_44[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_46 (La  (None, 257, 512)             1024      ['add_45[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_23 (M  (None, 257, 512)             1260185   ['layer_normalization_46[0][0]\n",
      " ultiHeadAttention)                                       6         ',                            \n",
      "                                                                     'layer_normalization_46[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_46 (Add)                (None, 257, 512)             0         ['multi_head_attention_23[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'add_45[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_47 (La  (None, 257, 512)             1024      ['add_46[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_47 (Dense)            (None, 257, 1024)            525312    ['layer_normalization_47[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_46 (Dropout)        (None, 257, 1024)            0         ['dense_47[0][0]']            \n",
      "                                                                                                  \n",
      " dense_48 (Dense)            (None, 257, 512)             524800    ['dropout_46[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_47 (Dropout)        (None, 257, 512)             0         ['dense_48[0][0]']            \n",
      "                                                                                                  \n",
      " add_47 (Add)                (None, 257, 512)             0         ['dropout_47[0][0]',          \n",
      "                                                                     'add_46[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_48 (La  (None, 257, 512)             1024      ['add_47[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (  (None, 512)                  0         ['layer_normalization_48[0][0]\n",
      " SlicingOpLambda)                                                   ']                            \n",
      "                                                                                                  \n",
      " dense_49 (Dense)            (None, 4)                    2052      ['tf.__operators__.getitem[0][\n",
      "                                                                    0]']                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 329273348 (1.23 GB)\n",
      "Trainable params: 329273348 (1.23 GB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Train: 2778 - Valid: 925 - Test: 925\n",
      "Train: 2778 - Valid: 925 - Test: 925\n",
      "Evaluating the test set...\n",
      "58/58 [==============================] - 378s 6s/step\n",
      "58/58 [==============================] - 353s 6s/step\n",
      "58/58 [==============================] - 339s 6s/step\n",
      "58/58 [==============================] - 313s 5s/step\n",
      "58/58 [==============================] - 316s 5s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Yellow_rust       0.95      0.84      0.89       237\n",
      "  Brown_rust       0.85      0.94      0.89       235\n",
      "     Healthy       0.95      0.95      0.95       241\n",
      "Blast_Leaves       0.99      1.00      1.00       212\n",
      "\n",
      "    accuracy                           0.93       925\n",
      "   macro avg       0.93      0.93      0.93       925\n",
      "weighted avg       0.93      0.93      0.93       925\n",
      "\n",
      "AUC-ROC (Yellow_rust): 0.9925\n",
      "AUC-ROC (Brown_rust): 0.9879\n",
      "AUC-ROC (Healthy): 0.9974\n",
      "AUC-ROC (Blast_Leaves): 1.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#test only\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "\n",
    "class ClassToken(Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        w_init = tf.random_normal_initializer()\n",
    "        self.w = tf.Variable(\n",
    "            initial_value = w_init(shape=(1, 1, input_shape[-1]), dtype=tf.float32),\n",
    "            trainable = True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        hidden_dim = self.w.shape[-1]\n",
    "\n",
    "        cls = tf.broadcast_to(self.w, [batch_size, 1, hidden_dim])\n",
    "        cls = tf.cast(cls, dtype=inputs.dtype)\n",
    "        return cls\n",
    "\n",
    "def mlp(x, cf):\n",
    "    x = Dense(cf[\"mlp_dim\"], activation=\"gelu\")(x)\n",
    "    x = Dropout(cf[\"dropout_rate\"])(x)\n",
    "    x = Dense(cf[\"hidden_dim\"])(x)\n",
    "    x = Dropout(cf[\"dropout_rate\"])(x)\n",
    "    return x\n",
    "\n",
    "def transformer_encoder(x, cf):\n",
    "    skip_1 = x\n",
    "    x = LayerNormalization()(x)\n",
    "    x = MultiHeadAttention(\n",
    "        num_heads=cf[\"num_heads\"], key_dim=cf[\"hidden_dim\"]\n",
    "    )(x, x)\n",
    "    x = Add()([x, skip_1])\n",
    "\n",
    "    skip_2 = x\n",
    "    x = LayerNormalization()(x)\n",
    "    x = mlp(x, cf)\n",
    "    x = Add()([x, skip_2])\n",
    "\n",
    "    return x\n",
    "\n",
    "def ViT(cf):\n",
    "    \"\"\" Inputs \"\"\"\n",
    "    input_shape = (cf[\"num_patches\"], cf[\"patch_size\"]*cf[\"patch_size\"]*cf[\"num_channels\"])\n",
    "    inputs = Input(input_shape)     ## (None, 256, 3072)\n",
    "\n",
    "    \"\"\" Patch + Position Embeddings \"\"\"\n",
    "    patch_embed = Dense(cf[\"hidden_dim\"])(inputs)   ## (None, 256, 768)\n",
    "\n",
    "    positions = tf.range(start=0, limit=cf[\"num_patches\"], delta=1)\n",
    "    pos_embed = Embedding(input_dim=cf[\"num_patches\"], output_dim=cf[\"hidden_dim\"])(positions) ## (256, 768)\n",
    "    embed = patch_embed + pos_embed ## (None, 256, 768)\n",
    "\n",
    "    \"\"\" Adding Class Token \"\"\"\n",
    "    token = ClassToken()(embed)\n",
    "    x = Concatenate(axis=1)([token, embed]) ## (None, 257, 768)\n",
    "\n",
    "    for _ in range(cf[\"num_layers\"]):\n",
    "        x = transformer_encoder(x, cf)\n",
    "\n",
    "    \"\"\" Classification Head \"\"\"\n",
    "    x = LayerNormalization()(x)     ## (None, 257, 768)\n",
    "    x = x[:, 0, :]\n",
    "    x = Dense(cf[\"num_classes\"], activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs, x)\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config = {}\n",
    "    config[\"num_layers\"] = 24\n",
    "#     config[\"hidden_dim\"] = 768\n",
    "#     config[\"mlp_dim\"] =3072\n",
    "    config[\"num_heads\"] = 12\n",
    "    config[\"dropout_rate\"] = 0.1\n",
    "    config[\"num_patches\"] = 256\n",
    "    config[\"patch_size\"] = 32\n",
    "    config[\"num_channels\"] = 3\n",
    "    config[\"num_classes\"] = 4\n",
    "\n",
    "    config[\"hidden_dim\"] = 512\n",
    "    config[\"mlp_dim\"] = 1024  \n",
    "\n",
    "    model = ViT(config)\n",
    "    model.summary()\n",
    "\n",
    "\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive/')\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from keras.metrics import AUC\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
    "from patchify import patchify\n",
    "# import tensorflow_hub as hub\n",
    "# Assuming you have already imported or defined the ViT model\n",
    "# ...\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "#from project import ViT\n",
    "hp = {\n",
    "    \"image_size\": 512,\n",
    "    \"num_channels\": 3,\n",
    "    \"patch_size\": 64,\n",
    "    \"num_classes\": 4,\n",
    "    \"class_names\": [\"Yellow_rust\",\"Brown_rust\", \"Healthy\",\"Blast_Leaves\"],\n",
    "    \"num_layers\": 24,\n",
    "    \"hidden_dim\": 512,\n",
    "    \"mlp_dim\": 1024,\n",
    "    \"num_heads\": 4,\n",
    "    \"dropout_rate\": 0.1,\n",
    "    \"batch_size\": 16,\n",
    "    \"lr\": 1e-4,\n",
    "    \"num_epochs\": 10\n",
    "}\n",
    "hp[\"num_patches\"] = (hp[\"image_size\"] ** 2) // (hp[\"patch_size\"] ** 2)\n",
    "hp[\"flat_patches_shape\"] = (hp[\"num_patches\"], hp[\"patch_size\"] * hp[\"patch_size\"] * hp[\"num_channels\"])\n",
    "\n",
    "\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "\n",
    "def load_data(path, split=0.20):\n",
    "    images = glob(os.path.join(path, \"*\", \"*.jpg\"))\n",
    "\n",
    "    # Separate images by class\n",
    "    images_class_BKL = [image for image in images if \"Yellow_rust\" in image]\n",
    "    images_class_NV = [image for image in images if \"Brown_rust\" in image]\n",
    "    images_class_MEL2 = [image for image in images if \"Healthy\" in image]\n",
    "    images_class_BlastLeaves = [image for image in images if \"Blast_Leaves\" in image]\n",
    "\n",
    "    # Oversample to 33,000 to match the largest class (BKL)\n",
    "    target_size = len(images_class_BKL)\n",
    "    #print(images_class_BKL)\n",
    "    images_class_NV = np.random.choice(images_class_NV, size=target_size, replace=True).tolist()\n",
    "    images_class_MEL2 = np.random.choice(images_class_MEL2, size=target_size, replace=True).tolist()\n",
    "    images_class_BlastLeaves = np.random.choice(images_class_BlastLeaves, size=target_size, replace=True).tolist()\n",
    "    # Concatenate lists again and shuffle\n",
    "    images = shuffle(images_class_BKL + images_class_NV + images_class_MEL2+ images_class_BlastLeaves)\n",
    "\n",
    "    split_size = int(len(images) * split)\n",
    "    train_x, valid_x = train_test_split(images, test_size=split_size, random_state=42)\n",
    "    train_x, test_x = train_test_split(train_x, test_size=split_size, random_state=42)\n",
    "    print(f\"Train: {len(train_x)} - Valid: {len(valid_x)} - Test: {len(test_x)}\")\n",
    "\n",
    "    return train_x, valid_x, test_x\n",
    "\n",
    "\n",
    "def process_image_label(path):\n",
    "    path = path.decode()\n",
    "    image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (hp[\"image_size\"], hp[\"image_size\"]))\n",
    "    image = image / 255.0\n",
    "\n",
    "    patch_shape = (hp[\"patch_size\"], hp[\"patch_size\"], hp[\"num_channels\"])\n",
    "    patches = patchify(image, patch_shape, hp[\"patch_size\"])\n",
    "    patches = np.reshape(patches, hp[\"flat_patches_shape\"])\n",
    "    patches = patches.astype(np.float32)\n",
    "\n",
    "    class_name = path.split(\"/\")[-2]\n",
    "    class_idx = hp[\"class_names\"].index(class_name)\n",
    "    class_idx = np.array(class_idx, dtype=np.int32)\n",
    "    return patches, class_idx\n",
    "\n",
    "\n",
    "def parse(path):\n",
    "    patches, labels = tf.numpy_function(process_image_label, [path], [tf.float32, tf.int32])\n",
    "    labels = tf.one_hot(labels, hp[\"num_classes\"])\n",
    "\n",
    "    patches.set_shape(hp[\"flat_patches_shape\"])\n",
    "    labels.set_shape(hp[\"num_classes\"])\n",
    "\n",
    "    return patches, labels\n",
    "\n",
    "\n",
    "def tf_dataset(images, batch=32):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((images))\n",
    "    ds = ds.map(parse).batch(batch).prefetch(8)\n",
    "    return ds\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    model = ViT(hp)\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        optimizer=tf.keras.optimizers.Adam(hp[\"lr\"], clipvalue=1.0),\n",
    "        metrics=[\"acc\", AUC(name='auc', multi_label=True)]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_dir(\"files\")\n",
    "    dataset_path = '/home/ali/Music/PYTHON/WholeDataset'\n",
    "    model_path = os.path.join(\"files\", \"model3.h5\")\n",
    "    csv_path = os.path.join(\"files\", \"log2.csv\")\n",
    "    train_x, valid_x, test_x = load_data(dataset_path)\n",
    "    images = train_x + valid_x\n",
    "    print(f\"Train: {len(train_x)} - Valid: {len(valid_x)} - Test: {len(test_x)}\")\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    fold_no = 1\n",
    "\n",
    "#     for train, val in kfold.split(images):\n",
    "#         print(f'Training for fold {fold_no} ...')\n",
    "#         train_ds = tf_dataset(np.array(images)[train], batch=hp[\"batch_size\"])\n",
    "#         valid_ds = tf_dataset(np.array(images)[val], batch=hp[\"batch_size\"])\n",
    "#         model = get_model()\n",
    "#         callbacks = [\n",
    "#             ModelCheckpoint(f\"files/modelN_fold{fold_no}.h5\", monitor='val_loss', verbose=1, save_best_only=True),\n",
    "#             ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, min_lr=1e-10, verbose=1),\n",
    "#             CSVLogger(f\"files/log2_fold{fold_no}.csv\"),\n",
    "#             EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=False),\n",
    "#         ]\n",
    "#         print(2)\n",
    "#         model.fit(train_ds, epochs=hp[\"num_epochs\"], validation_data=valid_ds, callbacks=callbacks)\n",
    "#         fold_no += 1\n",
    "#         print(3)\n",
    "\n",
    "    # Evaluating on the test set\n",
    "    print(\"Evaluating the test set...\")\n",
    "    test_ds = tf_dataset(test_x, batch=hp[\"batch_size\"])\n",
    "    all_preds = []\n",
    "    custom_objects = {\"ClassToken\": ClassToken}\n",
    "    for fold_no in range(1, 6):\n",
    "        with tf.keras.utils.custom_object_scope(custom_objects):\n",
    "            fold_model = tf.keras.models.load_model(f\"files/modelN_fold{fold_no}.h5\")\n",
    "        y_pred_probs = fold_model.predict(test_ds)\n",
    "        all_preds.append(y_pred_probs)\n",
    "\n",
    "    avg_preds = np.mean(all_preds, axis=0)\n",
    "    final_preds = np.argmax(avg_preds, axis=1)\n",
    "    y_true = [hp[\"class_names\"].index(img.split(\"/\")[-2]) for img in test_x]\n",
    "    print(classification_report(y_true, final_preds, target_names=hp[\"class_names\"]))\n",
    "    roc_aucs = []\n",
    "\n",
    "    for i, class_name in enumerate(hp[\"class_names\"]):\n",
    "        auc_val = roc_auc_score((np.array(y_true) == i).astype(int), avg_preds[:, i])\n",
    "        roc_aucs.append(auc_val)\n",
    "        print(f\"AUC-ROC ({class_name}): {auc_val:.4f}\")\n",
    "\n",
    "    for i, class_name in enumerate(hp[\"class_names\"]):\n",
    "        fpr, tpr, _ = roc_curve((np.array(y_true) == i).astype(int), avg_preds[:, i])\n",
    "        plt.plot(fpr, tpr, label=f\"{class_name} (AUC = {roc_aucs[i]:.2f})\")\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], color='grey', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
