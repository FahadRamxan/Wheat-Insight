{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)        [(None, 256, 3072)]          0         []                            \n",
      "                                                                                                  \n",
      " dense_300 (Dense)           (None, 256, 256)             786688    ['input_7[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TF  (None, 256, 256)             0         ['dense_300[0][0]']           \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " class_token_11 (ClassToken  (None, 1, 256)               256       ['tf.__operators__.add_6[0][0]\n",
      " )                                                                  ']                            \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate  (None, 257, 256)             0         ['class_token_11[0][0]',      \n",
      " )                                                                   'tf.__operators__.add_6[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " layer_normalization_294 (L  (None, 257, 256)             512       ['concatenate_6[0][0]']       \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_144 (  (None, 257, 256)             3155200   ['layer_normalization_294[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_294[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_288 (Add)               (None, 257, 256)             0         ['multi_head_attention_144[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'concatenate_6[0][0]']       \n",
      "                                                                                                  \n",
      " layer_normalization_295 (L  (None, 257, 256)             512       ['add_288[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_301 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_295[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_408 (Dropout)       (None, 257, 1024)            0         ['dense_301[0][0]']           \n",
      "                                                                                                  \n",
      " dense_302 (Dense)           (None, 257, 256)             262400    ['dropout_408[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_409 (Dropout)       (None, 257, 256)             0         ['dense_302[0][0]']           \n",
      "                                                                                                  \n",
      " add_289 (Add)               (None, 257, 256)             0         ['dropout_409[0][0]',         \n",
      "                                                                     'add_288[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_296 (L  (None, 257, 256)             512       ['add_289[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_145 (  (None, 257, 256)             3155200   ['layer_normalization_296[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_296[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_290 (Add)               (None, 257, 256)             0         ['multi_head_attention_145[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_289[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_297 (L  (None, 257, 256)             512       ['add_290[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_303 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_297[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_410 (Dropout)       (None, 257, 1024)            0         ['dense_303[0][0]']           \n",
      "                                                                                                  \n",
      " dense_304 (Dense)           (None, 257, 256)             262400    ['dropout_410[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_411 (Dropout)       (None, 257, 256)             0         ['dense_304[0][0]']           \n",
      "                                                                                                  \n",
      " add_291 (Add)               (None, 257, 256)             0         ['dropout_411[0][0]',         \n",
      "                                                                     'add_290[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_298 (L  (None, 257, 256)             512       ['add_291[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_146 (  (None, 257, 256)             3155200   ['layer_normalization_298[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_298[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_292 (Add)               (None, 257, 256)             0         ['multi_head_attention_146[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_291[0][0]']             \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " layer_normalization_299 (L  (None, 257, 256)             512       ['add_292[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_305 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_299[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_412 (Dropout)       (None, 257, 1024)            0         ['dense_305[0][0]']           \n",
      "                                                                                                  \n",
      " dense_306 (Dense)           (None, 257, 256)             262400    ['dropout_412[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_413 (Dropout)       (None, 257, 256)             0         ['dense_306[0][0]']           \n",
      "                                                                                                  \n",
      " add_293 (Add)               (None, 257, 256)             0         ['dropout_413[0][0]',         \n",
      "                                                                     'add_292[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_300 (L  (None, 257, 256)             512       ['add_293[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_147 (  (None, 257, 256)             3155200   ['layer_normalization_300[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_300[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_294 (Add)               (None, 257, 256)             0         ['multi_head_attention_147[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_293[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_301 (L  (None, 257, 256)             512       ['add_294[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_307 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_301[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_414 (Dropout)       (None, 257, 1024)            0         ['dense_307[0][0]']           \n",
      "                                                                                                  \n",
      " dense_308 (Dense)           (None, 257, 256)             262400    ['dropout_414[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_415 (Dropout)       (None, 257, 256)             0         ['dense_308[0][0]']           \n",
      "                                                                                                  \n",
      " add_295 (Add)               (None, 257, 256)             0         ['dropout_415[0][0]',         \n",
      "                                                                     'add_294[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_302 (L  (None, 257, 256)             512       ['add_295[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_148 (  (None, 257, 256)             3155200   ['layer_normalization_302[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_302[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_296 (Add)               (None, 257, 256)             0         ['multi_head_attention_148[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_295[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_303 (L  (None, 257, 256)             512       ['add_296[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_309 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_303[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_416 (Dropout)       (None, 257, 1024)            0         ['dense_309[0][0]']           \n",
      "                                                                                                  \n",
      " dense_310 (Dense)           (None, 257, 256)             262400    ['dropout_416[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_417 (Dropout)       (None, 257, 256)             0         ['dense_310[0][0]']           \n",
      "                                                                                                  \n",
      " add_297 (Add)               (None, 257, 256)             0         ['dropout_417[0][0]',         \n",
      "                                                                     'add_296[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_304 (L  (None, 257, 256)             512       ['add_297[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_149 (  (None, 257, 256)             3155200   ['layer_normalization_304[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_304[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_298 (Add)               (None, 257, 256)             0         ['multi_head_attention_149[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_297[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_305 (L  (None, 257, 256)             512       ['add_298[0][0]']             \n",
      " ayerNormalization)                                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " dense_311 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_305[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_418 (Dropout)       (None, 257, 1024)            0         ['dense_311[0][0]']           \n",
      "                                                                                                  \n",
      " dense_312 (Dense)           (None, 257, 256)             262400    ['dropout_418[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_419 (Dropout)       (None, 257, 256)             0         ['dense_312[0][0]']           \n",
      "                                                                                                  \n",
      " add_299 (Add)               (None, 257, 256)             0         ['dropout_419[0][0]',         \n",
      "                                                                     'add_298[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_306 (L  (None, 257, 256)             512       ['add_299[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_150 (  (None, 257, 256)             3155200   ['layer_normalization_306[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_306[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_300 (Add)               (None, 257, 256)             0         ['multi_head_attention_150[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_299[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_307 (L  (None, 257, 256)             512       ['add_300[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_313 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_307[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_420 (Dropout)       (None, 257, 1024)            0         ['dense_313[0][0]']           \n",
      "                                                                                                  \n",
      " dense_314 (Dense)           (None, 257, 256)             262400    ['dropout_420[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_421 (Dropout)       (None, 257, 256)             0         ['dense_314[0][0]']           \n",
      "                                                                                                  \n",
      " add_301 (Add)               (None, 257, 256)             0         ['dropout_421[0][0]',         \n",
      "                                                                     'add_300[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_308 (L  (None, 257, 256)             512       ['add_301[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_151 (  (None, 257, 256)             3155200   ['layer_normalization_308[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_308[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_302 (Add)               (None, 257, 256)             0         ['multi_head_attention_151[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_301[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_309 (L  (None, 257, 256)             512       ['add_302[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_315 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_309[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_422 (Dropout)       (None, 257, 1024)            0         ['dense_315[0][0]']           \n",
      "                                                                                                  \n",
      " dense_316 (Dense)           (None, 257, 256)             262400    ['dropout_422[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_423 (Dropout)       (None, 257, 256)             0         ['dense_316[0][0]']           \n",
      "                                                                                                  \n",
      " add_303 (Add)               (None, 257, 256)             0         ['dropout_423[0][0]',         \n",
      "                                                                     'add_302[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_310 (L  (None, 257, 256)             512       ['add_303[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_152 (  (None, 257, 256)             3155200   ['layer_normalization_310[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_310[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_304 (Add)               (None, 257, 256)             0         ['multi_head_attention_152[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_303[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_311 (L  (None, 257, 256)             512       ['add_304[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_317 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_311[0][0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_424 (Dropout)       (None, 257, 1024)            0         ['dense_317[0][0]']           \n",
      "                                                                                                  \n",
      " dense_318 (Dense)           (None, 257, 256)             262400    ['dropout_424[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_425 (Dropout)       (None, 257, 256)             0         ['dense_318[0][0]']           \n",
      "                                                                                                  \n",
      " add_305 (Add)               (None, 257, 256)             0         ['dropout_425[0][0]',         \n",
      "                                                                     'add_304[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_312 (L  (None, 257, 256)             512       ['add_305[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_153 (  (None, 257, 256)             3155200   ['layer_normalization_312[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_312[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_306 (Add)               (None, 257, 256)             0         ['multi_head_attention_153[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_305[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_313 (L  (None, 257, 256)             512       ['add_306[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_319 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_313[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_426 (Dropout)       (None, 257, 1024)            0         ['dense_319[0][0]']           \n",
      "                                                                                                  \n",
      " dense_320 (Dense)           (None, 257, 256)             262400    ['dropout_426[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_427 (Dropout)       (None, 257, 256)             0         ['dense_320[0][0]']           \n",
      "                                                                                                  \n",
      " add_307 (Add)               (None, 257, 256)             0         ['dropout_427[0][0]',         \n",
      "                                                                     'add_306[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_314 (L  (None, 257, 256)             512       ['add_307[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_154 (  (None, 257, 256)             3155200   ['layer_normalization_314[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_314[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_308 (Add)               (None, 257, 256)             0         ['multi_head_attention_154[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_307[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_315 (L  (None, 257, 256)             512       ['add_308[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_321 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_315[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_428 (Dropout)       (None, 257, 1024)            0         ['dense_321[0][0]']           \n",
      "                                                                                                  \n",
      " dense_322 (Dense)           (None, 257, 256)             262400    ['dropout_428[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_429 (Dropout)       (None, 257, 256)             0         ['dense_322[0][0]']           \n",
      "                                                                                                  \n",
      " add_309 (Add)               (None, 257, 256)             0         ['dropout_429[0][0]',         \n",
      "                                                                     'add_308[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_316 (L  (None, 257, 256)             512       ['add_309[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_155 (  (None, 257, 256)             3155200   ['layer_normalization_316[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_316[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_310 (Add)               (None, 257, 256)             0         ['multi_head_attention_155[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_309[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_317 (L  (None, 257, 256)             512       ['add_310[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_323 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_317[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dropout_430 (Dropout)       (None, 257, 1024)            0         ['dense_323[0][0]']           \n",
      "                                                                                                  \n",
      " dense_324 (Dense)           (None, 257, 256)             262400    ['dropout_430[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_431 (Dropout)       (None, 257, 256)             0         ['dense_324[0][0]']           \n",
      "                                                                                                  \n",
      " add_311 (Add)               (None, 257, 256)             0         ['dropout_431[0][0]',         \n",
      "                                                                     'add_310[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_318 (L  (None, 257, 256)             512       ['add_311[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_156 (  (None, 257, 256)             3155200   ['layer_normalization_318[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_318[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_312 (Add)               (None, 257, 256)             0         ['multi_head_attention_156[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_311[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_319 (L  (None, 257, 256)             512       ['add_312[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_325 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_319[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_432 (Dropout)       (None, 257, 1024)            0         ['dense_325[0][0]']           \n",
      "                                                                                                  \n",
      " dense_326 (Dense)           (None, 257, 256)             262400    ['dropout_432[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_433 (Dropout)       (None, 257, 256)             0         ['dense_326[0][0]']           \n",
      "                                                                                                  \n",
      " add_313 (Add)               (None, 257, 256)             0         ['dropout_433[0][0]',         \n",
      "                                                                     'add_312[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_320 (L  (None, 257, 256)             512       ['add_313[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_157 (  (None, 257, 256)             3155200   ['layer_normalization_320[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_320[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_314 (Add)               (None, 257, 256)             0         ['multi_head_attention_157[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_313[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_321 (L  (None, 257, 256)             512       ['add_314[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_327 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_321[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_434 (Dropout)       (None, 257, 1024)            0         ['dense_327[0][0]']           \n",
      "                                                                                                  \n",
      " dense_328 (Dense)           (None, 257, 256)             262400    ['dropout_434[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_435 (Dropout)       (None, 257, 256)             0         ['dense_328[0][0]']           \n",
      "                                                                                                  \n",
      " add_315 (Add)               (None, 257, 256)             0         ['dropout_435[0][0]',         \n",
      "                                                                     'add_314[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_322 (L  (None, 257, 256)             512       ['add_315[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_158 (  (None, 257, 256)             3155200   ['layer_normalization_322[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_322[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_316 (Add)               (None, 257, 256)             0         ['multi_head_attention_158[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_315[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_323 (L  (None, 257, 256)             512       ['add_316[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_329 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_323[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_436 (Dropout)       (None, 257, 1024)            0         ['dense_329[0][0]']           \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_330 (Dense)           (None, 257, 256)             262400    ['dropout_436[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_437 (Dropout)       (None, 257, 256)             0         ['dense_330[0][0]']           \n",
      "                                                                                                  \n",
      " add_317 (Add)               (None, 257, 256)             0         ['dropout_437[0][0]',         \n",
      "                                                                     'add_316[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_324 (L  (None, 257, 256)             512       ['add_317[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_159 (  (None, 257, 256)             3155200   ['layer_normalization_324[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_324[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_318 (Add)               (None, 257, 256)             0         ['multi_head_attention_159[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_317[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_325 (L  (None, 257, 256)             512       ['add_318[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_331 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_325[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_438 (Dropout)       (None, 257, 1024)            0         ['dense_331[0][0]']           \n",
      "                                                                                                  \n",
      " dense_332 (Dense)           (None, 257, 256)             262400    ['dropout_438[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_439 (Dropout)       (None, 257, 256)             0         ['dense_332[0][0]']           \n",
      "                                                                                                  \n",
      " add_319 (Add)               (None, 257, 256)             0         ['dropout_439[0][0]',         \n",
      "                                                                     'add_318[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_326 (L  (None, 257, 256)             512       ['add_319[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_160 (  (None, 257, 256)             3155200   ['layer_normalization_326[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_326[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_320 (Add)               (None, 257, 256)             0         ['multi_head_attention_160[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_319[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_327 (L  (None, 257, 256)             512       ['add_320[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_333 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_327[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_440 (Dropout)       (None, 257, 1024)            0         ['dense_333[0][0]']           \n",
      "                                                                                                  \n",
      " dense_334 (Dense)           (None, 257, 256)             262400    ['dropout_440[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_441 (Dropout)       (None, 257, 256)             0         ['dense_334[0][0]']           \n",
      "                                                                                                  \n",
      " add_321 (Add)               (None, 257, 256)             0         ['dropout_441[0][0]',         \n",
      "                                                                     'add_320[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_328 (L  (None, 257, 256)             512       ['add_321[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_161 (  (None, 257, 256)             3155200   ['layer_normalization_328[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_328[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_322 (Add)               (None, 257, 256)             0         ['multi_head_attention_161[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_321[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_329 (L  (None, 257, 256)             512       ['add_322[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_335 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_329[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_442 (Dropout)       (None, 257, 1024)            0         ['dense_335[0][0]']           \n",
      "                                                                                                  \n",
      " dense_336 (Dense)           (None, 257, 256)             262400    ['dropout_442[0][0]']         \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dropout_443 (Dropout)       (None, 257, 256)             0         ['dense_336[0][0]']           \n",
      "                                                                                                  \n",
      " add_323 (Add)               (None, 257, 256)             0         ['dropout_443[0][0]',         \n",
      "                                                                     'add_322[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_330 (L  (None, 257, 256)             512       ['add_323[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_162 (  (None, 257, 256)             3155200   ['layer_normalization_330[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_330[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_324 (Add)               (None, 257, 256)             0         ['multi_head_attention_162[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_323[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_331 (L  (None, 257, 256)             512       ['add_324[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_337 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_331[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_444 (Dropout)       (None, 257, 1024)            0         ['dense_337[0][0]']           \n",
      "                                                                                                  \n",
      " dense_338 (Dense)           (None, 257, 256)             262400    ['dropout_444[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_445 (Dropout)       (None, 257, 256)             0         ['dense_338[0][0]']           \n",
      "                                                                                                  \n",
      " add_325 (Add)               (None, 257, 256)             0         ['dropout_445[0][0]',         \n",
      "                                                                     'add_324[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_332 (L  (None, 257, 256)             512       ['add_325[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_163 (  (None, 257, 256)             3155200   ['layer_normalization_332[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_332[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_326 (Add)               (None, 257, 256)             0         ['multi_head_attention_163[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_325[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_333 (L  (None, 257, 256)             512       ['add_326[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_339 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_333[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_446 (Dropout)       (None, 257, 1024)            0         ['dense_339[0][0]']           \n",
      "                                                                                                  \n",
      " dense_340 (Dense)           (None, 257, 256)             262400    ['dropout_446[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_447 (Dropout)       (None, 257, 256)             0         ['dense_340[0][0]']           \n",
      "                                                                                                  \n",
      " add_327 (Add)               (None, 257, 256)             0         ['dropout_447[0][0]',         \n",
      "                                                                     'add_326[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_334 (L  (None, 257, 256)             512       ['add_327[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_164 (  (None, 257, 256)             3155200   ['layer_normalization_334[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_334[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_328 (Add)               (None, 257, 256)             0         ['multi_head_attention_164[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_327[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_335 (L  (None, 257, 256)             512       ['add_328[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_341 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_335[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_448 (Dropout)       (None, 257, 1024)            0         ['dense_341[0][0]']           \n",
      "                                                                                                  \n",
      " dense_342 (Dense)           (None, 257, 256)             262400    ['dropout_448[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_449 (Dropout)       (None, 257, 256)             0         ['dense_342[0][0]']           \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " add_329 (Add)               (None, 257, 256)             0         ['dropout_449[0][0]',         \n",
      "                                                                     'add_328[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_336 (L  (None, 257, 256)             512       ['add_329[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_165 (  (None, 257, 256)             3155200   ['layer_normalization_336[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_336[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_330 (Add)               (None, 257, 256)             0         ['multi_head_attention_165[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_329[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_337 (L  (None, 257, 256)             512       ['add_330[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_343 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_337[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_450 (Dropout)       (None, 257, 1024)            0         ['dense_343[0][0]']           \n",
      "                                                                                                  \n",
      " dense_344 (Dense)           (None, 257, 256)             262400    ['dropout_450[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_451 (Dropout)       (None, 257, 256)             0         ['dense_344[0][0]']           \n",
      "                                                                                                  \n",
      " add_331 (Add)               (None, 257, 256)             0         ['dropout_451[0][0]',         \n",
      "                                                                     'add_330[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_338 (L  (None, 257, 256)             512       ['add_331[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_166 (  (None, 257, 256)             3155200   ['layer_normalization_338[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_338[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_332 (Add)               (None, 257, 256)             0         ['multi_head_attention_166[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_331[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_339 (L  (None, 257, 256)             512       ['add_332[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_345 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_339[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_452 (Dropout)       (None, 257, 1024)            0         ['dense_345[0][0]']           \n",
      "                                                                                                  \n",
      " dense_346 (Dense)           (None, 257, 256)             262400    ['dropout_452[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_453 (Dropout)       (None, 257, 256)             0         ['dense_346[0][0]']           \n",
      "                                                                                                  \n",
      " add_333 (Add)               (None, 257, 256)             0         ['dropout_453[0][0]',         \n",
      "                                                                     'add_332[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_340 (L  (None, 257, 256)             512       ['add_333[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_167 (  (None, 257, 256)             3155200   ['layer_normalization_340[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_340[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_334 (Add)               (None, 257, 256)             0         ['multi_head_attention_167[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_333[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_341 (L  (None, 257, 256)             512       ['add_334[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_347 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_341[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_454 (Dropout)       (None, 257, 1024)            0         ['dense_347[0][0]']           \n",
      "                                                                                                  \n",
      " dense_348 (Dense)           (None, 257, 256)             262400    ['dropout_454[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_455 (Dropout)       (None, 257, 256)             0         ['dense_348[0][0]']           \n",
      "                                                                                                  \n",
      " add_335 (Add)               (None, 257, 256)             0         ['dropout_455[0][0]',         \n",
      "                                                                     'add_334[0][0]']             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " layer_normalization_342 (L  (None, 257, 256)             512       ['add_335[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_6  (None, 256)                  0         ['layer_normalization_342[0][0\n",
      "  (SlicingOpLambda)                                                 ]']                           \n",
      "                                                                                                  \n",
      " dense_349 (Dense)           (None, 6)                    1542      ['tf.__operators__.getitem_6[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 89152006 (340.09 MB)\n",
      "Trainable params: 89152006 (340.09 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Train: 4166 - Valid: 1388 - Test: 1388\n",
      "Train: 4166 - Valid: 1388 - Test: 1388\n",
      "Training for fold 1 ...\n",
      "2\n",
      "278/278 [==============================] - ETA: 0s - loss: 1.3846 - acc: 0.4400 - auc: 0.7722\n",
      "Epoch 1: val_loss improved from inf to 0.98951, saving model to files/modelN_fold1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278/278 [==============================] - 1927s 7s/step - loss: 1.3846 - acc: 0.4400 - auc: 0.7722 - val_loss: 0.9895 - val_acc: 0.6301 - val_auc: 0.9039 - lr: 1.0000e-04\n",
      "3\n",
      "Training for fold 2 ...\n",
      "2\n",
      "278/278 [==============================] - ETA: 0s - loss: 1.5140 - acc: 0.3955 - auc: 0.7295\n",
      "Epoch 1: val_loss improved from inf to 1.18747, saving model to files/modelN_fold2.h5\n",
      "278/278 [==============================] - 1945s 7s/step - loss: 1.5140 - acc: 0.3955 - auc: 0.7295 - val_loss: 1.1875 - val_acc: 0.5752 - val_auc: 0.8726 - lr: 1.0000e-04\n",
      "3\n",
      "Training for fold 3 ...\n",
      "2\n",
      "278/278 [==============================] - ETA: 0s - loss: 1.5224 - acc: 0.3946 - auc: 0.7293\n",
      "Epoch 1: val_loss improved from inf to 1.22721, saving model to files/modelN_fold3.h5\n",
      "278/278 [==============================] - 2427s 9s/step - loss: 1.5224 - acc: 0.3946 - auc: 0.7293 - val_loss: 1.2272 - val_acc: 0.5113 - val_auc: 0.8604 - lr: 1.0000e-04\n",
      "3\n",
      "Training for fold 4 ...\n",
      "2\n",
      "278/278 [==============================] - ETA: 0s - loss: 1.3989 - acc: 0.4492 - auc: 0.7704\n",
      "Epoch 1: val_loss improved from inf to 1.24814, saving model to files/modelN_fold4.h5\n",
      "278/278 [==============================] - 1845s 6s/step - loss: 1.3989 - acc: 0.4492 - auc: 0.7704 - val_loss: 1.2481 - val_acc: 0.5059 - val_auc: 0.8784 - lr: 1.0000e-04\n",
      "3\n",
      "Training for fold 5 ...\n",
      "2\n",
      "278/278 [==============================] - ETA: 0s - loss: 1.4741 - acc: 0.4266 - auc: 0.7496\n",
      "Epoch 1: val_loss improved from inf to 1.13402, saving model to files/modelN_fold5.h5\n",
      "278/278 [==============================] - 1663s 6s/step - loss: 1.4741 - acc: 0.4266 - auc: 0.7496 - val_loss: 1.1340 - val_acc: 0.5964 - val_auc: 0.8963 - lr: 1.0000e-04\n",
      "3\n",
      "Evaluating the test set...\n",
      "87/87 [==============================] - 148s 2s/step\n",
      "87/87 [==============================] - 160s 2s/step\n",
      "87/87 [==============================] - 141s 2s/step\n",
      "87/87 [==============================] - 162s 2s/step\n",
      "87/87 [==============================] - 162s 2s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Yellow_rust       0.38      0.96      0.54       221\n",
      "  Brown_rust       0.67      0.34      0.45       252\n",
      "     Healthy       0.43      0.55      0.48       224\n",
      "Blast_Leaves       0.78      1.00      0.88       221\n",
      "   Stem_Rust       1.00      0.45      0.62       236\n",
      "    Tan_Spot       0.72      0.08      0.14       234\n",
      "\n",
      "    accuracy                           0.55      1388\n",
      "   macro avg       0.66      0.56      0.52      1388\n",
      "weighted avg       0.67      0.55      0.51      1388\n",
      "\n",
      "AUC-ROC (Yellow_rust): 0.9136\n",
      "AUC-ROC (Brown_rust): 0.8882\n",
      "AUC-ROC (Healthy): 0.8508\n",
      "AUC-ROC (Blast_Leaves): 0.9953\n",
      "AUC-ROC (Stem_Rust): 0.8543\n",
      "AUC-ROC (Tan_Spot): 0.8300\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Final Document\n",
    "#1 epoch sall dataset train and tests\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "\n",
    "class ClassToken(Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        w_init = tf.random_normal_initializer()\n",
    "        self.w = tf.Variable(\n",
    "            initial_value = w_init(shape=(1, 1, input_shape[-1]), dtype=tf.float32),\n",
    "            trainable = True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        hidden_dim = self.w.shape[-1]\n",
    "\n",
    "        cls = tf.broadcast_to(self.w, [batch_size, 1, hidden_dim])\n",
    "        cls = tf.cast(cls, dtype=inputs.dtype)\n",
    "        return cls\n",
    "\n",
    "def mlp(x, cf):\n",
    "    x = Dense(cf[\"mlp_dim\"], activation=\"gelu\")(x)\n",
    "    x = Dropout(cf[\"dropout_rate\"])(x)\n",
    "    x = Dense(cf[\"hidden_dim\"])(x)\n",
    "    x = Dropout(cf[\"dropout_rate\"])(x)\n",
    "    return x\n",
    "\n",
    "def transformer_encoder(x, cf):\n",
    "    skip_1 = x\n",
    "    x = LayerNormalization()(x)\n",
    "    x = MultiHeadAttention(\n",
    "        num_heads=cf[\"num_heads\"], key_dim=cf[\"hidden_dim\"]\n",
    "    )(x, x)\n",
    "    x = Add()([x, skip_1])\n",
    "\n",
    "    skip_2 = x\n",
    "    x = LayerNormalization()(x)\n",
    "    x = mlp(x, cf)\n",
    "    x = Add()([x, skip_2])\n",
    "\n",
    "    return x\n",
    "\n",
    "def ViT(cf):\n",
    "    \"\"\" Inputs \"\"\"\n",
    "    input_shape = (cf[\"num_patches\"], cf[\"patch_size\"]*cf[\"patch_size\"]*cf[\"num_channels\"])\n",
    "    inputs = Input(input_shape)     ## (None, 256, 3072)\n",
    "\n",
    "    \"\"\" Patch + Position Embeddings \"\"\"\n",
    "    patch_embed = Dense(cf[\"hidden_dim\"])(inputs)   ## (None, 256, 768)\n",
    "\n",
    "    positions = tf.range(start=0, limit=cf[\"num_patches\"], delta=1)\n",
    "    pos_embed = Embedding(input_dim=cf[\"num_patches\"], output_dim=cf[\"hidden_dim\"])(positions) ## (256, 768)\n",
    "    embed = patch_embed + pos_embed ## (None, 256, 768)\n",
    "\n",
    "    \"\"\" Adding Class Token \"\"\"\n",
    "    token = ClassToken()(embed)\n",
    "    x = Concatenate(axis=1)([token, embed]) ## (None, 257, 768)\n",
    "\n",
    "    for _ in range(cf[\"num_layers\"]):\n",
    "        x = transformer_encoder(x, cf)\n",
    "\n",
    "    \"\"\" Classification Head \"\"\"\n",
    "    x = LayerNormalization()(x)     ## (None, 257, 768)\n",
    "    x = x[:, 0, :]\n",
    "    x = Dense(cf[\"num_classes\"], activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs, x)\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config = {}\n",
    "    config[\"num_layers\"] = 24\n",
    "#     config[\"hidden_dim\"] = 768\n",
    "#     config[\"mlp_dim\"] =3072\n",
    "    config[\"num_heads\"] = 12\n",
    "    config[\"dropout_rate\"] = 0.1\n",
    "    config[\"num_patches\"] = 256\n",
    "    config[\"patch_size\"] = 32\n",
    "    config[\"num_channels\"] = 3\n",
    "    config[\"num_classes\"] = 6\n",
    "\n",
    "    config[\"hidden_dim\"] = 256\n",
    "    config[\"mlp_dim\"] = 1024  \n",
    "\n",
    "    model = ViT(config)\n",
    "    model.summary()\n",
    "\n",
    "\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive/')\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from keras.metrics import AUC\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
    "from patchify import patchify\n",
    "# import tensorflow_hub as hub\n",
    "# Assuming you have already imported or defined the ViT model\n",
    "# ...\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "#from project import ViT\n",
    "hp = {\n",
    "    \"image_size\": 512,\n",
    "    \"num_channels\": 3,\n",
    "    \"patch_size\": 64,\n",
    "    \"num_classes\": 6,\n",
    "    \"class_names\": [\"Yellow_rust\",\"Brown_rust\", \"Healthy\",\"Blast_Leaves\",\"Stem_Rust\",\"Tan_Spot\"],\n",
    "    \"num_layers\": 24,\n",
    "    \"hidden_dim\": 256,\n",
    "    \"mlp_dim\": 1024,\n",
    "    \"num_heads\": 4,\n",
    "    \"dropout_rate\": 0.1,\n",
    "    \"batch_size\": 16,\n",
    "    \"lr\": 1e-4,\n",
    "    \"num_epochs\": 1\n",
    "}\n",
    "hp[\"num_patches\"] = (hp[\"image_size\"] ** 2) // (hp[\"patch_size\"] ** 2)\n",
    "hp[\"flat_patches_shape\"] = (hp[\"num_patches\"], hp[\"patch_size\"] * hp[\"patch_size\"] * hp[\"num_channels\"])\n",
    "\n",
    "\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "\n",
    "def load_data(path, split=0.20):\n",
    "    images = glob(os.path.join(path, \"*\", \"*.jpg\"))\n",
    "\n",
    "    # Separate images by class\n",
    "    images_class_BKL = [image for image in images if \"Yellow_rust\" in image]\n",
    "    images_class_NV = [image for image in images if \"Brown_rust\" in image]\n",
    "    images_class_MEL2 = [image for image in images if \"Healthy\" in image]\n",
    "    images_class_BlastLeaves = [image for image in images if \"Blast_Leaves\" in image]\n",
    "    images_class_Stem_Rust = [image for image in images if \"Stem_Rust\" in image]\n",
    "    images_class_Tan_Spot = [image for image in images if \"Tan_Spot\" in image]\n",
    "\n",
    "    # Oversample to 33,000 to match the largest class (BKL)\n",
    "    target_size = len(images_class_BKL)\n",
    "    #print(images_class_BKL)\n",
    "    images_class_NV = np.random.choice(images_class_NV, size=target_size, replace=True).tolist()\n",
    "    images_class_MEL2 = np.random.choice(images_class_MEL2, size=target_size, replace=True).tolist()\n",
    "    images_class_BlastLeaves = np.random.choice(images_class_BlastLeaves, size=target_size, replace=True).tolist()\n",
    "    images_class_Stem_Rust = np.random.choice(images_class_Stem_Rust, size=target_size, replace=True).tolist()\n",
    "    images_class_Tan_Spot = np.random.choice(images_class_Tan_Spot, size=target_size, replace=True).tolist()\n",
    "    # Concatenate lists again and shuffle\n",
    "    images = shuffle(images_class_BKL + images_class_NV + images_class_MEL2+ images_class_BlastLeaves+images_class_Stem_Rust+images_class_Tan_Spot)\n",
    "\n",
    "    split_size = int(len(images) * split)\n",
    "    train_x, valid_x = train_test_split(images, test_size=split_size, random_state=42)\n",
    "    train_x, test_x = train_test_split(train_x, test_size=split_size, random_state=42)\n",
    "    print(f\"Train: {len(train_x)} - Valid: {len(valid_x)} - Test: {len(test_x)}\")\n",
    "\n",
    "    return train_x, valid_x, test_x\n",
    "\n",
    "\n",
    "def process_image_label(path):\n",
    "    path = path.decode()\n",
    "    image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (hp[\"image_size\"], hp[\"image_size\"]))\n",
    "    image = image / 255.0\n",
    "\n",
    "    patch_shape = (hp[\"patch_size\"], hp[\"patch_size\"], hp[\"num_channels\"])\n",
    "    patches = patchify(image, patch_shape, hp[\"patch_size\"])\n",
    "    patches = np.reshape(patches, hp[\"flat_patches_shape\"])\n",
    "    patches = patches.astype(np.float32)\n",
    "\n",
    "    class_name = path.split(\"/\")[-2]\n",
    "    class_idx = hp[\"class_names\"].index(class_name)\n",
    "    class_idx = np.array(class_idx, dtype=np.int32)\n",
    "    return patches, class_idx\n",
    "\n",
    "\n",
    "def parse(path):\n",
    "    patches, labels = tf.numpy_function(process_image_label, [path], [tf.float32, tf.int32])\n",
    "    labels = tf.one_hot(labels, hp[\"num_classes\"])\n",
    "\n",
    "    patches.set_shape(hp[\"flat_patches_shape\"])\n",
    "    labels.set_shape(hp[\"num_classes\"])\n",
    "\n",
    "    return patches, labels\n",
    "\n",
    "\n",
    "def tf_dataset(images, batch=32):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((images))\n",
    "    ds = ds.map(parse).batch(batch).prefetch(8)\n",
    "    return ds\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    model = ViT(hp)\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        optimizer=tf.keras.optimizers.Adam(hp[\"lr\"], clipvalue=1.0),\n",
    "        metrics=[\"acc\", AUC(name='auc', multi_label=True)]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_dir(\"files\")\n",
    "    dataset_path = '/home/ali/Music/PYTHON/WholeDatasetReal'\n",
    "    model_path = os.path.join(\"files\", \"model3.h5\")\n",
    "    csv_path = os.path.join(\"files\", \"log2.csv\")\n",
    "    train_x, valid_x, test_x = load_data(dataset_path)\n",
    "    images = train_x + valid_x\n",
    "    print(f\"Train: {len(train_x)} - Valid: {len(valid_x)} - Test: {len(test_x)}\")\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    fold_no = 1\n",
    "\n",
    "    for train, val in kfold.split(images):\n",
    "        print(f'Training for fold {fold_no} ...')\n",
    "        train_ds = tf_dataset(np.array(images)[train], batch=hp[\"batch_size\"])\n",
    "        valid_ds = tf_dataset(np.array(images)[val], batch=hp[\"batch_size\"])\n",
    "        model = get_model()\n",
    "        callbacks = [\n",
    "            ModelCheckpoint(f\"files/modelN_fold{fold_no}.h5\", monitor='val_loss', verbose=1, save_best_only=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, min_lr=1e-10, verbose=1),\n",
    "            CSVLogger(f\"files/log2_fold{fold_no}.csv\"),\n",
    "            EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=False),\n",
    "        ]\n",
    "        print(2)\n",
    "        model.fit(train_ds, epochs=hp[\"num_epochs\"], validation_data=valid_ds, callbacks=callbacks)\n",
    "        fold_no += 1\n",
    "        print(3)\n",
    "\n",
    "    # Evaluating on the test set\n",
    "    print(\"Evaluating the test set...\")\n",
    "    test_ds = tf_dataset(test_x, batch=hp[\"batch_size\"])\n",
    "    all_preds = []\n",
    "    custom_objects = {\"ClassToken\": ClassToken}\n",
    "    for fold_no in range(1, 6):\n",
    "        with tf.keras.utils.custom_object_scope(custom_objects):\n",
    "            fold_model = tf.keras.models.load_model(f\"files/modelN_fold{fold_no}.h5\")\n",
    "        y_pred_probs = fold_model.predict(test_ds)\n",
    "        all_preds.append(y_pred_probs)\n",
    "\n",
    "    avg_preds = np.mean(all_preds, axis=0)\n",
    "    final_preds = np.argmax(avg_preds, axis=1)\n",
    "    y_true = [hp[\"class_names\"].index(img.split(\"/\")[-2]) for img in test_x]\n",
    "    print(classification_report(y_true, final_preds, target_names=hp[\"class_names\"]))\n",
    "    roc_aucs = []\n",
    "\n",
    "    for i, class_name in enumerate(hp[\"class_names\"]):\n",
    "        auc_val = roc_auc_score((np.array(y_true) == i).astype(int), avg_preds[:, i])\n",
    "        roc_aucs.append(auc_val)\n",
    "        print(f\"AUC-ROC ({class_name}): {auc_val:.4f}\")\n",
    "\n",
    "    for i, class_name in enumerate(hp[\"class_names\"]):\n",
    "        fpr, tpr, _ = roc_curve((np.array(y_true) == i).astype(int), avg_preds[:, i])\n",
    "        plt.plot(fpr, tpr, label=f\"{class_name} (AUC = {roc_aucs[i]:.2f})\")\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], color='grey', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_13 (InputLayer)       [(None, 256, 3072)]          0         []                            \n",
      "                                                                                                  \n",
      " dense_600 (Dense)           (None, 256, 256)             786688    ['input_13[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_12 (T  (None, 256, 256)             0         ['dense_600[0][0]']           \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " class_token_22 (ClassToken  (None, 1, 256)               256       ['tf.__operators__.add_12[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " concatenate_12 (Concatenat  (None, 257, 256)             0         ['class_token_22[0][0]',      \n",
      " e)                                                                  'tf.__operators__.add_12[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " layer_normalization_588 (L  (None, 257, 256)             512       ['concatenate_12[0][0]']      \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_288 (  (None, 257, 256)             3155200   ['layer_normalization_588[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_588[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_576 (Add)               (None, 257, 256)             0         ['multi_head_attention_288[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'concatenate_12[0][0]']      \n",
      "                                                                                                  \n",
      " layer_normalization_589 (L  (None, 257, 256)             512       ['add_576[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_601 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_589[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_816 (Dropout)       (None, 257, 1024)            0         ['dense_601[0][0]']           \n",
      "                                                                                                  \n",
      " dense_602 (Dense)           (None, 257, 256)             262400    ['dropout_816[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_817 (Dropout)       (None, 257, 256)             0         ['dense_602[0][0]']           \n",
      "                                                                                                  \n",
      " add_577 (Add)               (None, 257, 256)             0         ['dropout_817[0][0]',         \n",
      "                                                                     'add_576[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_590 (L  (None, 257, 256)             512       ['add_577[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_289 (  (None, 257, 256)             3155200   ['layer_normalization_590[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_590[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_578 (Add)               (None, 257, 256)             0         ['multi_head_attention_289[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_577[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_591 (L  (None, 257, 256)             512       ['add_578[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_603 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_591[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_818 (Dropout)       (None, 257, 1024)            0         ['dense_603[0][0]']           \n",
      "                                                                                                  \n",
      " dense_604 (Dense)           (None, 257, 256)             262400    ['dropout_818[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_819 (Dropout)       (None, 257, 256)             0         ['dense_604[0][0]']           \n",
      "                                                                                                  \n",
      " add_579 (Add)               (None, 257, 256)             0         ['dropout_819[0][0]',         \n",
      "                                                                     'add_578[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_592 (L  (None, 257, 256)             512       ['add_579[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_290 (  (None, 257, 256)             3155200   ['layer_normalization_592[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_592[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_580 (Add)               (None, 257, 256)             0         ['multi_head_attention_290[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_579[0][0]']             \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " layer_normalization_593 (L  (None, 257, 256)             512       ['add_580[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_605 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_593[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_820 (Dropout)       (None, 257, 1024)            0         ['dense_605[0][0]']           \n",
      "                                                                                                  \n",
      " dense_606 (Dense)           (None, 257, 256)             262400    ['dropout_820[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_821 (Dropout)       (None, 257, 256)             0         ['dense_606[0][0]']           \n",
      "                                                                                                  \n",
      " add_581 (Add)               (None, 257, 256)             0         ['dropout_821[0][0]',         \n",
      "                                                                     'add_580[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_594 (L  (None, 257, 256)             512       ['add_581[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_291 (  (None, 257, 256)             3155200   ['layer_normalization_594[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_594[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_582 (Add)               (None, 257, 256)             0         ['multi_head_attention_291[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_581[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_595 (L  (None, 257, 256)             512       ['add_582[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_607 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_595[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_822 (Dropout)       (None, 257, 1024)            0         ['dense_607[0][0]']           \n",
      "                                                                                                  \n",
      " dense_608 (Dense)           (None, 257, 256)             262400    ['dropout_822[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_823 (Dropout)       (None, 257, 256)             0         ['dense_608[0][0]']           \n",
      "                                                                                                  \n",
      " add_583 (Add)               (None, 257, 256)             0         ['dropout_823[0][0]',         \n",
      "                                                                     'add_582[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_596 (L  (None, 257, 256)             512       ['add_583[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_292 (  (None, 257, 256)             3155200   ['layer_normalization_596[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_596[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_584 (Add)               (None, 257, 256)             0         ['multi_head_attention_292[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_583[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_597 (L  (None, 257, 256)             512       ['add_584[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_609 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_597[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_824 (Dropout)       (None, 257, 1024)            0         ['dense_609[0][0]']           \n",
      "                                                                                                  \n",
      " dense_610 (Dense)           (None, 257, 256)             262400    ['dropout_824[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_825 (Dropout)       (None, 257, 256)             0         ['dense_610[0][0]']           \n",
      "                                                                                                  \n",
      " add_585 (Add)               (None, 257, 256)             0         ['dropout_825[0][0]',         \n",
      "                                                                     'add_584[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_598 (L  (None, 257, 256)             512       ['add_585[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_293 (  (None, 257, 256)             3155200   ['layer_normalization_598[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_598[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_586 (Add)               (None, 257, 256)             0         ['multi_head_attention_293[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_585[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_599 (L  (None, 257, 256)             512       ['add_586[0][0]']             \n",
      " ayerNormalization)                                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " dense_611 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_599[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_826 (Dropout)       (None, 257, 1024)            0         ['dense_611[0][0]']           \n",
      "                                                                                                  \n",
      " dense_612 (Dense)           (None, 257, 256)             262400    ['dropout_826[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_827 (Dropout)       (None, 257, 256)             0         ['dense_612[0][0]']           \n",
      "                                                                                                  \n",
      " add_587 (Add)               (None, 257, 256)             0         ['dropout_827[0][0]',         \n",
      "                                                                     'add_586[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_600 (L  (None, 257, 256)             512       ['add_587[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_294 (  (None, 257, 256)             3155200   ['layer_normalization_600[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_600[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_588 (Add)               (None, 257, 256)             0         ['multi_head_attention_294[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_587[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_601 (L  (None, 257, 256)             512       ['add_588[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_613 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_601[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_828 (Dropout)       (None, 257, 1024)            0         ['dense_613[0][0]']           \n",
      "                                                                                                  \n",
      " dense_614 (Dense)           (None, 257, 256)             262400    ['dropout_828[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_829 (Dropout)       (None, 257, 256)             0         ['dense_614[0][0]']           \n",
      "                                                                                                  \n",
      " add_589 (Add)               (None, 257, 256)             0         ['dropout_829[0][0]',         \n",
      "                                                                     'add_588[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_602 (L  (None, 257, 256)             512       ['add_589[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_295 (  (None, 257, 256)             3155200   ['layer_normalization_602[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_602[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_590 (Add)               (None, 257, 256)             0         ['multi_head_attention_295[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_589[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_603 (L  (None, 257, 256)             512       ['add_590[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_615 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_603[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_830 (Dropout)       (None, 257, 1024)            0         ['dense_615[0][0]']           \n",
      "                                                                                                  \n",
      " dense_616 (Dense)           (None, 257, 256)             262400    ['dropout_830[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_831 (Dropout)       (None, 257, 256)             0         ['dense_616[0][0]']           \n",
      "                                                                                                  \n",
      " add_591 (Add)               (None, 257, 256)             0         ['dropout_831[0][0]',         \n",
      "                                                                     'add_590[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_604 (L  (None, 257, 256)             512       ['add_591[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_296 (  (None, 257, 256)             3155200   ['layer_normalization_604[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_604[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_592 (Add)               (None, 257, 256)             0         ['multi_head_attention_296[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_591[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_605 (L  (None, 257, 256)             512       ['add_592[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_617 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_605[0][0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_832 (Dropout)       (None, 257, 1024)            0         ['dense_617[0][0]']           \n",
      "                                                                                                  \n",
      " dense_618 (Dense)           (None, 257, 256)             262400    ['dropout_832[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_833 (Dropout)       (None, 257, 256)             0         ['dense_618[0][0]']           \n",
      "                                                                                                  \n",
      " add_593 (Add)               (None, 257, 256)             0         ['dropout_833[0][0]',         \n",
      "                                                                     'add_592[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_606 (L  (None, 257, 256)             512       ['add_593[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_297 (  (None, 257, 256)             3155200   ['layer_normalization_606[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_606[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_594 (Add)               (None, 257, 256)             0         ['multi_head_attention_297[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_593[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_607 (L  (None, 257, 256)             512       ['add_594[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_619 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_607[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_834 (Dropout)       (None, 257, 1024)            0         ['dense_619[0][0]']           \n",
      "                                                                                                  \n",
      " dense_620 (Dense)           (None, 257, 256)             262400    ['dropout_834[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_835 (Dropout)       (None, 257, 256)             0         ['dense_620[0][0]']           \n",
      "                                                                                                  \n",
      " add_595 (Add)               (None, 257, 256)             0         ['dropout_835[0][0]',         \n",
      "                                                                     'add_594[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_608 (L  (None, 257, 256)             512       ['add_595[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_298 (  (None, 257, 256)             3155200   ['layer_normalization_608[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_608[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_596 (Add)               (None, 257, 256)             0         ['multi_head_attention_298[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_595[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_609 (L  (None, 257, 256)             512       ['add_596[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_621 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_609[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_836 (Dropout)       (None, 257, 1024)            0         ['dense_621[0][0]']           \n",
      "                                                                                                  \n",
      " dense_622 (Dense)           (None, 257, 256)             262400    ['dropout_836[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_837 (Dropout)       (None, 257, 256)             0         ['dense_622[0][0]']           \n",
      "                                                                                                  \n",
      " add_597 (Add)               (None, 257, 256)             0         ['dropout_837[0][0]',         \n",
      "                                                                     'add_596[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_610 (L  (None, 257, 256)             512       ['add_597[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_299 (  (None, 257, 256)             3155200   ['layer_normalization_610[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_610[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_598 (Add)               (None, 257, 256)             0         ['multi_head_attention_299[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_597[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_611 (L  (None, 257, 256)             512       ['add_598[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_623 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_611[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dropout_838 (Dropout)       (None, 257, 1024)            0         ['dense_623[0][0]']           \n",
      "                                                                                                  \n",
      " dense_624 (Dense)           (None, 257, 256)             262400    ['dropout_838[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_839 (Dropout)       (None, 257, 256)             0         ['dense_624[0][0]']           \n",
      "                                                                                                  \n",
      " add_599 (Add)               (None, 257, 256)             0         ['dropout_839[0][0]',         \n",
      "                                                                     'add_598[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_612 (L  (None, 257, 256)             512       ['add_599[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_300 (  (None, 257, 256)             3155200   ['layer_normalization_612[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_612[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_600 (Add)               (None, 257, 256)             0         ['multi_head_attention_300[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_599[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_613 (L  (None, 257, 256)             512       ['add_600[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_625 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_613[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_840 (Dropout)       (None, 257, 1024)            0         ['dense_625[0][0]']           \n",
      "                                                                                                  \n",
      " dense_626 (Dense)           (None, 257, 256)             262400    ['dropout_840[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_841 (Dropout)       (None, 257, 256)             0         ['dense_626[0][0]']           \n",
      "                                                                                                  \n",
      " add_601 (Add)               (None, 257, 256)             0         ['dropout_841[0][0]',         \n",
      "                                                                     'add_600[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_614 (L  (None, 257, 256)             512       ['add_601[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_301 (  (None, 257, 256)             3155200   ['layer_normalization_614[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_614[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_602 (Add)               (None, 257, 256)             0         ['multi_head_attention_301[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_601[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_615 (L  (None, 257, 256)             512       ['add_602[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_627 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_615[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_842 (Dropout)       (None, 257, 1024)            0         ['dense_627[0][0]']           \n",
      "                                                                                                  \n",
      " dense_628 (Dense)           (None, 257, 256)             262400    ['dropout_842[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_843 (Dropout)       (None, 257, 256)             0         ['dense_628[0][0]']           \n",
      "                                                                                                  \n",
      " add_603 (Add)               (None, 257, 256)             0         ['dropout_843[0][0]',         \n",
      "                                                                     'add_602[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_616 (L  (None, 257, 256)             512       ['add_603[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_302 (  (None, 257, 256)             3155200   ['layer_normalization_616[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_616[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_604 (Add)               (None, 257, 256)             0         ['multi_head_attention_302[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_603[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_617 (L  (None, 257, 256)             512       ['add_604[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_629 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_617[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_844 (Dropout)       (None, 257, 1024)            0         ['dense_629[0][0]']           \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_630 (Dense)           (None, 257, 256)             262400    ['dropout_844[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_845 (Dropout)       (None, 257, 256)             0         ['dense_630[0][0]']           \n",
      "                                                                                                  \n",
      " add_605 (Add)               (None, 257, 256)             0         ['dropout_845[0][0]',         \n",
      "                                                                     'add_604[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_618 (L  (None, 257, 256)             512       ['add_605[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_303 (  (None, 257, 256)             3155200   ['layer_normalization_618[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_618[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_606 (Add)               (None, 257, 256)             0         ['multi_head_attention_303[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_605[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_619 (L  (None, 257, 256)             512       ['add_606[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_631 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_619[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_846 (Dropout)       (None, 257, 1024)            0         ['dense_631[0][0]']           \n",
      "                                                                                                  \n",
      " dense_632 (Dense)           (None, 257, 256)             262400    ['dropout_846[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_847 (Dropout)       (None, 257, 256)             0         ['dense_632[0][0]']           \n",
      "                                                                                                  \n",
      " add_607 (Add)               (None, 257, 256)             0         ['dropout_847[0][0]',         \n",
      "                                                                     'add_606[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_620 (L  (None, 257, 256)             512       ['add_607[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_304 (  (None, 257, 256)             3155200   ['layer_normalization_620[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_620[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_608 (Add)               (None, 257, 256)             0         ['multi_head_attention_304[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_607[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_621 (L  (None, 257, 256)             512       ['add_608[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_633 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_621[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_848 (Dropout)       (None, 257, 1024)            0         ['dense_633[0][0]']           \n",
      "                                                                                                  \n",
      " dense_634 (Dense)           (None, 257, 256)             262400    ['dropout_848[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_849 (Dropout)       (None, 257, 256)             0         ['dense_634[0][0]']           \n",
      "                                                                                                  \n",
      " add_609 (Add)               (None, 257, 256)             0         ['dropout_849[0][0]',         \n",
      "                                                                     'add_608[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_622 (L  (None, 257, 256)             512       ['add_609[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_305 (  (None, 257, 256)             3155200   ['layer_normalization_622[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_622[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_610 (Add)               (None, 257, 256)             0         ['multi_head_attention_305[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_609[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_623 (L  (None, 257, 256)             512       ['add_610[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_635 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_623[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_850 (Dropout)       (None, 257, 1024)            0         ['dense_635[0][0]']           \n",
      "                                                                                                  \n",
      " dense_636 (Dense)           (None, 257, 256)             262400    ['dropout_850[0][0]']         \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dropout_851 (Dropout)       (None, 257, 256)             0         ['dense_636[0][0]']           \n",
      "                                                                                                  \n",
      " add_611 (Add)               (None, 257, 256)             0         ['dropout_851[0][0]',         \n",
      "                                                                     'add_610[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_624 (L  (None, 257, 256)             512       ['add_611[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_306 (  (None, 257, 256)             3155200   ['layer_normalization_624[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_624[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_612 (Add)               (None, 257, 256)             0         ['multi_head_attention_306[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_611[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_625 (L  (None, 257, 256)             512       ['add_612[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_637 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_625[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_852 (Dropout)       (None, 257, 1024)            0         ['dense_637[0][0]']           \n",
      "                                                                                                  \n",
      " dense_638 (Dense)           (None, 257, 256)             262400    ['dropout_852[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_853 (Dropout)       (None, 257, 256)             0         ['dense_638[0][0]']           \n",
      "                                                                                                  \n",
      " add_613 (Add)               (None, 257, 256)             0         ['dropout_853[0][0]',         \n",
      "                                                                     'add_612[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_626 (L  (None, 257, 256)             512       ['add_613[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_307 (  (None, 257, 256)             3155200   ['layer_normalization_626[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_626[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_614 (Add)               (None, 257, 256)             0         ['multi_head_attention_307[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_613[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_627 (L  (None, 257, 256)             512       ['add_614[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_639 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_627[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_854 (Dropout)       (None, 257, 1024)            0         ['dense_639[0][0]']           \n",
      "                                                                                                  \n",
      " dense_640 (Dense)           (None, 257, 256)             262400    ['dropout_854[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_855 (Dropout)       (None, 257, 256)             0         ['dense_640[0][0]']           \n",
      "                                                                                                  \n",
      " add_615 (Add)               (None, 257, 256)             0         ['dropout_855[0][0]',         \n",
      "                                                                     'add_614[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_628 (L  (None, 257, 256)             512       ['add_615[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_308 (  (None, 257, 256)             3155200   ['layer_normalization_628[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_628[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_616 (Add)               (None, 257, 256)             0         ['multi_head_attention_308[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_615[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_629 (L  (None, 257, 256)             512       ['add_616[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_641 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_629[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_856 (Dropout)       (None, 257, 1024)            0         ['dense_641[0][0]']           \n",
      "                                                                                                  \n",
      " dense_642 (Dense)           (None, 257, 256)             262400    ['dropout_856[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_857 (Dropout)       (None, 257, 256)             0         ['dense_642[0][0]']           \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " add_617 (Add)               (None, 257, 256)             0         ['dropout_857[0][0]',         \n",
      "                                                                     'add_616[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_630 (L  (None, 257, 256)             512       ['add_617[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_309 (  (None, 257, 256)             3155200   ['layer_normalization_630[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_630[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_618 (Add)               (None, 257, 256)             0         ['multi_head_attention_309[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_617[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_631 (L  (None, 257, 256)             512       ['add_618[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_643 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_631[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_858 (Dropout)       (None, 257, 1024)            0         ['dense_643[0][0]']           \n",
      "                                                                                                  \n",
      " dense_644 (Dense)           (None, 257, 256)             262400    ['dropout_858[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_859 (Dropout)       (None, 257, 256)             0         ['dense_644[0][0]']           \n",
      "                                                                                                  \n",
      " add_619 (Add)               (None, 257, 256)             0         ['dropout_859[0][0]',         \n",
      "                                                                     'add_618[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_632 (L  (None, 257, 256)             512       ['add_619[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_310 (  (None, 257, 256)             3155200   ['layer_normalization_632[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_632[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_620 (Add)               (None, 257, 256)             0         ['multi_head_attention_310[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_619[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_633 (L  (None, 257, 256)             512       ['add_620[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_645 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_633[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_860 (Dropout)       (None, 257, 1024)            0         ['dense_645[0][0]']           \n",
      "                                                                                                  \n",
      " dense_646 (Dense)           (None, 257, 256)             262400    ['dropout_860[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_861 (Dropout)       (None, 257, 256)             0         ['dense_646[0][0]']           \n",
      "                                                                                                  \n",
      " add_621 (Add)               (None, 257, 256)             0         ['dropout_861[0][0]',         \n",
      "                                                                     'add_620[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_634 (L  (None, 257, 256)             512       ['add_621[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " multi_head_attention_311 (  (None, 257, 256)             3155200   ['layer_normalization_634[0][0\n",
      " MultiHeadAttention)                                                ]',                           \n",
      "                                                                     'layer_normalization_634[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_622 (Add)               (None, 257, 256)             0         ['multi_head_attention_311[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'add_621[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_635 (L  (None, 257, 256)             512       ['add_622[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " dense_647 (Dense)           (None, 257, 1024)            263168    ['layer_normalization_635[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dropout_862 (Dropout)       (None, 257, 1024)            0         ['dense_647[0][0]']           \n",
      "                                                                                                  \n",
      " dense_648 (Dense)           (None, 257, 256)             262400    ['dropout_862[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_863 (Dropout)       (None, 257, 256)             0         ['dense_648[0][0]']           \n",
      "                                                                                                  \n",
      " add_623 (Add)               (None, 257, 256)             0         ['dropout_863[0][0]',         \n",
      "                                                                     'add_622[0][0]']             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " layer_normalization_636 (L  (None, 257, 256)             512       ['add_623[0][0]']             \n",
      " ayerNormalization)                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  (None, 256)                  0         ['layer_normalization_636[0][0\n",
      " 2 (SlicingOpLambda)                                                ]']                           \n",
      "                                                                                                  \n",
      " dense_649 (Dense)           (None, 6)                    1542      ['tf.__operators__.getitem_12[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 89152006 (340.09 MB)\n",
      "Trainable params: 89152006 (340.09 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Train: 4166 - Valid: 1388 - Test: 1388\n",
      "Train: 4166 - Valid: 1388 - Test: 1388\n",
      "Training for fold 1 ...\n",
      "2\n",
      "Epoch 1/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 1.4685 - acc: 0.4153 - auc: 0.7514\n",
      "Epoch 1: val_loss improved from inf to 1.09118, saving model to files/modelN_fold1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278/278 [==============================] - 1704s 6s/step - loss: 1.4685 - acc: 0.4153 - auc: 0.7514 - val_loss: 1.0912 - val_acc: 0.5248 - val_auc: 0.8826 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 1.0284 - acc: 0.6104 - auc: 0.8738\n",
      "Epoch 2: val_loss improved from 1.09118 to 0.84643, saving model to files/modelN_fold1.h5\n",
      "278/278 [==============================] - 1681s 6s/step - loss: 1.0284 - acc: 0.6104 - auc: 0.8738 - val_loss: 0.8464 - val_acc: 0.6742 - val_auc: 0.9451 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.7107 - acc: 0.7441 - auc: 0.9374\n",
      "Epoch 3: val_loss improved from 0.84643 to 0.68117, saving model to files/modelN_fold1.h5\n",
      "278/278 [==============================] - 1625s 6s/step - loss: 0.7107 - acc: 0.7441 - auc: 0.9374 - val_loss: 0.6812 - val_acc: 0.7453 - val_auc: 0.9595 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.5767 - acc: 0.7902 - auc: 0.9569\n",
      "Epoch 4: val_loss improved from 0.68117 to 0.63619, saving model to files/modelN_fold1.h5\n",
      "278/278 [==============================] - 1690s 6s/step - loss: 0.5767 - acc: 0.7902 - auc: 0.9569 - val_loss: 0.6362 - val_acc: 0.7741 - val_auc: 0.9664 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.5052 - acc: 0.8170 - auc: 0.9667\n",
      "Epoch 5: val_loss improved from 0.63619 to 0.54669, saving model to files/modelN_fold1.h5\n",
      "278/278 [==============================] - 1662s 6s/step - loss: 0.5052 - acc: 0.8170 - auc: 0.9667 - val_loss: 0.5467 - val_acc: 0.7930 - val_auc: 0.9723 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.4476 - acc: 0.8348 - auc: 0.9730\n",
      "Epoch 6: val_loss improved from 0.54669 to 0.51374, saving model to files/modelN_fold1.h5\n",
      "278/278 [==============================] - 1627s 6s/step - loss: 0.4476 - acc: 0.8348 - auc: 0.9730 - val_loss: 0.5137 - val_acc: 0.8164 - val_auc: 0.9752 - lr: 1.0000e-04\n",
      "Epoch 7/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.3994 - acc: 0.8506 - auc: 0.9776\n",
      "Epoch 7: val_loss improved from 0.51374 to 0.50835, saving model to files/modelN_fold1.h5\n",
      "278/278 [==============================] - 1695s 6s/step - loss: 0.3994 - acc: 0.8506 - auc: 0.9776 - val_loss: 0.5084 - val_acc: 0.8218 - val_auc: 0.9767 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.3713 - acc: 0.8647 - auc: 0.9810\n",
      "Epoch 8: val_loss did not improve from 0.50835\n",
      "278/278 [==============================] - 1659s 6s/step - loss: 0.3713 - acc: 0.8647 - auc: 0.9810 - val_loss: 0.5549 - val_acc: 0.8209 - val_auc: 0.9715 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.3449 - acc: 0.8733 - auc: 0.9834\n",
      "Epoch 9: val_loss did not improve from 0.50835\n",
      "278/278 [==============================] - 1628s 6s/step - loss: 0.3449 - acc: 0.8733 - auc: 0.9834 - val_loss: 0.6492 - val_acc: 0.7975 - val_auc: 0.9660 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.3080 - acc: 0.8875 - auc: 0.9857\n",
      "Epoch 10: val_loss improved from 0.50835 to 0.46868, saving model to files/modelN_fold1.h5\n",
      "278/278 [==============================] - 1688s 6s/step - loss: 0.3080 - acc: 0.8875 - auc: 0.9857 - val_loss: 0.4687 - val_acc: 0.8326 - val_auc: 0.9799 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.2418 - acc: 0.9131 - auc: 0.9915\n",
      "Epoch 11: val_loss did not improve from 0.46868\n",
      "278/278 [==============================] - 1657s 6s/step - loss: 0.2418 - acc: 0.9131 - auc: 0.9915 - val_loss: 0.5274 - val_acc: 0.8299 - val_auc: 0.9770 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.2293 - acc: 0.9160 - auc: 0.9923\n",
      "Epoch 12: val_loss improved from 0.46868 to 0.45107, saving model to files/modelN_fold1.h5\n",
      "278/278 [==============================] - 1626s 6s/step - loss: 0.2293 - acc: 0.9160 - auc: 0.9923 - val_loss: 0.4511 - val_acc: 0.8722 - val_auc: 0.9791 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.2228 - acc: 0.9223 - auc: 0.9925\n",
      "Epoch 13: val_loss improved from 0.45107 to 0.36479, saving model to files/modelN_fold1.h5\n",
      "278/278 [==============================] - 1684s 6s/step - loss: 0.2228 - acc: 0.9223 - auc: 0.9925 - val_loss: 0.3648 - val_acc: 0.8956 - val_auc: 0.9849 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.1743 - acc: 0.9368 - auc: 0.9949\n",
      "Epoch 14: val_loss did not improve from 0.36479\n",
      "278/278 [==============================] - 1638s 6s/step - loss: 0.1743 - acc: 0.9368 - auc: 0.9949 - val_loss: 0.3970 - val_acc: 0.8839 - val_auc: 0.9835 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.1652 - acc: 0.9413 - auc: 0.9954\n",
      "Epoch 15: val_loss did not improve from 0.36479\n",
      "278/278 [==============================] - 1637s 6s/step - loss: 0.1652 - acc: 0.9413 - auc: 0.9954 - val_loss: 0.6671 - val_acc: 0.8488 - val_auc: 0.9651 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.1787 - acc: 0.9361 - auc: 0.9946\n",
      "Epoch 16: val_loss improved from 0.36479 to 0.33466, saving model to files/modelN_fold1.h5\n",
      "278/278 [==============================] - 1688s 6s/step - loss: 0.1787 - acc: 0.9361 - auc: 0.9946 - val_loss: 0.3347 - val_acc: 0.9064 - val_auc: 0.9850 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.1193 - acc: 0.9599 - auc: 0.9973\n",
      "Epoch 17: val_loss did not improve from 0.33466\n",
      "278/278 [==============================] - 1657s 6s/step - loss: 0.1193 - acc: 0.9599 - auc: 0.9973 - val_loss: 0.3673 - val_acc: 0.9073 - val_auc: 0.9814 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.1459 - acc: 0.9485 - auc: 0.9963\n",
      "Epoch 18: val_loss did not improve from 0.33466\n",
      "278/278 [==============================] - 1653s 6s/step - loss: 0.1459 - acc: 0.9485 - auc: 0.9963 - val_loss: 0.4370 - val_acc: 0.8857 - val_auc: 0.9806 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0934 - acc: 0.9674 - auc: 0.9983\n",
      "Epoch 19: val_loss improved from 0.33466 to 0.32174, saving model to files/modelN_fold1.h5\n",
      "278/278 [==============================] - 1645s 6s/step - loss: 0.0934 - acc: 0.9674 - auc: 0.9983 - val_loss: 0.3217 - val_acc: 0.9244 - val_auc: 0.9853 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.1135 - acc: 0.9602 - auc: 0.9978\n",
      "Epoch 20: val_loss did not improve from 0.32174\n",
      "278/278 [==============================] - 1644s 6s/step - loss: 0.1135 - acc: 0.9602 - auc: 0.9978 - val_loss: 0.3274 - val_acc: 0.9181 - val_auc: 0.9856 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0909 - acc: 0.9687 - auc: 0.9981\n",
      "Epoch 21: val_loss did not improve from 0.32174\n",
      "278/278 [==============================] - 1658s 6s/step - loss: 0.0909 - acc: 0.9687 - auc: 0.9981 - val_loss: 0.3832 - val_acc: 0.9082 - val_auc: 0.9779 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.1194 - acc: 0.9563 - auc: 0.9975\n",
      "Epoch 22: val_loss did not improve from 0.32174\n",
      "278/278 [==============================] - 1655s 6s/step - loss: 0.1194 - acc: 0.9563 - auc: 0.9975 - val_loss: 0.3250 - val_acc: 0.9118 - val_auc: 0.9837 - lr: 1.0000e-04\n",
      "Epoch 23/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0852 - acc: 0.9703 - auc: 0.9984\n",
      "Epoch 23: val_loss improved from 0.32174 to 0.28047, saving model to files/modelN_fold1.h5\n",
      "278/278 [==============================] - 1688s 6s/step - loss: 0.0852 - acc: 0.9703 - auc: 0.9984 - val_loss: 0.2805 - val_acc: 0.9325 - val_auc: 0.9891 - lr: 1.0000e-04\n",
      "Epoch 24/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0713 - acc: 0.9755 - auc: 0.9986\n",
      "Epoch 24: val_loss did not improve from 0.28047\n",
      "278/278 [==============================] - 1648s 6s/step - loss: 0.0713 - acc: 0.9755 - auc: 0.9986 - val_loss: 0.3391 - val_acc: 0.9190 - val_auc: 0.9852 - lr: 1.0000e-04\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278/278 [==============================] - ETA: 0s - loss: 0.0935 - acc: 0.9658 - auc: 0.9985\n",
      "Epoch 25: val_loss did not improve from 0.28047\n",
      "278/278 [==============================] - 1630s 6s/step - loss: 0.0935 - acc: 0.9658 - auc: 0.9985 - val_loss: 0.3214 - val_acc: 0.9154 - val_auc: 0.9867 - lr: 1.0000e-04\n",
      "Epoch 26/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0623 - acc: 0.9795 - auc: 0.9991\n",
      "Epoch 26: val_loss did not improve from 0.28047\n",
      "278/278 [==============================] - 1707s 6s/step - loss: 0.0623 - acc: 0.9795 - auc: 0.9991 - val_loss: 0.3623 - val_acc: 0.9190 - val_auc: 0.9818 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0464 - acc: 0.9851 - auc: 0.9991\n",
      "Epoch 27: val_loss did not improve from 0.28047\n",
      "278/278 [==============================] - 1644s 6s/step - loss: 0.0464 - acc: 0.9851 - auc: 0.9991 - val_loss: 0.2887 - val_acc: 0.9442 - val_auc: 0.9863 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0910 - acc: 0.9719 - auc: 0.9975\n",
      "Epoch 28: val_loss did not improve from 0.28047\n",
      "278/278 [==============================] - 1649s 6s/step - loss: 0.0910 - acc: 0.9719 - auc: 0.9975 - val_loss: 0.3656 - val_acc: 0.9091 - val_auc: 0.9834 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0626 - acc: 0.9797 - auc: 0.9993\n",
      "Epoch 29: val_loss did not improve from 0.28047\n",
      "278/278 [==============================] - 1634s 6s/step - loss: 0.0626 - acc: 0.9797 - auc: 0.9993 - val_loss: 0.2902 - val_acc: 0.9352 - val_auc: 0.9869 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0588 - acc: 0.9818 - auc: 0.9991\n",
      "Epoch 30: val_loss did not improve from 0.28047\n",
      "278/278 [==============================] - 1641s 6s/step - loss: 0.0588 - acc: 0.9818 - auc: 0.9991 - val_loss: 0.3244 - val_acc: 0.9262 - val_auc: 0.9850 - lr: 1.0000e-04\n",
      "Epoch 31/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0697 - acc: 0.9746 - auc: 0.9988\n",
      "Epoch 31: val_loss did not improve from 0.28047\n",
      "278/278 [==============================] - 1641s 6s/step - loss: 0.0697 - acc: 0.9746 - auc: 0.9988 - val_loss: 0.3272 - val_acc: 0.9217 - val_auc: 0.9826 - lr: 1.0000e-04\n",
      "Epoch 32/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0598 - acc: 0.9777 - auc: 0.9990\n",
      "Epoch 32: val_loss did not improve from 0.28047\n",
      "278/278 [==============================] - 1664s 6s/step - loss: 0.0598 - acc: 0.9777 - auc: 0.9990 - val_loss: 0.4851 - val_acc: 0.8731 - val_auc: 0.9772 - lr: 1.0000e-04\n",
      "Epoch 33/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0523 - acc: 0.9806 - auc: 0.9993\n",
      "Epoch 33: val_loss did not improve from 0.28047\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "278/278 [==============================] - 1670s 6s/step - loss: 0.0523 - acc: 0.9806 - auc: 0.9993 - val_loss: 0.3238 - val_acc: 0.9334 - val_auc: 0.9844 - lr: 1.0000e-04\n",
      "Epoch 34/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0152 - acc: 0.9959 - auc: 0.9999\n",
      "Epoch 34: val_loss improved from 0.28047 to 0.26785, saving model to files/modelN_fold1.h5\n",
      "278/278 [==============================] - 1724s 6s/step - loss: 0.0152 - acc: 0.9959 - auc: 0.9999 - val_loss: 0.2679 - val_acc: 0.9469 - val_auc: 0.9854 - lr: 1.0000e-05\n",
      "Epoch 35/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0040 - acc: 0.9998 - auc: 1.0000\n",
      "Epoch 35: val_loss improved from 0.26785 to 0.26152, saving model to files/modelN_fold1.h5\n",
      "278/278 [==============================] - 1677s 6s/step - loss: 0.0040 - acc: 0.9998 - auc: 1.0000 - val_loss: 0.2615 - val_acc: 0.9487 - val_auc: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 36/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0024 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 36: val_loss did not improve from 0.26152\n",
      "278/278 [==============================] - 1655s 6s/step - loss: 0.0024 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.2659 - val_acc: 0.9496 - val_auc: 0.9862 - lr: 1.0000e-05\n",
      "Epoch 37/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0021 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 37: val_loss did not improve from 0.26152\n",
      "278/278 [==============================] - 1657s 6s/step - loss: 0.0021 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.2690 - val_acc: 0.9478 - val_auc: 0.9863 - lr: 1.0000e-05\n",
      "Epoch 38/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0017 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 38: val_loss did not improve from 0.26152\n",
      "278/278 [==============================] - 1668s 6s/step - loss: 0.0017 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.2699 - val_acc: 0.9478 - val_auc: 0.9860 - lr: 1.0000e-05\n",
      "Epoch 39/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0013 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 39: val_loss did not improve from 0.26152\n",
      "278/278 [==============================] - 1629s 6s/step - loss: 0.0013 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.2724 - val_acc: 0.9478 - val_auc: 0.9862 - lr: 1.0000e-05\n",
      "Epoch 40/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0011 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 40: val_loss did not improve from 0.26152\n",
      "278/278 [==============================] - 1671s 6s/step - loss: 0.0011 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.2772 - val_acc: 0.9478 - val_auc: 0.9862 - lr: 1.0000e-05\n",
      "Epoch 41/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0010 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 41: val_loss did not improve from 0.26152\n",
      "278/278 [==============================] - 1662s 6s/step - loss: 0.0010 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.2811 - val_acc: 0.9478 - val_auc: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 42/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 7.8430e-04 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 42: val_loss did not improve from 0.26152\n",
      "278/278 [==============================] - 1652s 6s/step - loss: 7.8430e-04 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.2837 - val_acc: 0.9487 - val_auc: 0.9871 - lr: 1.0000e-05\n",
      "Epoch 43/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 7.6507e-04 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 43: val_loss did not improve from 0.26152\n",
      "278/278 [==============================] - 1670s 6s/step - loss: 7.6507e-04 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.2869 - val_acc: 0.9487 - val_auc: 0.9866 - lr: 1.0000e-05\n",
      "Epoch 44/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 6.2017e-04 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 44: val_loss did not improve from 0.26152\n",
      "278/278 [==============================] - 1642s 6s/step - loss: 6.2017e-04 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.2888 - val_acc: 0.9487 - val_auc: 0.9872 - lr: 1.0000e-05\n",
      "Epoch 45/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 5.7420e-04 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 45: val_loss did not improve from 0.26152\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "278/278 [==============================] - 1654s 6s/step - loss: 5.7420e-04 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.2962 - val_acc: 0.9496 - val_auc: 0.9851 - lr: 1.0000e-05\n",
      "Epoch 46/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 5.1517e-04 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 46: val_loss did not improve from 0.26152\n",
      "278/278 [==============================] - 1660s 6s/step - loss: 5.1517e-04 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.2952 - val_acc: 0.9496 - val_auc: 0.9858 - lr: 1.0000e-06\n",
      "Epoch 47/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 4.4986e-04 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 47: val_loss did not improve from 0.26152\n",
      "278/278 [==============================] - 1666s 6s/step - loss: 4.4986e-04 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.2955 - val_acc: 0.9496 - val_auc: 0.9858 - lr: 1.0000e-06\n",
      "Epoch 48/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 4.7239e-04 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 48: val_loss did not improve from 0.26152\n",
      "278/278 [==============================] - 1647s 6s/step - loss: 4.7239e-04 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.2959 - val_acc: 0.9496 - val_auc: 0.9858 - lr: 1.0000e-06\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278/278 [==============================] - ETA: 0s - loss: 4.9839e-04 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 49: val_loss did not improve from 0.26152\n",
      "278/278 [==============================] - 1736s 6s/step - loss: 4.9839e-04 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.2952 - val_acc: 0.9496 - val_auc: 0.9859 - lr: 1.0000e-06\n",
      "Epoch 50/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 4.6012e-04 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 50: val_loss did not improve from 0.26152\n",
      "278/278 [==============================] - 1709s 6s/step - loss: 4.6012e-04 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.2957 - val_acc: 0.9496 - val_auc: 0.9859 - lr: 1.0000e-06\n",
      "3\n",
      "Training for fold 2 ...\n",
      "2\n",
      "Epoch 1/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 1.4291 - acc: 0.4393 - auc: 0.7612\n",
      "Epoch 1: val_loss improved from inf to 1.04648, saving model to files/modelN_fold2.h5\n",
      "278/278 [==============================] - 1695s 6s/step - loss: 1.4291 - acc: 0.4393 - auc: 0.7612 - val_loss: 1.0465 - val_acc: 0.5572 - val_auc: 0.8844 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.8898 - acc: 0.6685 - auc: 0.9053\n",
      "Epoch 2: val_loss improved from 1.04648 to 0.71527, saving model to files/modelN_fold2.h5\n",
      "278/278 [==============================] - 1639s 6s/step - loss: 0.8898 - acc: 0.6685 - auc: 0.9053 - val_loss: 0.7153 - val_acc: 0.7408 - val_auc: 0.9481 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.6573 - acc: 0.7684 - auc: 0.9461\n",
      "Epoch 3: val_loss improved from 0.71527 to 0.51980, saving model to files/modelN_fold2.h5\n",
      "278/278 [==============================] - 1648s 6s/step - loss: 0.6573 - acc: 0.7684 - auc: 0.9461 - val_loss: 0.5198 - val_acc: 0.7930 - val_auc: 0.9688 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.5626 - acc: 0.7990 - auc: 0.9598\n",
      "Epoch 4: val_loss improved from 0.51980 to 0.50667, saving model to files/modelN_fold2.h5\n",
      "278/278 [==============================] - 1661s 6s/step - loss: 0.5626 - acc: 0.7990 - auc: 0.9598 - val_loss: 0.5067 - val_acc: 0.8029 - val_auc: 0.9719 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.5174 - acc: 0.8141 - auc: 0.9651\n",
      "Epoch 5: val_loss improved from 0.50667 to 0.42602, saving model to files/modelN_fold2.h5\n",
      "278/278 [==============================] - 1644s 6s/step - loss: 0.5174 - acc: 0.8141 - auc: 0.9651 - val_loss: 0.4260 - val_acc: 0.8434 - val_auc: 0.9776 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.4676 - acc: 0.8303 - auc: 0.9709\n",
      "Epoch 6: val_loss improved from 0.42602 to 0.36636, saving model to files/modelN_fold2.h5\n",
      "278/278 [==============================] - 1654s 6s/step - loss: 0.4676 - acc: 0.8303 - auc: 0.9709 - val_loss: 0.3664 - val_acc: 0.8713 - val_auc: 0.9835 - lr: 1.0000e-04\n",
      "Epoch 7/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.4102 - acc: 0.8497 - auc: 0.9768\n",
      "Epoch 7: val_loss improved from 0.36636 to 0.33689, saving model to files/modelN_fold2.h5\n",
      "278/278 [==============================] - 1682s 6s/step - loss: 0.4102 - acc: 0.8497 - auc: 0.9768 - val_loss: 0.3369 - val_acc: 0.8857 - val_auc: 0.9854 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.3617 - acc: 0.8674 - auc: 0.9820\n",
      "Epoch 8: val_loss improved from 0.33689 to 0.31811, saving model to files/modelN_fold2.h5\n",
      "278/278 [==============================] - 1642s 6s/step - loss: 0.3617 - acc: 0.8674 - auc: 0.9820 - val_loss: 0.3181 - val_acc: 0.8839 - val_auc: 0.9871 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.3266 - acc: 0.8812 - auc: 0.9845\n",
      "Epoch 9: val_loss did not improve from 0.31811\n",
      "278/278 [==============================] - 1630s 6s/step - loss: 0.3266 - acc: 0.8812 - auc: 0.9845 - val_loss: 0.3986 - val_acc: 0.8569 - val_auc: 0.9822 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.3003 - acc: 0.8911 - auc: 0.9870\n",
      "Epoch 10: val_loss improved from 0.31811 to 0.30029, saving model to files/modelN_fold2.h5\n",
      "278/278 [==============================] - 1679s 6s/step - loss: 0.3003 - acc: 0.8911 - auc: 0.9870 - val_loss: 0.3003 - val_acc: 0.9028 - val_auc: 0.9858 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.2609 - acc: 0.9124 - auc: 0.9900\n",
      "Epoch 11: val_loss did not improve from 0.30029\n",
      "278/278 [==============================] - 1638s 6s/step - loss: 0.2609 - acc: 0.9124 - auc: 0.9900 - val_loss: 0.3850 - val_acc: 0.8713 - val_auc: 0.9817 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.2432 - acc: 0.9142 - auc: 0.9917\n",
      "Epoch 12: val_loss did not improve from 0.30029\n",
      "278/278 [==============================] - 1647s 6s/step - loss: 0.2432 - acc: 0.9142 - auc: 0.9917 - val_loss: 0.3253 - val_acc: 0.8893 - val_auc: 0.9856 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.2294 - acc: 0.9233 - auc: 0.9921\n",
      "Epoch 13: val_loss improved from 0.30029 to 0.27751, saving model to files/modelN_fold2.h5\n",
      "278/278 [==============================] - 1697s 6s/step - loss: 0.2294 - acc: 0.9233 - auc: 0.9921 - val_loss: 0.2775 - val_acc: 0.8983 - val_auc: 0.9893 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.1665 - acc: 0.9417 - auc: 0.9957\n",
      "Epoch 14: val_loss improved from 0.27751 to 0.22989, saving model to files/modelN_fold2.h5\n",
      "278/278 [==============================] - 1645s 6s/step - loss: 0.1665 - acc: 0.9417 - auc: 0.9957 - val_loss: 0.2299 - val_acc: 0.9316 - val_auc: 0.9927 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.1481 - acc: 0.9476 - auc: 0.9964\n",
      "Epoch 15: val_loss did not improve from 0.22989\n",
      "278/278 [==============================] - 1637s 6s/step - loss: 0.1481 - acc: 0.9476 - auc: 0.9964 - val_loss: 0.2861 - val_acc: 0.9199 - val_auc: 0.9894 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.1912 - acc: 0.9309 - auc: 0.9947\n",
      "Epoch 16: val_loss did not improve from 0.22989\n",
      "278/278 [==============================] - 1647s 6s/step - loss: 0.1912 - acc: 0.9309 - auc: 0.9947 - val_loss: 0.2835 - val_acc: 0.9109 - val_auc: 0.9917 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.1541 - acc: 0.9446 - auc: 0.9964\n",
      "Epoch 17: val_loss did not improve from 0.22989\n",
      "278/278 [==============================] - 1634s 6s/step - loss: 0.1541 - acc: 0.9446 - auc: 0.9964 - val_loss: 0.2668 - val_acc: 0.9181 - val_auc: 0.9898 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.1478 - acc: 0.9487 - auc: 0.9961\n",
      "Epoch 18: val_loss did not improve from 0.22989\n",
      "278/278 [==============================] - 1652s 6s/step - loss: 0.1478 - acc: 0.9487 - auc: 0.9961 - val_loss: 0.3028 - val_acc: 0.8911 - val_auc: 0.9894 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.1179 - acc: 0.9617 - auc: 0.9974\n",
      "Epoch 19: val_loss improved from 0.22989 to 0.19502, saving model to files/modelN_fold2.h5\n",
      "278/278 [==============================] - 1709s 6s/step - loss: 0.1179 - acc: 0.9617 - auc: 0.9974 - val_loss: 0.1950 - val_acc: 0.9397 - val_auc: 0.9931 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.1249 - acc: 0.9584 - auc: 0.9976\n",
      "Epoch 20: val_loss did not improve from 0.19502\n",
      "278/278 [==============================] - 1626s 6s/step - loss: 0.1249 - acc: 0.9584 - auc: 0.9976 - val_loss: 0.2105 - val_acc: 0.9388 - val_auc: 0.9942 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.1135 - acc: 0.9638 - auc: 0.9970\n",
      "Epoch 21: val_loss did not improve from 0.19502\n",
      "278/278 [==============================] - 1657s 6s/step - loss: 0.1135 - acc: 0.9638 - auc: 0.9970 - val_loss: 0.2045 - val_acc: 0.9361 - val_auc: 0.9926 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0725 - acc: 0.9732 - auc: 0.9991\n",
      "Epoch 22: val_loss did not improve from 0.19502\n",
      "278/278 [==============================] - 1662s 6s/step - loss: 0.0725 - acc: 0.9732 - auc: 0.9991 - val_loss: 0.1964 - val_acc: 0.9406 - val_auc: 0.9916 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.1038 - acc: 0.9631 - auc: 0.9980\n",
      "Epoch 23: val_loss did not improve from 0.19502\n",
      "278/278 [==============================] - 1632s 6s/step - loss: 0.1038 - acc: 0.9631 - auc: 0.9980 - val_loss: 0.2205 - val_acc: 0.9424 - val_auc: 0.9903 - lr: 1.0000e-04\n",
      "Epoch 24/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0575 - acc: 0.9804 - auc: 0.9991\n",
      "Epoch 24: val_loss improved from 0.19502 to 0.17449, saving model to files/modelN_fold2.h5\n",
      "278/278 [==============================] - 1704s 6s/step - loss: 0.0575 - acc: 0.9804 - auc: 0.9991 - val_loss: 0.1745 - val_acc: 0.9514 - val_auc: 0.9941 - lr: 1.0000e-04\n",
      "Epoch 25/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.1194 - acc: 0.9608 - auc: 0.9971\n",
      "Epoch 25: val_loss did not improve from 0.17449\n",
      "278/278 [==============================] - 1637s 6s/step - loss: 0.1194 - acc: 0.9608 - auc: 0.9971 - val_loss: 0.2376 - val_acc: 0.9361 - val_auc: 0.9905 - lr: 1.0000e-04\n",
      "Epoch 26/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0794 - acc: 0.9743 - auc: 0.9986\n",
      "Epoch 26: val_loss improved from 0.17449 to 0.15842, saving model to files/modelN_fold2.h5\n",
      "278/278 [==============================] - 1653s 6s/step - loss: 0.0794 - acc: 0.9743 - auc: 0.9986 - val_loss: 0.1584 - val_acc: 0.9586 - val_auc: 0.9943 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0606 - acc: 0.9793 - auc: 0.9993\n",
      "Epoch 27: val_loss did not improve from 0.15842\n",
      "278/278 [==============================] - 1650s 6s/step - loss: 0.0606 - acc: 0.9793 - auc: 0.9993 - val_loss: 0.2230 - val_acc: 0.9343 - val_auc: 0.9914 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0389 - acc: 0.9854 - auc: 0.9996\n",
      "Epoch 28: val_loss did not improve from 0.15842\n",
      "278/278 [==============================] - 1639s 6s/step - loss: 0.0389 - acc: 0.9854 - auc: 0.9996 - val_loss: 0.2280 - val_acc: 0.9433 - val_auc: 0.9904 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.1066 - acc: 0.9656 - auc: 0.9978\n",
      "Epoch 29: val_loss did not improve from 0.15842\n",
      "278/278 [==============================] - 1654s 6s/step - loss: 0.1066 - acc: 0.9656 - auc: 0.9978 - val_loss: 0.2221 - val_acc: 0.9370 - val_auc: 0.9898 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0410 - acc: 0.9876 - auc: 0.9995\n",
      "Epoch 30: val_loss did not improve from 0.15842\n",
      "278/278 [==============================] - 1645s 6s/step - loss: 0.0410 - acc: 0.9876 - auc: 0.9995 - val_loss: 0.2632 - val_acc: 0.9379 - val_auc: 0.9886 - lr: 1.0000e-04\n",
      "Epoch 31/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0928 - acc: 0.9689 - auc: 0.9976\n",
      "Epoch 31: val_loss did not improve from 0.15842\n",
      "278/278 [==============================] - 1643s 6s/step - loss: 0.0928 - acc: 0.9689 - auc: 0.9976 - val_loss: 0.2100 - val_acc: 0.9442 - val_auc: 0.9907 - lr: 1.0000e-04\n",
      "Epoch 32/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0380 - acc: 0.9865 - auc: 0.9998\n",
      "Epoch 32: val_loss did not improve from 0.15842\n",
      "278/278 [==============================] - 1659s 6s/step - loss: 0.0380 - acc: 0.9865 - auc: 0.9998 - val_loss: 0.2869 - val_acc: 0.9298 - val_auc: 0.9876 - lr: 1.0000e-04\n",
      "Epoch 33/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0460 - acc: 0.9845 - auc: 0.9995\n",
      "Epoch 33: val_loss did not improve from 0.15842\n",
      "278/278 [==============================] - 1628s 6s/step - loss: 0.0460 - acc: 0.9845 - auc: 0.9995 - val_loss: 0.3973 - val_acc: 0.9001 - val_auc: 0.9827 - lr: 1.0000e-04\n",
      "Epoch 34/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0735 - acc: 0.9770 - auc: 0.9984\n",
      "Epoch 34: val_loss did not improve from 0.15842\n",
      "278/278 [==============================] - 1655s 6s/step - loss: 0.0735 - acc: 0.9770 - auc: 0.9984 - val_loss: 0.1751 - val_acc: 0.9523 - val_auc: 0.9923 - lr: 1.0000e-04\n",
      "Epoch 35/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0275 - acc: 0.9921 - auc: 0.9996\n",
      "Epoch 35: val_loss did not improve from 0.15842\n",
      "278/278 [==============================] - 1663s 6s/step - loss: 0.0275 - acc: 0.9921 - auc: 0.9996 - val_loss: 0.1798 - val_acc: 0.9568 - val_auc: 0.9908 - lr: 1.0000e-04\n",
      "Epoch 36/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0384 - acc: 0.9845 - auc: 0.9997\n",
      "Epoch 36: val_loss did not improve from 0.15842\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "278/278 [==============================] - 1657s 6s/step - loss: 0.0384 - acc: 0.9845 - auc: 0.9997 - val_loss: 0.2190 - val_acc: 0.9514 - val_auc: 0.9896 - lr: 1.0000e-04\n",
      "Epoch 37/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0145 - acc: 0.9950 - auc: 1.0000\n",
      "Epoch 37: val_loss improved from 0.15842 to 0.14162, saving model to files/modelN_fold2.h5\n",
      "278/278 [==============================] - 1651s 6s/step - loss: 0.0145 - acc: 0.9950 - auc: 1.0000 - val_loss: 0.1416 - val_acc: 0.9640 - val_auc: 0.9948 - lr: 1.0000e-05\n",
      "Epoch 38/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0041 - acc: 0.9998 - auc: 1.0000\n",
      "Epoch 38: val_loss did not improve from 0.14162\n",
      "278/278 [==============================] - 1643s 6s/step - loss: 0.0041 - acc: 0.9998 - auc: 1.0000 - val_loss: 0.1436 - val_acc: 0.9667 - val_auc: 0.9930 - lr: 1.0000e-05\n",
      "Epoch 39/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0026 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 39: val_loss did not improve from 0.14162\n",
      "278/278 [==============================] - 1654s 6s/step - loss: 0.0026 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.1473 - val_acc: 0.9694 - val_auc: 0.9925 - lr: 1.0000e-05\n",
      "Epoch 40/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0025 - acc: 0.9998 - auc: 1.0000\n",
      "Epoch 40: val_loss did not improve from 0.14162\n",
      "278/278 [==============================] - 1648s 6s/step - loss: 0.0025 - acc: 0.9998 - auc: 1.0000 - val_loss: 0.1503 - val_acc: 0.9694 - val_auc: 0.9925 - lr: 1.0000e-05\n",
      "Epoch 41/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0014 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 41: val_loss did not improve from 0.14162\n",
      "278/278 [==============================] - 1643s 6s/step - loss: 0.0014 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.1546 - val_acc: 0.9694 - val_auc: 0.9925 - lr: 1.0000e-05\n",
      "Epoch 42/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0013 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 42: val_loss did not improve from 0.14162\n",
      "278/278 [==============================] - 1763s 6s/step - loss: 0.0013 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.1554 - val_acc: 0.9685 - val_auc: 0.9920 - lr: 1.0000e-05\n",
      "Epoch 43/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0011 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 43: val_loss did not improve from 0.14162\n",
      "278/278 [==============================] - 1763s 6s/step - loss: 0.0011 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.1563 - val_acc: 0.9703 - val_auc: 0.9920 - lr: 1.0000e-05\n",
      "Epoch 44/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 9.1545e-04 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 44: val_loss did not improve from 0.14162\n",
      "278/278 [==============================] - 1772s 6s/step - loss: 9.1545e-04 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.1568 - val_acc: 0.9703 - val_auc: 0.9920 - lr: 1.0000e-05\n",
      "Epoch 45/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 9.0365e-04 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 45: val_loss did not improve from 0.14162\n",
      "278/278 [==============================] - 1755s 6s/step - loss: 9.0365e-04 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.1571 - val_acc: 0.9694 - val_auc: 0.9923 - lr: 1.0000e-05\n",
      "Epoch 46/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 6.5840e-04 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 46: val_loss did not improve from 0.14162\n",
      "278/278 [==============================] - 1766s 6s/step - loss: 6.5840e-04 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.1605 - val_acc: 0.9703 - val_auc: 0.9916 - lr: 1.0000e-05\n",
      "Epoch 47/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 5.5210e-04 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 47: val_loss did not improve from 0.14162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "278/278 [==============================] - 1769s 6s/step - loss: 5.5210e-04 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.1632 - val_acc: 0.9703 - val_auc: 0.9917 - lr: 1.0000e-05\n",
      "Epoch 48/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 5.2577e-04 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 48: val_loss did not improve from 0.14162\n",
      "278/278 [==============================] - 1658s 6s/step - loss: 5.2577e-04 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.1630 - val_acc: 0.9712 - val_auc: 0.9917 - lr: 1.0000e-06\n",
      "Epoch 49/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 4.8478e-04 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 49: val_loss did not improve from 0.14162\n",
      "278/278 [==============================] - 1630s 6s/step - loss: 4.8478e-04 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.1632 - val_acc: 0.9721 - val_auc: 0.9917 - lr: 1.0000e-06\n",
      "Epoch 50/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 5.0018e-04 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 50: val_loss did not improve from 0.14162\n",
      "278/278 [==============================] - 1652s 6s/step - loss: 5.0018e-04 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.1640 - val_acc: 0.9712 - val_auc: 0.9916 - lr: 1.0000e-06\n",
      "3\n",
      "Training for fold 3 ...\n",
      "2\n",
      "Epoch 1/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 1.3604 - acc: 0.4598 - auc: 0.7856\n",
      "Epoch 1: val_loss improved from inf to 1.16198, saving model to files/modelN_fold3.h5\n",
      "278/278 [==============================] - 1705s 6s/step - loss: 1.3604 - acc: 0.4598 - auc: 0.7856 - val_loss: 1.1620 - val_acc: 0.5302 - val_auc: 0.8853 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.8424 - acc: 0.6858 - auc: 0.9164\n",
      "Epoch 2: val_loss improved from 1.16198 to 0.74254, saving model to files/modelN_fold3.h5\n",
      "278/278 [==============================] - 1620s 6s/step - loss: 0.8424 - acc: 0.6858 - auc: 0.9164 - val_loss: 0.7425 - val_acc: 0.7219 - val_auc: 0.9434 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.6397 - acc: 0.7738 - auc: 0.9487\n",
      "Epoch 3: val_loss improved from 0.74254 to 0.70985, saving model to files/modelN_fold3.h5\n",
      "278/278 [==============================] - 1693s 6s/step - loss: 0.6397 - acc: 0.7738 - auc: 0.9487 - val_loss: 0.7099 - val_acc: 0.7282 - val_auc: 0.9559 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.5649 - acc: 0.8022 - auc: 0.9595\n",
      "Epoch 4: val_loss improved from 0.70985 to 0.50426, saving model to files/modelN_fold3.h5\n",
      "278/278 [==============================] - 1640s 6s/step - loss: 0.5649 - acc: 0.8022 - auc: 0.9595 - val_loss: 0.5043 - val_acc: 0.8155 - val_auc: 0.9709 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.4852 - acc: 0.8247 - auc: 0.9686\n",
      "Epoch 5: val_loss improved from 0.50426 to 0.48580, saving model to files/modelN_fold3.h5\n",
      "278/278 [==============================] - 1673s 6s/step - loss: 0.4852 - acc: 0.8247 - auc: 0.9686 - val_loss: 0.4858 - val_acc: 0.8164 - val_auc: 0.9724 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.4467 - acc: 0.8474 - auc: 0.9732\n",
      "Epoch 6: val_loss improved from 0.48580 to 0.38733, saving model to files/modelN_fold3.h5\n",
      "278/278 [==============================] - 1646s 6s/step - loss: 0.4467 - acc: 0.8474 - auc: 0.9732 - val_loss: 0.3873 - val_acc: 0.8551 - val_auc: 0.9800 - lr: 1.0000e-04\n",
      "Epoch 7/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.4092 - acc: 0.8589 - auc: 0.9778\n",
      "Epoch 7: val_loss improved from 0.38733 to 0.38212, saving model to files/modelN_fold3.h5\n",
      "278/278 [==============================] - 1698s 6s/step - loss: 0.4092 - acc: 0.8589 - auc: 0.9778 - val_loss: 0.3821 - val_acc: 0.8542 - val_auc: 0.9813 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.3543 - acc: 0.8704 - auc: 0.9830\n",
      "Epoch 8: val_loss improved from 0.38212 to 0.36714, saving model to files/modelN_fold3.h5\n",
      "278/278 [==============================] - 1658s 6s/step - loss: 0.3543 - acc: 0.8704 - auc: 0.9830 - val_loss: 0.3671 - val_acc: 0.8578 - val_auc: 0.9829 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.3184 - acc: 0.8852 - auc: 0.9861\n",
      "Epoch 9: val_loss improved from 0.36714 to 0.26313, saving model to files/modelN_fold3.h5\n",
      "278/278 [==============================] - 1671s 6s/step - loss: 0.3184 - acc: 0.8852 - auc: 0.9861 - val_loss: 0.2631 - val_acc: 0.9091 - val_auc: 0.9910 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.2733 - acc: 0.9034 - auc: 0.9889\n",
      "Epoch 10: val_loss did not improve from 0.26313\n",
      "278/278 [==============================] - 1645s 6s/step - loss: 0.2733 - acc: 0.9034 - auc: 0.9889 - val_loss: 0.3121 - val_acc: 0.8857 - val_auc: 0.9875 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.2525 - acc: 0.9122 - auc: 0.9905\n",
      "Epoch 11: val_loss improved from 0.26313 to 0.22342, saving model to files/modelN_fold3.h5\n",
      "278/278 [==============================] - 1661s 6s/step - loss: 0.2525 - acc: 0.9122 - auc: 0.9905 - val_loss: 0.2234 - val_acc: 0.9280 - val_auc: 0.9920 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.2371 - acc: 0.9163 - auc: 0.9920\n",
      "Epoch 12: val_loss did not improve from 0.22342\n",
      "278/278 [==============================] - 1633s 6s/step - loss: 0.2371 - acc: 0.9163 - auc: 0.9920 - val_loss: 0.2925 - val_acc: 0.8947 - val_auc: 0.9885 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.1942 - acc: 0.9334 - auc: 0.9943\n",
      "Epoch 13: val_loss did not improve from 0.22342\n",
      "278/278 [==============================] - 1637s 6s/step - loss: 0.1942 - acc: 0.9334 - auc: 0.9943 - val_loss: 0.2707 - val_acc: 0.8983 - val_auc: 0.9898 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.2037 - acc: 0.9255 - auc: 0.9940\n",
      "Epoch 14: val_loss did not improve from 0.22342\n",
      "278/278 [==============================] - 1641s 6s/step - loss: 0.2037 - acc: 0.9255 - auc: 0.9940 - val_loss: 0.2383 - val_acc: 0.9172 - val_auc: 0.9921 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.1737 - acc: 0.9422 - auc: 0.9952\n",
      "Epoch 15: val_loss did not improve from 0.22342\n",
      "278/278 [==============================] - 1659s 6s/step - loss: 0.1737 - acc: 0.9422 - auc: 0.9952 - val_loss: 0.2246 - val_acc: 0.9298 - val_auc: 0.9924 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.1473 - acc: 0.9509 - auc: 0.9962\n",
      "Epoch 16: val_loss did not improve from 0.22342\n",
      "278/278 [==============================] - 1628s 6s/step - loss: 0.1473 - acc: 0.9509 - auc: 0.9962 - val_loss: 0.2477 - val_acc: 0.9163 - val_auc: 0.9918 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.1258 - acc: 0.9590 - auc: 0.9972\n",
      "Epoch 17: val_loss improved from 0.22342 to 0.19123, saving model to files/modelN_fold3.h5\n",
      "278/278 [==============================] - 1696s 6s/step - loss: 0.1258 - acc: 0.9590 - auc: 0.9972 - val_loss: 0.1912 - val_acc: 0.9397 - val_auc: 0.9920 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.1097 - acc: 0.9615 - auc: 0.9977\n",
      "Epoch 18: val_loss improved from 0.19123 to 0.17597, saving model to files/modelN_fold3.h5\n",
      "278/278 [==============================] - 1693s 6s/step - loss: 0.1097 - acc: 0.9615 - auc: 0.9977 - val_loss: 0.1760 - val_acc: 0.9496 - val_auc: 0.9937 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.1080 - acc: 0.9635 - auc: 0.9976\n",
      "Epoch 19: val_loss did not improve from 0.17597\n",
      "278/278 [==============================] - 1636s 6s/step - loss: 0.1080 - acc: 0.9635 - auc: 0.9976 - val_loss: 0.2076 - val_acc: 0.9316 - val_auc: 0.9931 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.1219 - acc: 0.9606 - auc: 0.9971\n",
      "Epoch 20: val_loss improved from 0.17597 to 0.15601, saving model to files/modelN_fold3.h5\n",
      "278/278 [==============================] - 1706s 6s/step - loss: 0.1219 - acc: 0.9606 - auc: 0.9971 - val_loss: 0.1560 - val_acc: 0.9604 - val_auc: 0.9928 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0930 - acc: 0.9692 - auc: 0.9983\n",
      "Epoch 21: val_loss did not improve from 0.15601\n",
      "278/278 [==============================] - 1651s 6s/step - loss: 0.0930 - acc: 0.9692 - auc: 0.9983 - val_loss: 0.2306 - val_acc: 0.9298 - val_auc: 0.9908 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.1161 - acc: 0.9611 - auc: 0.9976\n",
      "Epoch 22: val_loss did not improve from 0.15601\n",
      "278/278 [==============================] - 1666s 6s/step - loss: 0.1161 - acc: 0.9611 - auc: 0.9976 - val_loss: 0.1929 - val_acc: 0.9415 - val_auc: 0.9932 - lr: 1.0000e-04\n",
      "Epoch 23/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0996 - acc: 0.9624 - auc: 0.9987\n",
      "Epoch 23: val_loss did not improve from 0.15601\n",
      "278/278 [==============================] - 1651s 6s/step - loss: 0.0996 - acc: 0.9624 - auc: 0.9987 - val_loss: 0.1914 - val_acc: 0.9532 - val_auc: 0.9926 - lr: 1.0000e-04\n",
      "Epoch 24/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0786 - acc: 0.9737 - auc: 0.9988\n",
      "Epoch 24: val_loss did not improve from 0.15601\n",
      "278/278 [==============================] - 1648s 6s/step - loss: 0.0786 - acc: 0.9737 - auc: 0.9988 - val_loss: 0.1865 - val_acc: 0.9424 - val_auc: 0.9929 - lr: 1.0000e-04\n",
      "Epoch 25/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0801 - acc: 0.9716 - auc: 0.9986\n",
      "Epoch 25: val_loss did not improve from 0.15601\n",
      "278/278 [==============================] - 1641s 6s/step - loss: 0.0801 - acc: 0.9716 - auc: 0.9986 - val_loss: 0.3229 - val_acc: 0.9172 - val_auc: 0.9869 - lr: 1.0000e-04\n",
      "Epoch 26/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0675 - acc: 0.9768 - auc: 0.9990\n",
      "Epoch 26: val_loss did not improve from 0.15601\n",
      "278/278 [==============================] - 1638s 6s/step - loss: 0.0675 - acc: 0.9768 - auc: 0.9990 - val_loss: 0.2419 - val_acc: 0.9370 - val_auc: 0.9902 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0532 - acc: 0.9813 - auc: 0.9992\n",
      "Epoch 27: val_loss did not improve from 0.15601\n",
      "278/278 [==============================] - 1661s 6s/step - loss: 0.0532 - acc: 0.9813 - auc: 0.9992 - val_loss: 0.2491 - val_acc: 0.9325 - val_auc: 0.9898 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0628 - acc: 0.9795 - auc: 0.9987\n",
      "Epoch 28: val_loss did not improve from 0.15601\n",
      "278/278 [==============================] - 1626s 6s/step - loss: 0.0628 - acc: 0.9795 - auc: 0.9987 - val_loss: 0.2649 - val_acc: 0.9361 - val_auc: 0.9873 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0693 - acc: 0.9775 - auc: 0.9988\n",
      "Epoch 29: val_loss did not improve from 0.15601\n",
      "278/278 [==============================] - 1650s 6s/step - loss: 0.0693 - acc: 0.9775 - auc: 0.9988 - val_loss: 0.2082 - val_acc: 0.9406 - val_auc: 0.9922 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0716 - acc: 0.9746 - auc: 0.9986\n",
      "Epoch 30: val_loss did not improve from 0.15601\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "278/278 [==============================] - 1645s 6s/step - loss: 0.0716 - acc: 0.9746 - auc: 0.9986 - val_loss: 0.2219 - val_acc: 0.9415 - val_auc: 0.9906 - lr: 1.0000e-04\n",
      "Epoch 31/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0260 - acc: 0.9919 - auc: 0.9998\n",
      "Epoch 31: val_loss did not improve from 0.15601\n",
      "278/278 [==============================] - 1628s 6s/step - loss: 0.0260 - acc: 0.9919 - auc: 0.9998 - val_loss: 0.1565 - val_acc: 0.9640 - val_auc: 0.9935 - lr: 1.0000e-05\n",
      "Epoch 32/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0079 - acc: 0.9986 - auc: 1.0000\n",
      "Epoch 32: val_loss improved from 0.15601 to 0.15385, saving model to files/modelN_fold3.h5\n",
      "278/278 [==============================] - 1694s 6s/step - loss: 0.0079 - acc: 0.9986 - auc: 1.0000 - val_loss: 0.1539 - val_acc: 0.9667 - val_auc: 0.9931 - lr: 1.0000e-05\n",
      "Epoch 33/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0050 - acc: 0.9995 - auc: 1.0000\n",
      "Epoch 33: val_loss did not improve from 0.15385\n",
      "278/278 [==============================] - 1647s 6s/step - loss: 0.0050 - acc: 0.9995 - auc: 1.0000 - val_loss: 0.1560 - val_acc: 0.9649 - val_auc: 0.9937 - lr: 1.0000e-05\n",
      "Epoch 34/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0039 - acc: 0.9998 - auc: 1.0000\n",
      "Epoch 34: val_loss did not improve from 0.15385\n",
      "278/278 [==============================] - 1659s 6s/step - loss: 0.0039 - acc: 0.9998 - auc: 1.0000 - val_loss: 0.1565 - val_acc: 0.9667 - val_auc: 0.9933 - lr: 1.0000e-05\n",
      "Epoch 35/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0027 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 35: val_loss did not improve from 0.15385\n",
      "278/278 [==============================] - 1654s 6s/step - loss: 0.0027 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.1564 - val_acc: 0.9658 - val_auc: 0.9938 - lr: 1.0000e-05\n",
      "Epoch 36/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0022 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 36: val_loss did not improve from 0.15385\n",
      "278/278 [==============================] - 1647s 6s/step - loss: 0.0022 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.1591 - val_acc: 0.9640 - val_auc: 0.9938 - lr: 1.0000e-05\n",
      "Epoch 37/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0018 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 37: val_loss did not improve from 0.15385\n",
      "278/278 [==============================] - 1640s 6s/step - loss: 0.0018 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.1583 - val_acc: 0.9631 - val_auc: 0.9938 - lr: 1.0000e-05\n",
      "Epoch 38/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0015 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 38: val_loss did not improve from 0.15385\n",
      "278/278 [==============================] - 1655s 6s/step - loss: 0.0015 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.1599 - val_acc: 0.9631 - val_auc: 0.9939 - lr: 1.0000e-05\n",
      "Epoch 39/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0013 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 39: val_loss did not improve from 0.15385\n",
      "278/278 [==============================] - 1664s 6s/step - loss: 0.0013 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.1626 - val_acc: 0.9640 - val_auc: 0.9939 - lr: 1.0000e-05\n",
      "Epoch 40/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0010 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 40: val_loss did not improve from 0.15385\n",
      "278/278 [==============================] - 1640s 6s/step - loss: 0.0010 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.1670 - val_acc: 0.9631 - val_auc: 0.9931 - lr: 1.0000e-05\n",
      "Epoch 41/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 8.8154e-04 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 41: val_loss did not improve from 0.15385\n",
      "278/278 [==============================] - 1651s 6s/step - loss: 8.8154e-04 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.1692 - val_acc: 0.9631 - val_auc: 0.9930 - lr: 1.0000e-05\n",
      "Epoch 42/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 7.1251e-04 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 42: val_loss did not improve from 0.15385\n",
      "\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "278/278 [==============================] - 1638s 6s/step - loss: 7.1251e-04 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.1694 - val_acc: 0.9622 - val_auc: 0.9931 - lr: 1.0000e-05\n",
      "Epoch 43/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 6.7566e-04 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 43: val_loss did not improve from 0.15385\n",
      "278/278 [==============================] - 1671s 6s/step - loss: 6.7566e-04 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.1699 - val_acc: 0.9622 - val_auc: 0.9930 - lr: 1.0000e-06\n",
      "Epoch 44/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 5.9321e-04 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 44: val_loss did not improve from 0.15385\n",
      "278/278 [==============================] - 1650s 6s/step - loss: 5.9321e-04 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.1703 - val_acc: 0.9622 - val_auc: 0.9930 - lr: 1.0000e-06\n",
      "Epoch 45/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 6.2734e-04 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 45: val_loss did not improve from 0.15385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278/278 [==============================] - 1646s 6s/step - loss: 6.2734e-04 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.1704 - val_acc: 0.9631 - val_auc: 0.9930 - lr: 1.0000e-06\n",
      "Epoch 46/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 6.2993e-04 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 46: val_loss did not improve from 0.15385\n",
      "278/278 [==============================] - 1646s 6s/step - loss: 6.2993e-04 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.1707 - val_acc: 0.9622 - val_auc: 0.9930 - lr: 1.0000e-06\n",
      "Epoch 47/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 6.2061e-04 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 47: val_loss did not improve from 0.15385\n",
      "278/278 [==============================] - 1656s 6s/step - loss: 6.2061e-04 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.1718 - val_acc: 0.9595 - val_auc: 0.9931 - lr: 1.0000e-06\n",
      "Epoch 48/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 5.8673e-04 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 48: val_loss did not improve from 0.15385\n",
      "278/278 [==============================] - 1634s 6s/step - loss: 5.8673e-04 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.1723 - val_acc: 0.9595 - val_auc: 0.9931 - lr: 1.0000e-06\n",
      "Epoch 49/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 5.5722e-04 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 49: val_loss did not improve from 0.15385\n",
      "278/278 [==============================] - 1656s 6s/step - loss: 5.5722e-04 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.1725 - val_acc: 0.9613 - val_auc: 0.9931 - lr: 1.0000e-06\n",
      "Epoch 50/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 5.3465e-04 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 50: val_loss did not improve from 0.15385\n",
      "278/278 [==============================] - 1644s 6s/step - loss: 5.3465e-04 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.1730 - val_acc: 0.9604 - val_auc: 0.9931 - lr: 1.0000e-06\n",
      "3\n",
      "Training for fold 4 ...\n",
      "2\n",
      "Epoch 1/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 1.4328 - acc: 0.4180 - auc: 0.7598\n",
      "Epoch 1: val_loss improved from inf to 1.15003, saving model to files/modelN_fold4.h5\n",
      "278/278 [==============================] - 1690s 6s/step - loss: 1.4328 - acc: 0.4180 - auc: 0.7598 - val_loss: 1.1500 - val_acc: 0.5410 - val_auc: 0.8661 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.9611 - acc: 0.6347 - auc: 0.8892\n",
      "Epoch 2: val_loss improved from 1.15003 to 0.74776, saving model to files/modelN_fold4.h5\n",
      "278/278 [==============================] - 1677s 6s/step - loss: 0.9611 - acc: 0.6347 - auc: 0.8892 - val_loss: 0.7478 - val_acc: 0.7534 - val_auc: 0.9377 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.6655 - acc: 0.7596 - auc: 0.9450\n",
      "Epoch 3: val_loss improved from 0.74776 to 0.60740, saving model to files/modelN_fold4.h5\n",
      "278/278 [==============================] - 1647s 6s/step - loss: 0.6655 - acc: 0.7596 - auc: 0.9450 - val_loss: 0.6074 - val_acc: 0.7786 - val_auc: 0.9612 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.5662 - acc: 0.7970 - auc: 0.9595\n",
      "Epoch 4: val_loss improved from 0.60740 to 0.56285, saving model to files/modelN_fold4.h5\n",
      "278/278 [==============================] - 1670s 6s/step - loss: 0.5662 - acc: 0.7970 - auc: 0.9595 - val_loss: 0.5629 - val_acc: 0.7903 - val_auc: 0.9661 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.4923 - acc: 0.8238 - auc: 0.9683\n",
      "Epoch 5: val_loss improved from 0.56285 to 0.54709, saving model to files/modelN_fold4.h5\n",
      "278/278 [==============================] - 1635s 6s/step - loss: 0.4923 - acc: 0.8238 - auc: 0.9683 - val_loss: 0.5471 - val_acc: 0.8029 - val_auc: 0.9678 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.4184 - acc: 0.8503 - auc: 0.9764\n",
      "Epoch 6: val_loss improved from 0.54709 to 0.53827, saving model to files/modelN_fold4.h5\n",
      "278/278 [==============================] - 1673s 6s/step - loss: 0.4184 - acc: 0.8503 - auc: 0.9764 - val_loss: 0.5383 - val_acc: 0.8038 - val_auc: 0.9707 - lr: 1.0000e-04\n",
      "Epoch 7/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.3859 - acc: 0.8645 - auc: 0.9797\n",
      "Epoch 7: val_loss improved from 0.53827 to 0.40275, saving model to files/modelN_fold4.h5\n",
      "278/278 [==============================] - 1633s 6s/step - loss: 0.3859 - acc: 0.8645 - auc: 0.9797 - val_loss: 0.4028 - val_acc: 0.8614 - val_auc: 0.9792 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.3401 - acc: 0.8780 - auc: 0.9835\n",
      "Epoch 8: val_loss did not improve from 0.40275\n",
      "278/278 [==============================] - 1644s 6s/step - loss: 0.3401 - acc: 0.8780 - auc: 0.9835 - val_loss: 0.5138 - val_acc: 0.8173 - val_auc: 0.9750 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.3047 - acc: 0.8929 - auc: 0.9868\n",
      "Epoch 9: val_loss did not improve from 0.40275\n",
      "278/278 [==============================] - 1622s 6s/step - loss: 0.3047 - acc: 0.8929 - auc: 0.9868 - val_loss: 0.4154 - val_acc: 0.8533 - val_auc: 0.9808 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.2600 - acc: 0.9106 - auc: 0.9897\n",
      "Epoch 10: val_loss improved from 0.40275 to 0.34852, saving model to files/modelN_fold4.h5\n",
      "278/278 [==============================] - 1681s 6s/step - loss: 0.2600 - acc: 0.9106 - auc: 0.9897 - val_loss: 0.3485 - val_acc: 0.8812 - val_auc: 0.9872 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.2471 - acc: 0.9169 - auc: 0.9906\n",
      "Epoch 11: val_loss did not improve from 0.34852\n",
      "278/278 [==============================] - 1656s 6s/step - loss: 0.2471 - acc: 0.9169 - auc: 0.9906 - val_loss: 0.3861 - val_acc: 0.8605 - val_auc: 0.9839 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.2150 - acc: 0.9271 - auc: 0.9928\n",
      "Epoch 12: val_loss did not improve from 0.34852\n",
      "278/278 [==============================] - 1657s 6s/step - loss: 0.2150 - acc: 0.9271 - auc: 0.9928 - val_loss: 0.3667 - val_acc: 0.8596 - val_auc: 0.9853 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.2193 - acc: 0.9266 - auc: 0.9927\n",
      "Epoch 13: val_loss improved from 0.34852 to 0.34659, saving model to files/modelN_fold4.h5\n",
      "278/278 [==============================] - 1675s 6s/step - loss: 0.2193 - acc: 0.9266 - auc: 0.9927 - val_loss: 0.3466 - val_acc: 0.8803 - val_auc: 0.9874 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.1976 - acc: 0.9327 - auc: 0.9936\n",
      "Epoch 14: val_loss improved from 0.34659 to 0.25974, saving model to files/modelN_fold4.h5\n",
      "278/278 [==============================] - 1653s 6s/step - loss: 0.1976 - acc: 0.9327 - auc: 0.9936 - val_loss: 0.2597 - val_acc: 0.9298 - val_auc: 0.9893 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.1572 - acc: 0.9442 - auc: 0.9960\n",
      "Epoch 15: val_loss improved from 0.25974 to 0.22027, saving model to files/modelN_fold4.h5\n",
      "278/278 [==============================] - 1686s 6s/step - loss: 0.1572 - acc: 0.9442 - auc: 0.9960 - val_loss: 0.2203 - val_acc: 0.9271 - val_auc: 0.9926 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.1374 - acc: 0.9518 - auc: 0.9968\n",
      "Epoch 16: val_loss did not improve from 0.22027\n",
      "278/278 [==============================] - 1620s 6s/step - loss: 0.1374 - acc: 0.9518 - auc: 0.9968 - val_loss: 0.2498 - val_acc: 0.9271 - val_auc: 0.9901 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.1218 - acc: 0.9586 - auc: 0.9972\n",
      "Epoch 17: val_loss did not improve from 0.22027\n",
      "278/278 [==============================] - 1639s 6s/step - loss: 0.1218 - acc: 0.9586 - auc: 0.9972 - val_loss: 0.3205 - val_acc: 0.9001 - val_auc: 0.9871 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.1247 - acc: 0.9557 - auc: 0.9971\n",
      "Epoch 18: val_loss did not improve from 0.22027\n",
      "278/278 [==============================] - 1634s 6s/step - loss: 0.1247 - acc: 0.9557 - auc: 0.9971 - val_loss: 0.2263 - val_acc: 0.9406 - val_auc: 0.9914 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.1212 - acc: 0.9617 - auc: 0.9973\n",
      "Epoch 19: val_loss did not improve from 0.22027\n",
      "278/278 [==============================] - 1643s 6s/step - loss: 0.1212 - acc: 0.9617 - auc: 0.9973 - val_loss: 0.2657 - val_acc: 0.9226 - val_auc: 0.9904 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.1306 - acc: 0.9536 - auc: 0.9964\n",
      "Epoch 20: val_loss did not improve from 0.22027\n",
      "278/278 [==============================] - 1629s 6s/step - loss: 0.1306 - acc: 0.9536 - auc: 0.9964 - val_loss: 0.2342 - val_acc: 0.9316 - val_auc: 0.9914 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0989 - acc: 0.9656 - auc: 0.9979\n",
      "Epoch 21: val_loss did not improve from 0.22027\n",
      "278/278 [==============================] - 1646s 6s/step - loss: 0.0989 - acc: 0.9656 - auc: 0.9979 - val_loss: 0.2516 - val_acc: 0.9289 - val_auc: 0.9910 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0786 - acc: 0.9775 - auc: 0.9984\n",
      "Epoch 22: val_loss did not improve from 0.22027\n",
      "278/278 [==============================] - 1623s 6s/step - loss: 0.0786 - acc: 0.9775 - auc: 0.9984 - val_loss: 0.2619 - val_acc: 0.9271 - val_auc: 0.9922 - lr: 1.0000e-04\n",
      "Epoch 23/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0937 - acc: 0.9701 - auc: 0.9981\n",
      "Epoch 23: val_loss did not improve from 0.22027\n",
      "278/278 [==============================] - 1645s 6s/step - loss: 0.0937 - acc: 0.9701 - auc: 0.9981 - val_loss: 0.2805 - val_acc: 0.9262 - val_auc: 0.9904 - lr: 1.0000e-04\n",
      "Epoch 24/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0903 - acc: 0.9687 - auc: 0.9985\n",
      "Epoch 24: val_loss improved from 0.22027 to 0.18054, saving model to files/modelN_fold4.h5\n",
      "278/278 [==============================] - 1659s 6s/step - loss: 0.0903 - acc: 0.9687 - auc: 0.9985 - val_loss: 0.1805 - val_acc: 0.9505 - val_auc: 0.9936 - lr: 1.0000e-04\n",
      "Epoch 25/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0911 - acc: 0.9710 - auc: 0.9981\n",
      "Epoch 25: val_loss did not improve from 0.18054\n",
      "278/278 [==============================] - 1645s 6s/step - loss: 0.0911 - acc: 0.9710 - auc: 0.9981 - val_loss: 0.2369 - val_acc: 0.9325 - val_auc: 0.9908 - lr: 1.0000e-04\n",
      "Epoch 26/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0441 - acc: 0.9858 - auc: 0.9997\n",
      "Epoch 26: val_loss did not improve from 0.18054\n",
      "278/278 [==============================] - 1657s 6s/step - loss: 0.0441 - acc: 0.9858 - auc: 0.9997 - val_loss: 0.2424 - val_acc: 0.9478 - val_auc: 0.9893 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0806 - acc: 0.9734 - auc: 0.9984\n",
      "Epoch 27: val_loss did not improve from 0.18054\n",
      "278/278 [==============================] - 1625s 6s/step - loss: 0.0806 - acc: 0.9734 - auc: 0.9984 - val_loss: 0.2544 - val_acc: 0.9370 - val_auc: 0.9885 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0783 - acc: 0.9710 - auc: 0.9987\n",
      "Epoch 28: val_loss did not improve from 0.18054\n",
      "278/278 [==============================] - 1651s 6s/step - loss: 0.0783 - acc: 0.9710 - auc: 0.9987 - val_loss: 0.1979 - val_acc: 0.9550 - val_auc: 0.9919 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0853 - acc: 0.9710 - auc: 0.9986\n",
      "Epoch 29: val_loss did not improve from 0.18054\n",
      "278/278 [==============================] - 1657s 6s/step - loss: 0.0853 - acc: 0.9710 - auc: 0.9986 - val_loss: 0.2317 - val_acc: 0.9451 - val_auc: 0.9910 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0523 - acc: 0.9824 - auc: 0.9993\n",
      "Epoch 30: val_loss did not improve from 0.18054\n",
      "278/278 [==============================] - 1634s 6s/step - loss: 0.0523 - acc: 0.9824 - auc: 0.9993 - val_loss: 0.3666 - val_acc: 0.9091 - val_auc: 0.9850 - lr: 1.0000e-04\n",
      "Epoch 31/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0806 - acc: 0.9721 - auc: 0.9988\n",
      "Epoch 31: val_loss did not improve from 0.18054\n",
      "278/278 [==============================] - 1656s 6s/step - loss: 0.0806 - acc: 0.9721 - auc: 0.9988 - val_loss: 0.2649 - val_acc: 0.9415 - val_auc: 0.9885 - lr: 1.0000e-04\n",
      "Epoch 32/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0546 - acc: 0.9815 - auc: 0.9992\n",
      "Epoch 32: val_loss did not improve from 0.18054\n",
      "278/278 [==============================] - 1647s 6s/step - loss: 0.0546 - acc: 0.9815 - auc: 0.9992 - val_loss: 0.2284 - val_acc: 0.9424 - val_auc: 0.9907 - lr: 1.0000e-04\n",
      "Epoch 33/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0320 - acc: 0.9896 - auc: 0.9997\n",
      "Epoch 33: val_loss did not improve from 0.18054\n",
      "278/278 [==============================] - 1660s 6s/step - loss: 0.0320 - acc: 0.9896 - auc: 0.9997 - val_loss: 0.1906 - val_acc: 0.9613 - val_auc: 0.9927 - lr: 1.0000e-04\n",
      "Epoch 34/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0403 - acc: 0.9876 - auc: 0.9993\n",
      "Epoch 34: val_loss did not improve from 0.18054\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "278/278 [==============================] - 1657s 6s/step - loss: 0.0403 - acc: 0.9876 - auc: 0.9993 - val_loss: 0.3140 - val_acc: 0.9334 - val_auc: 0.9854 - lr: 1.0000e-04\n",
      "Epoch 35/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0158 - acc: 0.9959 - auc: 1.0000\n",
      "Epoch 35: val_loss improved from 0.18054 to 0.17491, saving model to files/modelN_fold4.h5\n",
      "278/278 [==============================] - 1638s 6s/step - loss: 0.0158 - acc: 0.9959 - auc: 1.0000 - val_loss: 0.1749 - val_acc: 0.9613 - val_auc: 0.9927 - lr: 1.0000e-05\n",
      "Epoch 36/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0051 - acc: 0.9989 - auc: 1.0000\n",
      "Epoch 36: val_loss improved from 0.17491 to 0.17345, saving model to files/modelN_fold4.h5\n",
      "278/278 [==============================] - 1644s 6s/step - loss: 0.0051 - acc: 0.9989 - auc: 1.0000 - val_loss: 0.1734 - val_acc: 0.9631 - val_auc: 0.9927 - lr: 1.0000e-05\n",
      "Epoch 37/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0028 - acc: 0.9998 - auc: 1.0000\n",
      "Epoch 37: val_loss did not improve from 0.17345\n",
      "278/278 [==============================] - 1634s 6s/step - loss: 0.0028 - acc: 0.9998 - auc: 1.0000 - val_loss: 0.1741 - val_acc: 0.9622 - val_auc: 0.9928 - lr: 1.0000e-05\n",
      "Epoch 38/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0022 - acc: 0.9998 - auc: 1.0000\n",
      "Epoch 38: val_loss did not improve from 0.17345\n",
      "278/278 [==============================] - 1658s 6s/step - loss: 0.0022 - acc: 0.9998 - auc: 1.0000 - val_loss: 0.1754 - val_acc: 0.9658 - val_auc: 0.9928 - lr: 1.0000e-05\n",
      "Epoch 39/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0016 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 39: val_loss did not improve from 0.17345\n",
      "278/278 [==============================] - 1645s 6s/step - loss: 0.0016 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.1756 - val_acc: 0.9649 - val_auc: 0.9929 - lr: 1.0000e-05\n",
      "Epoch 40/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0013 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 40: val_loss did not improve from 0.17345\n",
      "278/278 [==============================] - 1639s 6s/step - loss: 0.0013 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.1763 - val_acc: 0.9649 - val_auc: 0.9929 - lr: 1.0000e-05\n",
      "Epoch 41/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0012 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 41: val_loss did not improve from 0.17345\n",
      "278/278 [==============================] - 1644s 6s/step - loss: 0.0012 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.1761 - val_acc: 0.9676 - val_auc: 0.9929 - lr: 1.0000e-05\n",
      "Epoch 42/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 9.1998e-04 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 42: val_loss did not improve from 0.17345\n",
      "278/278 [==============================] - 1622s 6s/step - loss: 9.1998e-04 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.1765 - val_acc: 0.9658 - val_auc: 0.9935 - lr: 1.0000e-05\n",
      "Epoch 43/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 8.8479e-04 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 43: val_loss did not improve from 0.17345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278/278 [==============================] - 1639s 6s/step - loss: 8.8479e-04 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.1785 - val_acc: 0.9658 - val_auc: 0.9940 - lr: 1.0000e-05\n",
      "Epoch 44/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 7.2496e-04 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 44: val_loss did not improve from 0.17345\n",
      "278/278 [==============================] - 1657s 6s/step - loss: 7.2496e-04 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.1805 - val_acc: 0.9667 - val_auc: 0.9935 - lr: 1.0000e-05\n",
      "Epoch 45/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 6.3382e-04 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 45: val_loss did not improve from 0.17345\n",
      "278/278 [==============================] - 1665s 6s/step - loss: 6.3382e-04 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.1808 - val_acc: 0.9667 - val_auc: 0.9930 - lr: 1.0000e-05\n",
      "Epoch 46/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 5.0837e-04 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 46: val_loss did not improve from 0.17345\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "278/278 [==============================] - 1632s 6s/step - loss: 5.0837e-04 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.1823 - val_acc: 0.9667 - val_auc: 0.9934 - lr: 1.0000e-05\n",
      "Epoch 47/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 4.6640e-04 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 47: val_loss did not improve from 0.17345\n",
      "278/278 [==============================] - 1610s 6s/step - loss: 4.6640e-04 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.1825 - val_acc: 0.9667 - val_auc: 0.9934 - lr: 1.0000e-06\n",
      "Epoch 48/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 4.6216e-04 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 48: val_loss did not improve from 0.17345\n",
      "278/278 [==============================] - 1633s 6s/step - loss: 4.6216e-04 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.1827 - val_acc: 0.9667 - val_auc: 0.9934 - lr: 1.0000e-06\n",
      "Epoch 49/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 4.3869e-04 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 49: val_loss did not improve from 0.17345\n",
      "278/278 [==============================] - 1622s 6s/step - loss: 4.3869e-04 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.1829 - val_acc: 0.9667 - val_auc: 0.9934 - lr: 1.0000e-06\n",
      "Epoch 50/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 4.3951e-04 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 50: val_loss did not improve from 0.17345\n",
      "278/278 [==============================] - 1640s 6s/step - loss: 4.3951e-04 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.1827 - val_acc: 0.9667 - val_auc: 0.9934 - lr: 1.0000e-06\n",
      "3\n",
      "Training for fold 5 ...\n",
      "2\n",
      "Epoch 1/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 1.4493 - acc: 0.4374 - auc: 0.7591\n",
      "Epoch 1: val_loss improved from inf to 1.08614, saving model to files/modelN_fold5.h5\n",
      "278/278 [==============================] - 1682s 6s/step - loss: 1.4493 - acc: 0.4374 - auc: 0.7591 - val_loss: 1.0861 - val_acc: 0.5829 - val_auc: 0.8865 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.9525 - acc: 0.6321 - auc: 0.8927\n",
      "Epoch 2: val_loss improved from 1.08614 to 0.75615, saving model to files/modelN_fold5.h5\n",
      "278/278 [==============================] - 1605s 6s/step - loss: 0.9525 - acc: 0.6321 - auc: 0.8927 - val_loss: 0.7561 - val_acc: 0.7081 - val_auc: 0.9436 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.6811 - acc: 0.7541 - auc: 0.9427\n",
      "Epoch 3: val_loss improved from 0.75615 to 0.58520, saving model to files/modelN_fold5.h5\n",
      "278/278 [==============================] - 1632s 6s/step - loss: 0.6811 - acc: 0.7541 - auc: 0.9427 - val_loss: 0.5852 - val_acc: 0.8081 - val_auc: 0.9616 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.5504 - acc: 0.8031 - auc: 0.9606\n",
      "Epoch 4: val_loss improved from 0.58520 to 0.51621, saving model to files/modelN_fold5.h5\n",
      "278/278 [==============================] - 1615s 6s/step - loss: 0.5504 - acc: 0.8031 - auc: 0.9606 - val_loss: 0.5162 - val_acc: 0.8108 - val_auc: 0.9687 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.4774 - acc: 0.8272 - auc: 0.9700\n",
      "Epoch 5: val_loss improved from 0.51621 to 0.49808, saving model to files/modelN_fold5.h5\n",
      "278/278 [==============================] - 1630s 6s/step - loss: 0.4774 - acc: 0.8272 - auc: 0.9700 - val_loss: 0.4981 - val_acc: 0.8378 - val_auc: 0.9717 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.4209 - acc: 0.8504 - auc: 0.9759\n",
      "Epoch 6: val_loss did not improve from 0.49808\n",
      "278/278 [==============================] - 1606s 6s/step - loss: 0.4209 - acc: 0.8504 - auc: 0.9759 - val_loss: 0.5076 - val_acc: 0.8315 - val_auc: 0.9727 - lr: 1.0000e-04\n",
      "Epoch 7/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.3753 - acc: 0.8690 - auc: 0.9805\n",
      "Epoch 7: val_loss did not improve from 0.49808\n",
      "278/278 [==============================] - 1641s 6s/step - loss: 0.3753 - acc: 0.8690 - auc: 0.9805 - val_loss: 0.4986 - val_acc: 0.8369 - val_auc: 0.9728 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.3662 - acc: 0.8670 - auc: 0.9818\n",
      "Epoch 8: val_loss did not improve from 0.49808\n",
      "278/278 [==============================] - 1604s 6s/step - loss: 0.3662 - acc: 0.8670 - auc: 0.9818 - val_loss: 0.5300 - val_acc: 0.8405 - val_auc: 0.9723 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.3187 - acc: 0.8915 - auc: 0.9855\n",
      "Epoch 9: val_loss improved from 0.49808 to 0.41427, saving model to files/modelN_fold5.h5\n",
      "278/278 [==============================] - 1617s 6s/step - loss: 0.3187 - acc: 0.8915 - auc: 0.9855 - val_loss: 0.4143 - val_acc: 0.8532 - val_auc: 0.9813 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.2895 - acc: 0.9026 - auc: 0.9881\n",
      "Epoch 10: val_loss improved from 0.41427 to 0.36028, saving model to files/modelN_fold5.h5\n",
      "278/278 [==============================] - 1652s 6s/step - loss: 0.2895 - acc: 0.9026 - auc: 0.9881 - val_loss: 0.3603 - val_acc: 0.8730 - val_auc: 0.9848 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.2601 - acc: 0.9113 - auc: 0.9906\n",
      "Epoch 11: val_loss improved from 0.36028 to 0.33993, saving model to files/modelN_fold5.h5\n",
      "278/278 [==============================] - 1622s 6s/step - loss: 0.2601 - acc: 0.9113 - auc: 0.9906 - val_loss: 0.3399 - val_acc: 0.8937 - val_auc: 0.9851 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.2309 - acc: 0.9210 - auc: 0.9922\n",
      "Epoch 12: val_loss improved from 0.33993 to 0.31444, saving model to files/modelN_fold5.h5\n",
      "278/278 [==============================] - 1643s 6s/step - loss: 0.2309 - acc: 0.9210 - auc: 0.9922 - val_loss: 0.3144 - val_acc: 0.8982 - val_auc: 0.9863 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.1986 - acc: 0.9318 - auc: 0.9941\n",
      "Epoch 13: val_loss improved from 0.31444 to 0.28464, saving model to files/modelN_fold5.h5\n",
      "278/278 [==============================] - 1634s 6s/step - loss: 0.1986 - acc: 0.9318 - auc: 0.9941 - val_loss: 0.2846 - val_acc: 0.9063 - val_auc: 0.9877 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.1655 - acc: 0.9426 - auc: 0.9955\n",
      "Epoch 14: val_loss did not improve from 0.28464\n",
      "278/278 [==============================] - 1597s 6s/step - loss: 0.1655 - acc: 0.9426 - auc: 0.9955 - val_loss: 0.4246 - val_acc: 0.8613 - val_auc: 0.9809 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.1433 - acc: 0.9487 - auc: 0.9969\n",
      "Epoch 15: val_loss did not improve from 0.28464\n",
      "278/278 [==============================] - 1622s 6s/step - loss: 0.1433 - acc: 0.9487 - auc: 0.9969 - val_loss: 0.3830 - val_acc: 0.8928 - val_auc: 0.9850 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.1437 - acc: 0.9496 - auc: 0.9961\n",
      "Epoch 16: val_loss did not improve from 0.28464\n",
      "278/278 [==============================] - 1598s 6s/step - loss: 0.1437 - acc: 0.9496 - auc: 0.9961 - val_loss: 0.3231 - val_acc: 0.9009 - val_auc: 0.9876 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.1505 - acc: 0.9496 - auc: 0.9960\n",
      "Epoch 17: val_loss did not improve from 0.28464\n",
      "278/278 [==============================] - 1619s 6s/step - loss: 0.1505 - acc: 0.9496 - auc: 0.9960 - val_loss: 0.3373 - val_acc: 0.8937 - val_auc: 0.9855 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.1409 - acc: 0.9559 - auc: 0.9960\n",
      "Epoch 18: val_loss improved from 0.28464 to 0.27636, saving model to files/modelN_fold5.h5\n",
      "278/278 [==============================] - 1632s 6s/step - loss: 0.1409 - acc: 0.9559 - auc: 0.9960 - val_loss: 0.2764 - val_acc: 0.9162 - val_auc: 0.9896 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.1029 - acc: 0.9635 - auc: 0.9980\n",
      "Epoch 19: val_loss did not improve from 0.27636\n",
      "278/278 [==============================] - 1620s 6s/step - loss: 0.1029 - acc: 0.9635 - auc: 0.9980 - val_loss: 0.3318 - val_acc: 0.9009 - val_auc: 0.9886 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.1062 - acc: 0.9635 - auc: 0.9979\n",
      "Epoch 20: val_loss did not improve from 0.27636\n",
      "278/278 [==============================] - 1631s 6s/step - loss: 0.1062 - acc: 0.9635 - auc: 0.9979 - val_loss: 0.3248 - val_acc: 0.9054 - val_auc: 0.9879 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0988 - acc: 0.9667 - auc: 0.9977\n",
      "Epoch 21: val_loss did not improve from 0.27636\n",
      "278/278 [==============================] - 1604s 6s/step - loss: 0.0988 - acc: 0.9667 - auc: 0.9977 - val_loss: 0.3237 - val_acc: 0.9063 - val_auc: 0.9856 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.1111 - acc: 0.9608 - auc: 0.9973\n",
      "Epoch 22: val_loss did not improve from 0.27636\n",
      "278/278 [==============================] - 1601s 6s/step - loss: 0.1111 - acc: 0.9608 - auc: 0.9973 - val_loss: 0.3345 - val_acc: 0.9135 - val_auc: 0.9863 - lr: 1.0000e-04\n",
      "Epoch 23/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0900 - acc: 0.9687 - auc: 0.9984\n",
      "Epoch 23: val_loss did not improve from 0.27636\n",
      "278/278 [==============================] - 1623s 6s/step - loss: 0.0900 - acc: 0.9687 - auc: 0.9984 - val_loss: 0.2910 - val_acc: 0.9297 - val_auc: 0.9869 - lr: 1.0000e-04\n",
      "Epoch 24/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0947 - acc: 0.9683 - auc: 0.9979\n",
      "Epoch 24: val_loss improved from 0.27636 to 0.27608, saving model to files/modelN_fold5.h5\n",
      "278/278 [==============================] - 1635s 6s/step - loss: 0.0947 - acc: 0.9683 - auc: 0.9979 - val_loss: 0.2761 - val_acc: 0.9288 - val_auc: 0.9885 - lr: 1.0000e-04\n",
      "Epoch 25/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0743 - acc: 0.9730 - auc: 0.9986\n",
      "Epoch 25: val_loss did not improve from 0.27608\n",
      "278/278 [==============================] - 1620s 6s/step - loss: 0.0743 - acc: 0.9730 - auc: 0.9986 - val_loss: 0.2917 - val_acc: 0.9243 - val_auc: 0.9885 - lr: 1.0000e-04\n",
      "Epoch 26/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0513 - acc: 0.9809 - auc: 0.9993\n",
      "Epoch 26: val_loss did not improve from 0.27608\n",
      "278/278 [==============================] - 1600s 6s/step - loss: 0.0513 - acc: 0.9809 - auc: 0.9993 - val_loss: 0.3580 - val_acc: 0.9207 - val_auc: 0.9841 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0484 - acc: 0.9809 - auc: 0.9995\n",
      "Epoch 27: val_loss did not improve from 0.27608\n",
      "278/278 [==============================] - 1611s 6s/step - loss: 0.0484 - acc: 0.9809 - auc: 0.9995 - val_loss: 0.4848 - val_acc: 0.8847 - val_auc: 0.9796 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0949 - acc: 0.9658 - auc: 0.9979\n",
      "Epoch 28: val_loss did not improve from 0.27608\n",
      "278/278 [==============================] - 1602s 6s/step - loss: 0.0949 - acc: 0.9658 - auc: 0.9979 - val_loss: 0.2811 - val_acc: 0.9288 - val_auc: 0.9877 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0460 - acc: 0.9840 - auc: 0.9996\n",
      "Epoch 29: val_loss did not improve from 0.27608\n",
      "278/278 [==============================] - 1635s 6s/step - loss: 0.0460 - acc: 0.9840 - auc: 0.9996 - val_loss: 0.3232 - val_acc: 0.9189 - val_auc: 0.9857 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0927 - acc: 0.9701 - auc: 0.9978\n",
      "Epoch 30: val_loss did not improve from 0.27608\n",
      "278/278 [==============================] - 1598s 6s/step - loss: 0.0927 - acc: 0.9701 - auc: 0.9978 - val_loss: 0.3329 - val_acc: 0.9225 - val_auc: 0.9873 - lr: 1.0000e-04\n",
      "Epoch 31/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0377 - acc: 0.9883 - auc: 0.9997\n",
      "Epoch 31: val_loss did not improve from 0.27608\n",
      "278/278 [==============================] - 1616s 6s/step - loss: 0.0377 - acc: 0.9883 - auc: 0.9997 - val_loss: 0.3640 - val_acc: 0.9144 - val_auc: 0.9847 - lr: 1.0000e-04\n",
      "Epoch 32/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0254 - acc: 0.9926 - auc: 0.9999\n",
      "Epoch 32: val_loss did not improve from 0.27608\n",
      "278/278 [==============================] - 1595s 6s/step - loss: 0.0254 - acc: 0.9926 - auc: 0.9999 - val_loss: 0.3908 - val_acc: 0.9144 - val_auc: 0.9849 - lr: 1.0000e-04\n",
      "Epoch 33/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0745 - acc: 0.9737 - auc: 0.9985\n",
      "Epoch 33: val_loss did not improve from 0.27608\n",
      "278/278 [==============================] - 1635s 6s/step - loss: 0.0745 - acc: 0.9737 - auc: 0.9985 - val_loss: 0.2868 - val_acc: 0.9333 - val_auc: 0.9865 - lr: 1.0000e-04\n",
      "Epoch 34/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0461 - acc: 0.9845 - auc: 0.9993\n",
      "Epoch 34: val_loss did not improve from 0.27608\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "278/278 [==============================] - 1602s 6s/step - loss: 0.0461 - acc: 0.9845 - auc: 0.9993 - val_loss: 0.4301 - val_acc: 0.9009 - val_auc: 0.9814 - lr: 1.0000e-04\n",
      "Epoch 35/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0191 - acc: 0.9946 - auc: 0.9998\n",
      "Epoch 35: val_loss improved from 0.27608 to 0.24227, saving model to files/modelN_fold5.h5\n",
      "278/278 [==============================] - 1652s 6s/step - loss: 0.0191 - acc: 0.9946 - auc: 0.9998 - val_loss: 0.2423 - val_acc: 0.9495 - val_auc: 0.9886 - lr: 1.0000e-05\n",
      "Epoch 36/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0048 - acc: 0.9998 - auc: 1.0000\n",
      "Epoch 36: val_loss improved from 0.24227 to 0.23683, saving model to files/modelN_fold5.h5\n",
      "278/278 [==============================] - 1604s 6s/step - loss: 0.0048 - acc: 0.9998 - auc: 1.0000 - val_loss: 0.2368 - val_acc: 0.9514 - val_auc: 0.9887 - lr: 1.0000e-05\n",
      "Epoch 37/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0032 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 37: val_loss improved from 0.23683 to 0.23675, saving model to files/modelN_fold5.h5\n",
      "278/278 [==============================] - 1661s 6s/step - loss: 0.0032 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.2367 - val_acc: 0.9514 - val_auc: 0.9887 - lr: 1.0000e-05\n",
      "Epoch 38/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0026 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 38: val_loss did not improve from 0.23675\n",
      "278/278 [==============================] - 1597s 6s/step - loss: 0.0026 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.2385 - val_acc: 0.9523 - val_auc: 0.9878 - lr: 1.0000e-05\n",
      "Epoch 39/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0020 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 39: val_loss did not improve from 0.23675\n",
      "278/278 [==============================] - 1614s 6s/step - loss: 0.0020 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.2400 - val_acc: 0.9523 - val_auc: 0.9879 - lr: 1.0000e-05\n",
      "Epoch 40/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0016 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 40: val_loss did not improve from 0.23675\n",
      "278/278 [==============================] - 1599s 6s/step - loss: 0.0016 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.2415 - val_acc: 0.9541 - val_auc: 0.9878 - lr: 1.0000e-05\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278/278 [==============================] - ETA: 0s - loss: 0.0014 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 41: val_loss did not improve from 0.23675\n",
      "278/278 [==============================] - 1622s 6s/step - loss: 0.0014 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.2447 - val_acc: 0.9541 - val_auc: 0.9874 - lr: 1.0000e-05\n",
      "Epoch 42/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 0.0012 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 42: val_loss did not improve from 0.23675\n",
      "278/278 [==============================] - 1604s 6s/step - loss: 0.0012 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.2466 - val_acc: 0.9550 - val_auc: 0.9874 - lr: 1.0000e-05\n",
      "Epoch 43/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 9.9755e-04 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 43: val_loss did not improve from 0.23675\n",
      "278/278 [==============================] - 1638s 6s/step - loss: 9.9755e-04 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.2487 - val_acc: 0.9541 - val_auc: 0.9874 - lr: 1.0000e-05\n",
      "Epoch 44/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 8.5943e-04 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 44: val_loss did not improve from 0.23675\n",
      "278/278 [==============================] - 1604s 6s/step - loss: 8.5943e-04 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.2510 - val_acc: 0.9550 - val_auc: 0.9874 - lr: 1.0000e-05\n",
      "Epoch 45/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 7.3238e-04 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 45: val_loss did not improve from 0.23675\n",
      "278/278 [==============================] - 1646s 6s/step - loss: 7.3238e-04 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.2533 - val_acc: 0.9550 - val_auc: 0.9875 - lr: 1.0000e-05\n",
      "Epoch 46/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 6.6685e-04 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 46: val_loss did not improve from 0.23675\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "278/278 [==============================] - 1605s 6s/step - loss: 6.6685e-04 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.2572 - val_acc: 0.9541 - val_auc: 0.9875 - lr: 1.0000e-05\n",
      "Epoch 47/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 5.6372e-04 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 47: val_loss did not improve from 0.23675\n",
      "278/278 [==============================] - 1635s 6s/step - loss: 5.6372e-04 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.2577 - val_acc: 0.9541 - val_auc: 0.9875 - lr: 1.0000e-06\n",
      "Epoch 48/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 5.5031e-04 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 48: val_loss did not improve from 0.23675\n",
      "278/278 [==============================] - 1605s 6s/step - loss: 5.5031e-04 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.2579 - val_acc: 0.9541 - val_auc: 0.9875 - lr: 1.0000e-06\n",
      "Epoch 49/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 5.2563e-04 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 49: val_loss did not improve from 0.23675\n",
      "278/278 [==============================] - 1637s 6s/step - loss: 5.2563e-04 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.2584 - val_acc: 0.9532 - val_auc: 0.9875 - lr: 1.0000e-06\n",
      "Epoch 50/50\n",
      "278/278 [==============================] - ETA: 0s - loss: 4.9621e-04 - acc: 1.0000 - auc: 1.0000\n",
      "Epoch 50: val_loss did not improve from 0.23675\n",
      "278/278 [==============================] - 1606s 6s/step - loss: 4.9621e-04 - acc: 1.0000 - auc: 1.0000 - val_loss: 0.2593 - val_acc: 0.9532 - val_auc: 0.9875 - lr: 1.0000e-06\n",
      "3\n",
      "Evaluating the test set...\n",
      "87/87 [==============================] - 147s 2s/step\n",
      "87/87 [==============================] - 155s 2s/step\n",
      "87/87 [==============================] - 142s 2s/step\n",
      "87/87 [==============================] - 161s 2s/step\n",
      "87/87 [==============================] - 154s 2s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Yellow_rust       0.98      0.98      0.98       224\n",
      "  Brown_rust       0.94      0.96      0.95       225\n",
      "     Healthy       0.98      0.96      0.97       248\n",
      "Blast_Leaves       1.00      1.00      1.00       250\n",
      "   Stem_Rust       0.95      0.92      0.93       218\n",
      "    Tan_Spot       0.94      0.99      0.96       223\n",
      "\n",
      "    accuracy                           0.97      1388\n",
      "   macro avg       0.97      0.97      0.97      1388\n",
      "weighted avg       0.97      0.97      0.97      1388\n",
      "\n",
      "AUC-ROC (Yellow_rust): 0.9995\n",
      "AUC-ROC (Brown_rust): 0.9976\n",
      "AUC-ROC (Healthy): 0.9986\n",
      "AUC-ROC (Blast_Leaves): 1.0000\n",
      "AUC-ROC (Stem_Rust): 0.9967\n",
      "AUC-ROC (Tan_Spot): 0.9991\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#50 epoch sall dataset train and test\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "\n",
    "class ClassToken(Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        w_init = tf.random_normal_initializer()\n",
    "        self.w = tf.Variable(\n",
    "            initial_value = w_init(shape=(1, 1, input_shape[-1]), dtype=tf.float32),\n",
    "            trainable = True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        hidden_dim = self.w.shape[-1]\n",
    "\n",
    "        cls = tf.broadcast_to(self.w, [batch_size, 1, hidden_dim])\n",
    "        cls = tf.cast(cls, dtype=inputs.dtype)\n",
    "        return cls\n",
    "\n",
    "def mlp(x, cf):\n",
    "    x = Dense(cf[\"mlp_dim\"], activation=\"gelu\")(x)\n",
    "    x = Dropout(cf[\"dropout_rate\"])(x)\n",
    "    x = Dense(cf[\"hidden_dim\"])(x)\n",
    "    x = Dropout(cf[\"dropout_rate\"])(x)\n",
    "    return x\n",
    "\n",
    "def transformer_encoder(x, cf):\n",
    "    skip_1 = x\n",
    "    x = LayerNormalization()(x)\n",
    "    x = MultiHeadAttention(\n",
    "        num_heads=cf[\"num_heads\"], key_dim=cf[\"hidden_dim\"]\n",
    "    )(x, x)\n",
    "    x = Add()([x, skip_1])\n",
    "\n",
    "    skip_2 = x\n",
    "    x = LayerNormalization()(x)\n",
    "    x = mlp(x, cf)\n",
    "    x = Add()([x, skip_2])\n",
    "\n",
    "    return x\n",
    "\n",
    "def ViT(cf):\n",
    "    \"\"\" Inputs \"\"\"\n",
    "    input_shape = (cf[\"num_patches\"], cf[\"patch_size\"]*cf[\"patch_size\"]*cf[\"num_channels\"])\n",
    "    inputs = Input(input_shape)     ## (None, 256, 3072)\n",
    "\n",
    "    \"\"\" Patch + Position Embeddings \"\"\"\n",
    "    patch_embed = Dense(cf[\"hidden_dim\"])(inputs)   ## (None, 256, 768)\n",
    "\n",
    "    positions = tf.range(start=0, limit=cf[\"num_patches\"], delta=1)\n",
    "    pos_embed = Embedding(input_dim=cf[\"num_patches\"], output_dim=cf[\"hidden_dim\"])(positions) ## (256, 768)\n",
    "    embed = patch_embed + pos_embed ## (None, 256, 768)\n",
    "\n",
    "    \"\"\" Adding Class Token \"\"\"\n",
    "    token = ClassToken()(embed)\n",
    "    x = Concatenate(axis=1)([token, embed]) ## (None, 257, 768)\n",
    "\n",
    "    for _ in range(cf[\"num_layers\"]):\n",
    "        x = transformer_encoder(x, cf)\n",
    "\n",
    "    \"\"\" Classification Head \"\"\"\n",
    "    x = LayerNormalization()(x)     ## (None, 257, 768)\n",
    "    x = x[:, 0, :]\n",
    "    x = Dense(cf[\"num_classes\"], activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs, x)\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config = {}\n",
    "    config[\"num_layers\"] = 24\n",
    "#     config[\"hidden_dim\"] = 768\n",
    "#     config[\"mlp_dim\"] =3072\n",
    "    config[\"num_heads\"] = 12\n",
    "    config[\"dropout_rate\"] = 0.1\n",
    "    config[\"num_patches\"] = 256\n",
    "    config[\"patch_size\"] = 32\n",
    "    config[\"num_channels\"] = 3\n",
    "    config[\"num_classes\"] = 6\n",
    "\n",
    "    config[\"hidden_dim\"] = 256\n",
    "    config[\"mlp_dim\"] = 1024  \n",
    "\n",
    "    model = ViT(config)\n",
    "    model.summary()\n",
    "\n",
    "\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive/')\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from keras.metrics import AUC\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
    "from patchify import patchify\n",
    "# import tensorflow_hub as hub\n",
    "# Assuming you have already imported or defined the ViT model\n",
    "# ...\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "#from project import ViT\n",
    "hp = {\n",
    "    \"image_size\": 512,\n",
    "    \"num_channels\": 3,\n",
    "    \"patch_size\": 64,\n",
    "    \"num_classes\": 6,\n",
    "    \"class_names\": [\"Yellow_rust\",\"Brown_rust\", \"Healthy\",\"Blast_Leaves\",\"Stem_Rust\",\"Tan_Spot\"],\n",
    "    \"num_layers\": 24,\n",
    "    \"hidden_dim\": 256,\n",
    "    \"mlp_dim\": 1024,\n",
    "    \"num_heads\": 4,\n",
    "    \"dropout_rate\": 0.1,\n",
    "    \"batch_size\": 16,\n",
    "    \"lr\": 1e-4,\n",
    "    \"num_epochs\": 50\n",
    "}\n",
    "hp[\"num_patches\"] = (hp[\"image_size\"] ** 2) // (hp[\"patch_size\"] ** 2)\n",
    "hp[\"flat_patches_shape\"] = (hp[\"num_patches\"], hp[\"patch_size\"] * hp[\"patch_size\"] * hp[\"num_channels\"])\n",
    "\n",
    "\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "\n",
    "def load_data(path, split=0.20):\n",
    "    images = glob(os.path.join(path, \"*\", \"*.jpg\"))\n",
    "\n",
    "    # Separate images by class\n",
    "    images_class_BKL = [image for image in images if \"Yellow_rust\" in image]\n",
    "    images_class_NV = [image for image in images if \"Brown_rust\" in image]\n",
    "    images_class_MEL2 = [image for image in images if \"Healthy\" in image]\n",
    "    images_class_BlastLeaves = [image for image in images if \"Blast_Leaves\" in image]\n",
    "    images_class_Stem_Rust = [image for image in images if \"Stem_Rust\" in image]\n",
    "    images_class_Tan_Spot = [image for image in images if \"Tan_Spot\" in image]\n",
    "\n",
    "    # Oversample to 33,000 to match the largest class (BKL)\n",
    "    target_size = len(images_class_BKL)\n",
    "    #print(images_class_BKL)\n",
    "    images_class_NV = np.random.choice(images_class_NV, size=target_size, replace=True).tolist()\n",
    "    images_class_MEL2 = np.random.choice(images_class_MEL2, size=target_size, replace=True).tolist()\n",
    "    images_class_BlastLeaves = np.random.choice(images_class_BlastLeaves, size=target_size, replace=True).tolist()\n",
    "    images_class_Stem_Rust = np.random.choice(images_class_Stem_Rust, size=target_size, replace=True).tolist()\n",
    "    images_class_Tan_Spot = np.random.choice(images_class_Tan_Spot, size=target_size, replace=True).tolist()\n",
    "    # Concatenate lists again and shuffle\n",
    "    images = shuffle(images_class_BKL + images_class_NV + images_class_MEL2+ images_class_BlastLeaves+images_class_Stem_Rust+images_class_Tan_Spot)\n",
    "\n",
    "    split_size = int(len(images) * split)\n",
    "    train_x, valid_x = train_test_split(images, test_size=split_size, random_state=42)\n",
    "    train_x, test_x = train_test_split(train_x, test_size=split_size, random_state=42)\n",
    "    print(f\"Train: {len(train_x)} - Valid: {len(valid_x)} - Test: {len(test_x)}\")\n",
    "\n",
    "    return train_x, valid_x, test_x\n",
    "\n",
    "\n",
    "def process_image_label(path):\n",
    "    path = path.decode()\n",
    "    image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (hp[\"image_size\"], hp[\"image_size\"]))\n",
    "    image = image / 255.0\n",
    "\n",
    "    patch_shape = (hp[\"patch_size\"], hp[\"patch_size\"], hp[\"num_channels\"])\n",
    "    patches = patchify(image, patch_shape, hp[\"patch_size\"])\n",
    "    patches = np.reshape(patches, hp[\"flat_patches_shape\"])\n",
    "    patches = patches.astype(np.float32)\n",
    "\n",
    "    class_name = path.split(\"/\")[-2]\n",
    "    class_idx = hp[\"class_names\"].index(class_name)\n",
    "    class_idx = np.array(class_idx, dtype=np.int32)\n",
    "    return patches, class_idx\n",
    "\n",
    "\n",
    "def parse(path):\n",
    "    patches, labels = tf.numpy_function(process_image_label, [path], [tf.float32, tf.int32])\n",
    "    labels = tf.one_hot(labels, hp[\"num_classes\"])\n",
    "\n",
    "    patches.set_shape(hp[\"flat_patches_shape\"])\n",
    "    labels.set_shape(hp[\"num_classes\"])\n",
    "\n",
    "    return patches, labels\n",
    "\n",
    "\n",
    "def tf_dataset(images, batch=32):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((images))\n",
    "    ds = ds.map(parse).batch(batch).prefetch(8)\n",
    "    return ds\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    model = ViT(hp)\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        optimizer=tf.keras.optimizers.Adam(hp[\"lr\"], clipvalue=1.0),\n",
    "        metrics=[\"acc\", AUC(name='auc', multi_label=True)]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_dir(\"files\")\n",
    "    dataset_path = '/home/ali/Music/PYTHON/WholeDatasetReal'\n",
    "    model_path = os.path.join(\"files\", \"model3.h5\")\n",
    "    csv_path = os.path.join(\"files\", \"log2.csv\")\n",
    "    train_x, valid_x, test_x = load_data(dataset_path)\n",
    "    images = train_x + valid_x\n",
    "    print(f\"Train: {len(train_x)} - Valid: {len(valid_x)} - Test: {len(test_x)}\")\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    fold_no = 1\n",
    "\n",
    "    for train, val in kfold.split(images):\n",
    "        print(f'Training for fold {fold_no} ...')\n",
    "        train_ds = tf_dataset(np.array(images)[train], batch=hp[\"batch_size\"])\n",
    "        valid_ds = tf_dataset(np.array(images)[val], batch=hp[\"batch_size\"])\n",
    "        model = get_model()\n",
    "        callbacks = [\n",
    "            ModelCheckpoint(f\"files/modelN_fold{fold_no}.h5\", monitor='val_loss', verbose=1, save_best_only=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, min_lr=1e-10, verbose=1),\n",
    "            CSVLogger(f\"files/log2_fold{fold_no}.csv\"),\n",
    "            EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=False),\n",
    "        ]\n",
    "        print(2)\n",
    "        model.fit(train_ds, epochs=hp[\"num_epochs\"], validation_data=valid_ds, callbacks=callbacks)\n",
    "        fold_no += 1\n",
    "        print(3)\n",
    "\n",
    "    # Evaluating on the test set\n",
    "    print(\"Evaluating the test set...\")\n",
    "    test_ds = tf_dataset(test_x, batch=hp[\"batch_size\"])\n",
    "    all_preds = []\n",
    "    custom_objects = {\"ClassToken\": ClassToken}\n",
    "    for fold_no in range(1, 6):\n",
    "        with tf.keras.utils.custom_object_scope(custom_objects):\n",
    "            fold_model = tf.keras.models.load_model(f\"files/modelN_fold{fold_no}.h5\")\n",
    "        y_pred_probs = fold_model.predict(test_ds)\n",
    "        all_preds.append(y_pred_probs)\n",
    "\n",
    "    avg_preds = np.mean(all_preds, axis=0)\n",
    "    final_preds = np.argmax(avg_preds, axis=1)\n",
    "    y_true = [hp[\"class_names\"].index(img.split(\"/\")[-2]) for img in test_x]\n",
    "    print(classification_report(y_true, final_preds, target_names=hp[\"class_names\"]))\n",
    "    roc_aucs = []\n",
    "\n",
    "    for i, class_name in enumerate(hp[\"class_names\"]):\n",
    "        auc_val = roc_auc_score((np.array(y_true) == i).astype(int), avg_preds[:, i])\n",
    "        roc_aucs.append(auc_val)\n",
    "        print(f\"AUC-ROC ({class_name}): {auc_val:.4f}\")\n",
    "\n",
    "    for i, class_name in enumerate(hp[\"class_names\"]):\n",
    "        fpr, tpr, _ = roc_curve((np.array(y_true) == i).astype(int), avg_preds[:, i])\n",
    "        plt.plot(fpr, tpr, label=f\"{class_name} (AUC = {roc_aucs[i]:.2f})\")\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], color='grey', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
